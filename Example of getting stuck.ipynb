{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">TABLE OF CONTENTS</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "**Updates to the table of contents are periodic, but run the cell below to first start or force an update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://sites.google.com/site/brodylabhome/files/make_table_of_contents.js')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition @javascript_str(ANY<:Any) in module Main at In[1]:1 overwritten at In[2]:1.\n"
     ]
    }
   ],
   "source": [
    "macro javascript_str(s) display(\"text/javascript\", s); end\n",
    "\n",
    "javascript\"\"\"\n",
    "$.getScript('https://sites.google.com/site/brodylabhome/files/make_table_of_contents.js')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We define functions to convert Duals, the variable types used by ForwardDiff, \\nto Floats. This is useful if we want to print out the value of a variable \\n(since print doesn't know how to Duals). Note that after being converted to a Float, no\\ndifferentiation by ForwardDiff can happen!  e.g. after\\n    x = convert(Float64, y)\\nForwardDiff can still differentiate y, but it can't differentiate x\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using ForwardDiff\n",
    "using DiffBase\n",
    "\n",
    "pygui(true)\n",
    "\n",
    "import Base.convert\n",
    "convert(::Type{Float64}, x::ForwardDiff.Dual) = Float64(x.value)\n",
    "function convert(::Array{Float64}, x::Array{ForwardDiff.Dual}) \n",
    "    y = zeros(size(x)); \n",
    "    for i in 1:prod(size(x)) \n",
    "        y[i] = convert(Float64, x[i]) \n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "include(\"general_utils.jl\")\n",
    "include(\"hessian_utils.jl\")\n",
    "\n",
    "\"\"\"\n",
    "We define functions to convert Duals, the variable types used by ForwardDiff, \n",
    "to Floats. This is useful if we want to print out the value of a variable \n",
    "(since print doesn't know how to Duals). Note that after being converted to a Float, no\n",
    "differentiation by ForwardDiff can happen!  e.g. after\n",
    "    x = convert(Float64, y)\n",
    "ForwardDiff can still differentiate y, but it can't differentiate x\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup -- definitions of forwardModel() and backwardsModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backwardsModel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "o = g(z)    squashing tanh function, running from 0 to 1, is equal to 0.5 when input is 0.\n",
    "\"\"\"\n",
    "function g(z)\n",
    "    return 0.5*tanh.(z)+0.5\n",
    "end\n",
    "    \n",
    "\"\"\"\n",
    "z = g^-1(o)    inverse of squashing tanh function, input must be in (0, 1), output is zero when passed 0.5.\n",
    "\"\"\"\n",
    "function ginverse(z)\n",
    "    return 0.5*log.(z./(1-z))\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "forwardModel(startU; dt=0.01, tau=0.1, nsteps=100, input=[0.1, 0], noise=[], W=[0 -5;-5 0], \n",
    "    init_add=0, const_add=0, sigma=0, gleak=1, U_rest=0, \n",
    "    do_plot=false, nderivs=0, difforder=0, clearfig=true, fignum=1, dUdt_mag_only=false)\n",
    "\n",
    "Runs a tanh() style-network forwards in time, given its starting point, using simple Euler integration\n",
    "    tau dU/dt = -U + W*V + I\n",
    "    V = 0.5*tanh(U)+ 0.5\n",
    "\n",
    "**PARAMETERS:**\n",
    "\n",
    "startU     A column vector, nunits-by-1, indicating the values of U at time zero\n",
    "\n",
    "\n",
    "**OPTIONAL PARAMETERS**\n",
    "\n",
    "dt      Scalar, timestep size\n",
    "\n",
    "tau     Scalar, in seconds\n",
    "\n",
    "gleak   \n",
    "        dUdt will have a term equal to gleak*(U_rest - U)\n",
    "U_rest\n",
    "\n",
    "nsteps  Number of timesteps to run, including time=0.\n",
    "\n",
    "input   Either an nunits-by-1 vector, in which case inputs to each unit are constant\n",
    "        across time, or a matrix, nunits-by-nsteps, indicating input for each unit at each timepoint.\n",
    "\n",
    "W       Weight matrix, nunits-by-nunits\n",
    "\n",
    "init_add    Vector or scalar that gets added to U at very first timestep, U[:,1]\n",
    "\n",
    "const_add   Scalar that gets added to U after every timestep\n",
    "\n",
    "sigma       After each timestep, add sigma*sqrt(dt)*randn() to each element of U\n",
    "\n",
    "do_plot   Default false, if true, plots V of up to the first two dimensions\n",
    "\n",
    "fignum     Figure number on which to plot\n",
    "\n",
    "clrearfig  If true, the figure is first cleared, otherwise any plot ois overlaid\n",
    "\n",
    "nderivs, difforder     Required for making sure function can create its own arrays and \n",
    "                       still be differentiated\n",
    "\n",
    "dUdt_mag_only  If true, returns |dUdt|^2 from the first timestep only, then stops.\n",
    "\n",
    "** RETURNS:**\n",
    "\n",
    "Uend Vend       nunits-by-1 vectors representing the final values of U and V that were found.\n",
    "U, V            nunits-by-nsteps matrices containing the full trajectories\n",
    "\n",
    "\"\"\"\n",
    "function forwardModel(startU; dt=0.01, tau=0.1, nsteps=100, input=[], noise=[], W=[0 -5;-5 0], \n",
    "    init_add=0, const_add=0, do_plot=false, nderivs=0, difforder=0, clearfig=true, fignum=1,\n",
    "    dUdt_mag_only=false, sigma=0, g_leak=1, U_rest=0, theta=0, beta=1, other_unused_params...)\n",
    "\n",
    "    my_input = ForwardDiffZeros(size(input,1), size(input,2), nderivs=nderivs, difforder=difforder)\n",
    "    for i=1:prod(size(input)); my_input[i] = input[i]; end\n",
    "    input = my_input;\n",
    "    \n",
    "    nunits = length(startU)\n",
    "    if size(startU,2) > size(startU,1)\n",
    "        error(\"startU must be a column vector\")\n",
    "    end\n",
    "    \n",
    "    # --- formatting input ---\n",
    "    if ~(typeof(input)<:Array) || prod(size(input))==1  # was a scalar\n",
    "        input = input[1]*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(input)==0 # was the empty matrix\n",
    "        input = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(input,2)==1     # was a column vector\n",
    "        input = input*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    # --- formatting noise ---\n",
    "    if ~(typeof(noise)<:Array) || prod(size(noise))==1  # was a scalar\n",
    "        noise = noise*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(noise)==0 # was the empty matrix\n",
    "        noise = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(noise,2)==1     # was a column vector\n",
    "        noise = noise*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    \n",
    "    U = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    V = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    \n",
    "    if ~(typeof(W)<:Array); W = [W]; end\n",
    "\n",
    "    W     = reshape(W, nunits, nunits)\n",
    "    U     = reshape(U, nunits, nsteps)\n",
    "    V     = reshape(V, nunits, nsteps)\n",
    "    input = reshape(input, nunits, nsteps)\n",
    "    noise = reshape(noise, nunits, nsteps)\n",
    "\n",
    "    input[:,1] += init_add\n",
    "    input      += const_add\n",
    "\n",
    "    #@printf(\"size(U) is (%d,%d), and size(startU) is (%d,%d) and size(noise) is (%d,%d)\", \n",
    "    #    size(U,1), size(U,2), size(startU,1), size(startU,2), size(noise,1), size(noise,2))\n",
    "    # @printf(\"U[1]=%g, noise[1]=%g\\n\", startU, noise[1])\n",
    "    U[:,1] = startU + noise[:,1]; # @printf(\"Resulting U=%g\\n\", U[1])\n",
    "    V[:,1] = g((U[:,1]-theta)/beta); # @printf(\"Resulting V=%g\\n\", V[1])\n",
    "    \n",
    "    for i=2:nsteps\n",
    "        dUdt = g_leak*(U_rest -U[:,i-1]) + W*V[:,i-1] + input[:,i-1]\n",
    "        if dUdt_mag_only; return sum(dUdt.*dUdt); end;\n",
    "        # @printf(\"dUdt=%g\\n\", dUdt[1])\n",
    "        # @printf(\"i=%g\\n\", i)\n",
    "        # @printf(\"noise[2]=%g\\n\", noise[2])\n",
    "        U[:,i] = U[:,i-1] + (dt/tau)*dUdt + noise[:,i] + sigma*sqrt(dt)*randn(size(U,1),1)\n",
    "        # @printf(\"Resulting U[2]=%g\\n\", U[2])\n",
    "        V[:,i] = g((U[:,i]-theta)/beta)\n",
    "        # @printf(\"Resulting V[2]=%g\\n\", V[2])\n",
    "    end\n",
    "\n",
    "    if do_plot\n",
    "        figure(fignum)\n",
    "        if length(startU)==1\n",
    "            if clearfig; clf(); end;\n",
    "            t = (0:nsteps-1)*dt\n",
    "            plot(t, V[1,:], \"b-\")\n",
    "            plot(t[1], V[1,1], \"g.\")\n",
    "            plot(t[end], V[1,end], \"r.\")\n",
    "            xlabel(\"t\"); ylabel(\"V1\"); ylim([-0.01, 1.01])\n",
    "        elseif length(startU)>=2\n",
    "            if clearfig; clf(); end;\n",
    "            plot(V[1,:], V[2,:], \"b-\")\n",
    "            plot(V[1,1], V[2,1], \"g.\")\n",
    "            plot(V[1,end], V[2,end], \"r.\")\n",
    "            xlabel(\"V1\"); ylabel(\"V2\"); \n",
    "            xlim([-0.01, 1.01]); ylim([-0.01, 1.01])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return U[:,end], V[:,end], U, V\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "backwardsModel(endU; dt=0.01, tau=0.1, nsteps=100, input=[0],noise=[],  W=[0 -5;-5 0], \n",
    "    do_plot=false, nderivs=0, difforder=0, clearfig=true, fignum=1, tol=1e-15, start_eta=10)\n",
    "\n",
    "Runs a tanh() style-network BACKWARDS in time, given its ending point, by making a backwards\n",
    "guess at each timepoint and then using Hessian minimization to find the backwards vector that correctly\n",
    "leads to the current timestep value.  Uses forwardModel() . The forwards equations are:\n",
    "\n",
    "    tau dU/dt = -U + W*V + I\n",
    "    V = 0.5*tanh(U)+ 0.5\n",
    "\n",
    "**PARAMETERS:**\n",
    "\n",
    "endU     A column vector, nunits-by-1, indicating the values of U at time=end\n",
    "\n",
    "\n",
    "**OPTIONAL PARAMETERS:**\n",
    "\n",
    "dt      Scalar, timestep size\n",
    "\n",
    "tau     Scalar, in seconds\n",
    "\n",
    "nsteps  Number of timesteps to run, including time=0.\n",
    "\n",
    "input   Either an nunits-by-1 vector, in which case inputs to each unit are constant\n",
    "        across time, or a matrix, nunits-by-nsteps, indicating input for each unit at each timepoint.\n",
    "\n",
    "W       Weight matrix, nunits-by-nunits\n",
    "\n",
    "do_plot   Default false, if true, plots V of up to the first two dimensions\n",
    "\n",
    "tol       Tolerance in the minimization procedure for finding each backwards timestep. Passed on\n",
    "          to trust_region_Hessian_minimization()\n",
    "\n",
    "start_eta   Passed on to trust_region_Hessian_minimization()\n",
    "\n",
    "fignum     Figure number on which to plot\n",
    "\n",
    "clrearfig  If true, the figure is first cleared, otherwise any plot ois overlaid\n",
    "\n",
    "nderivs, difforder     Required for making sure function can create its own arrays and \n",
    "                       still be differentiated\n",
    "\n",
    "\n",
    "\n",
    "** RETURNS:**\n",
    "\n",
    "Ustart Vstart   nunits-by-1 vectors representing the starting values of U and V that were found.\n",
    "U, V            nunits-by-nsteps matrices containing the full trajectories\n",
    "costs           1-by-nsteps vector with the final cost from the minimization procedure for each\n",
    "                timestep. This is the squared difference between the U[t+1] produced by the U[t] \n",
    "                guess and the actual U[t+1]\n",
    "\n",
    "\"\"\"\n",
    "function backwardsModel(endU; nsteps=100, start_eta=10, tol=1e-15, maxiter=400, \n",
    "    do_plot=false, init_add=0, input=[], noise=[], nderivs=0, difforder=0, clearfig=false, fignum=1, params...)    \n",
    "\n",
    "    nunits = length(endU)\n",
    "\n",
    "    # --- formatting input ---\n",
    "    if ~(typeof(input)<:Array) || prod(size(input))==1  # was a scalar\n",
    "        input = input[1]*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(input)==0 # was the empty matrix\n",
    "        input = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(input,2)==1     # was a column vector\n",
    "        input = input*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    # --- formatting noise ---\n",
    "    if ~(typeof(noise)<:Array)  # was a scalar\n",
    "        noise = noise*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(noise)==0 # was the empty matrix\n",
    "        noise = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(noise,2)==1     # was a column vector\n",
    "        noise = noise*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    \n",
    "    function J(U1, U2; nderivs=0, difforder=0, noise=[], inputs=[], pars...)\n",
    "        U2hat = forwardModel(U1; nsteps=2, noise=noise, input=input, nderivs=nderivs, difforder=difforder, pars...)[1]\n",
    "        U2hat = U2hat\n",
    "        DU = U2hat - U2\n",
    "    \n",
    "        return sum(DU.*DU)\n",
    "    end\n",
    "    \n",
    "    if length(noise)==0\n",
    "        noise = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    end\n",
    "\n",
    "    U = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    U = reshape(U, nunits, nsteps)\n",
    "    costs = ForwardDiffZeros(nsteps, 1, nderivs=nderivs, difforder=difforder)    \n",
    "    \n",
    "    U[:,end] = endU\n",
    "    for i=(nsteps-1):-1:1\n",
    "        if i==1\n",
    "            my_init_add = init_add\n",
    "        else\n",
    "            my_init_add = 0\n",
    "        end\n",
    "        \n",
    "        U[:,i], costs[i] = trust_region_Hessian_minimization(U[:,i+1], \n",
    "            (x) -> J(x, U[:,i+1]; nderivs=length(endU), difforder=2, \n",
    "            input=input[:,i:i+1], noise = noise[:,i:i+1], init_add=my_init_add, params...); \n",
    "            verbose=false, start_eta=start_eta, tol=tol, maxiter=maxiter)\n",
    "        U[:,i] += noise[:,i]\n",
    "    end\n",
    "    \n",
    "    \n",
    "    V = g(U)\n",
    "    \n",
    "    if do_plot\n",
    "        figure(fignum)        \n",
    "        if length(endU)==1\n",
    "            if clearfig; clf(); end;\n",
    "            t = (0:nsteps-1)*dt\n",
    "            plot(t, V[1,:], \"m-\")\n",
    "            plot(t[1], V[1,1], \"go\")\n",
    "            plot(t[end], V[1,end], \"ro\")            \n",
    "            ylim([-0.01, 1.01])\n",
    "        elseif length(endU)>=2\n",
    "            if clearfig; clf(); end;            \n",
    "            plot(V[1,:], V[2,:], \"m-\")\n",
    "            plot(V[1,1], V[2,1], \"go\")\n",
    "            plot(V[1,end], V[2,end], \"ro\")\n",
    "            xlim([-0.01, 1.01]); ylim([-0.01, 1.01])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return U[:,1], V[:,1], U, V, costs\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of getting stuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = [2, 2, 2.1, -1]\n",
      "-- cost=0.0624999,   cost1=0.0624999, cost2=0 :  mean(hits)=0.5, mean(diffs)=2.29331e-08\n",
      "0: eta=1 ps=[2.000, 2.000, 2.100, -1.000]\n",
      "-- cost=0.0624999,   cost1=0.0624999, cost2=0 :  mean(hits)=0.5, mean(diffs)=2.29321e-08\n",
      "-- cost=0.0625,   cost1=0.0625, cost2=0 :  mean(hits)=0.5, mean(diffs)=3.67053e-09\n",
      "1: eta=0.5 cost=0.0624999 jtype=Newton costheta=NaN ps=[2.000, 2.000, 2.100, -1.000]\n",
      "-- cost=0.0624578,   cost1=0.0624578, cost2=0 :  mean(hits)=0.500084, mean(diffs)=2.53654e-06\n",
      "2: eta=0.55 cost=0.0624578 jtype=constrained costheta=-0.780 ps=[2.271, 1.723, 1.924, -1.262]\n",
      "-- cost=0.0624834,   cost1=0.0624834, cost2=0 :  mean(hits)=0.500033, mean(diffs)=3.48113e-07\n",
      "3: eta=0.275 cost=0.0624578 jtype=Newton costheta=NaN ps=[2.271, 1.723, 1.924, -1.262]\n",
      "-- cost=0.0624834,   cost1=0.0624834, cost2=0 :  mean(hits)=0.500033, mean(diffs)=3.48113e-07\n",
      "4: eta=0.1375 cost=0.0624578 jtype=Newton costheta=NaN ps=[2.271, 1.723, 1.924, -1.262]\n",
      "-- cost=0.0623676,   cost1=0.0623676, cost2=0 :  mean(hits)=0.500265, mean(diffs)=2.11005e-05\n",
      "5: eta=0.15125 cost=0.0623676 jtype=constrained costheta=-1.000 ps=[2.299, 1.693, 1.853, -1.373]\n",
      "-- cost=0.0620374,   cost1=0.0620374, cost2=0 :  mean(hits)=0.500927, mean(diffs)=0.000221686\n",
      "6: eta=0.166375 cost=0.0620374 jtype=constrained costheta=-1.000 ps=[2.328, 1.662, 1.777, -1.497]\n",
      "-- cost=0.0607675,   cost1=0.0607675, cost2=0 :  mean(hits)=0.503489, mean(diffs)=0.00270102\n",
      "7: eta=0.183013 cost=0.0607675 jtype=constrained costheta=-1.000 ps=[2.358, 1.629, 1.697, -1.635]\n",
      "-- cost=0.0561642,   cost1=0.0561642, cost2=0 :  mean(hits)=0.51301, mean(diffs)=0.0322894\n",
      "8: eta=0.201314 cost=0.0561642 jtype=constrained costheta=-1.000 ps=[2.391, 1.593, 1.615, -1.791]\n",
      "-- cost=0.0455367,   cost1=0.0455367, cost2=0 :  mean(hits)=0.536607, mean(diffs)=0.240174\n",
      "9: eta=0.221445 cost=0.0455367 jtype=constrained costheta=-0.999 ps=[2.432, 1.547, 1.536, -1.966]\n",
      "-- cost=0.0356321,   cost1=0.0356321, cost2=0 :  mean(hits)=0.561235, mean(diffs)=0.541478\n",
      "10: eta=0.24359 cost=0.0356321 jtype=constrained costheta=-0.940 ps=[2.538, 1.425, 1.491, -2.110]\n",
      "-- cost=0.0267294,   cost1=0.0267294, cost2=0 :  mean(hits)=0.586509, mean(diffs)=0.681848\n",
      "11: eta=0.267949 cost=0.0267294 jtype=constrained costheta=-0.983 ps=[2.683, 1.249, 1.469, -2.194]\n",
      "-- cost=0.0176649,   cost1=0.0176649, cost2=0 :  mean(hits)=0.617091, mean(diffs)=0.798886\n",
      "12: eta=0.294743 cost=0.0176649 jtype=constrained costheta=-0.997 ps=[2.835, 1.054, 1.449, -2.295]\n",
      "-- cost=0.00958744,   cost1=0.00958744, cost2=0 :  mean(hits)=0.652085, mean(diffs)=0.871972\n",
      "13: eta=0.324218 cost=0.00958744 jtype=constrained costheta=-0.997 ps=[3.000, 0.827, 1.437, -2.384]\n",
      "-- cost=0.00397835,   cost1=0.00397835, cost2=0 :  mean(hits)=0.686926, mean(diffs)=0.971909\n",
      "14: eta=0.35664 cost=0.00397835 jtype=constrained costheta=-0.986 ps=[3.152, 0.612, 1.425, -2.573]\n",
      "-- cost=0.00367755,   cost1=0.00367755, cost2=0 :  mean(hits)=0.689357, mean(diffs)=0.990018\n",
      "15: eta=0.392304 cost=0.00367755 jtype=Newton costheta=-0.759 ps=[3.143, 0.564, 1.476, -2.671]\n",
      "-- cost=0.003622,   cost1=0.003622, cost2=0 :  mean(hits)=0.689817, mean(diffs)=0.995314\n",
      "16: eta=0.431534 cost=0.003622 jtype=Newton costheta=-0.727 ps=[3.140, 0.547, 1.510, -2.741]\n",
      "-- cost=0.00360765,   cost1=0.00360765, cost2=0 :  mean(hits)=0.689936, mean(diffs)=0.997352\n",
      "17: eta=0.474687 cost=0.00360765 jtype=Newton costheta=-0.676 ps=[3.140, 0.544, 1.538, -2.804]\n",
      "-- cost=0.00360316,   cost1=0.00360316, cost2=0 :  mean(hits)=0.689974, mean(diffs)=0.998284\n",
      "18: eta=0.522156 cost=0.00360316 jtype=Newton costheta=-0.626 ps=[3.140, 0.549, 1.564, -2.866]\n",
      "-- cost=0.00360154,   cost1=0.00360154, cost2=0 :  mean(hits)=0.689987, mean(diffs)=0.998782\n",
      "19: eta=0.574372 cost=0.00360154 jtype=Newton costheta=-0.573 ps=[3.140, 0.562, 1.588, -2.933]\n",
      "-- cost=0.00360087,   cost1=0.00360087, cost2=0 :  mean(hits)=0.689993, mean(diffs)=0.999087\n",
      "20: eta=0.631809 cost=0.00360087 jtype=Newton costheta=-0.526 ps=[3.140, 0.586, 1.613, -3.012]\n",
      "-- cost=0.00360054,   cost1=0.00360054, cost2=0 :  mean(hits)=0.689995, mean(diffs)=0.999296\n",
      "21: eta=0.69499 cost=0.00360054 jtype=Newton costheta=-0.503 ps=[3.138, 0.621, 1.643, -3.112]\n",
      "-- cost=0.00360036,   cost1=0.00360036, cost2=0 :  mean(hits)=0.689997, mean(diffs)=0.999448\n",
      "22: eta=0.764489 cost=0.00360036 jtype=Newton costheta=-0.508 ps=[3.134, 0.663, 1.686, -3.242]\n",
      "-- cost=0.00360026,   cost1=0.00360026, cost2=0 :  mean(hits)=0.689998, mean(diffs)=0.999562\n",
      "23: eta=0.840937 cost=0.00360026 jtype=Newton costheta=-0.517 ps=[3.128, 0.705, 1.749, -3.412]\n",
      "-- cost=0.00360019,   cost1=0.00360019, cost2=0 :  mean(hits)=0.689998, mean(diffs)=0.999646\n",
      "24: eta=0.925031 cost=0.00360019 jtype=Newton costheta=-0.479 ps=[3.122, 0.738, 1.841, -3.634]\n",
      "-- cost=0.00360014,   cost1=0.00360014, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999706\n",
      "25: eta=1.01753 cost=0.00360014 jtype=Newton costheta=-0.328 ps=[3.117, 0.758, 1.967, -3.915]\n",
      "-- cost=0.00360012,   cost1=0.00360012, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999746\n",
      "26: eta=1.11929 cost=0.00360012 jtype=Newton costheta=-0.119 ps=[3.115, 0.766, 2.120, -4.243]\n",
      "-- cost=0.0036001,   cost1=0.0036001, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.99977\n",
      "27: eta=1.23122 cost=0.0036001 jtype=Newton costheta=-0.023 ps=[3.115, 0.768, 2.275, -4.571]\n",
      "-- cost=0.00360009,   cost1=0.00360009, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999786\n",
      "28: eta=1.35434 cost=0.00360009 jtype=Newton costheta=-0.006 ps=[3.115, 0.768, 2.438, -4.911]\n",
      "-- cost=0.00360009,   cost1=0.00360009, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999797\n",
      "29: eta=1.48977 cost=0.00360009 jtype=Newton costheta=-0.002 ps=[3.115, 0.768, 2.618, -5.279]\n",
      "-- cost=0.00360008,   cost1=0.00360008, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999804\n",
      "30: eta=1.63875 cost=0.00360008 jtype=Newton costheta=-0.001 ps=[3.114, 0.767, 2.814, -5.674]\n",
      "-- cost=0.00360008,   cost1=0.00360008, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999809\n",
      "31: eta=1.80262 cost=0.00360008 jtype=Newton costheta=-0.000 ps=[3.114, 0.767, 3.028, -6.105]\n",
      "-- cost=0.00360008,   cost1=0.00360008, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999813\n",
      "32: eta=1.98289 cost=0.00360008 jtype=Newton costheta=-0.000 ps=[3.114, 0.766, 3.262, -6.573]\n",
      "-- cost=0.00360008,   cost1=0.00360008, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999815\n",
      "33: eta=2.18118 cost=0.00360008 jtype=Newton costheta=-0.000 ps=[3.114, 0.765, 3.519, -7.085]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999817\n",
      "34: eta=2.39929 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.114, 0.765, 3.802, -7.651]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999817\n",
      "35: eta=2.63922 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.113, 0.764, 4.130, -8.308]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "36: eta=2.90314 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.113, 0.763, 4.563, -9.179]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "37: eta=3.19346 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.113, 0.761, 5.057, -10.169]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "38: eta=3.5128 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.112, 0.760, 5.555, -11.166]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "39: eta=3.86409 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.112, 0.759, 6.054, -12.164]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "40: eta=4.25049 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.112, 0.758, 6.554, -13.164]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "41: eta=4.67554 cost=0.00360007 jtype=Newton costheta=-0.000 ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00490008,   cost1=0.00490008, cost2=0 :  mean(hits)=0.679999, mean(diffs)=0.999818\n",
      "42: eta=2.33777 cost=0.00360007 jtype=Newton costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00490008,   cost1=0.00490008, cost2=0 :  mean(hits)=0.679999, mean(diffs)=0.999818\n",
      "43: eta=1.16889 cost=0.00360007 jtype=Newton costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00490008,   cost1=0.00490008, cost2=0 :  mean(hits)=0.679999, mean(diffs)=0.999818\n",
      "44: eta=0.584443 cost=0.00360007 jtype=Newton costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.0256001,   cost1=0.0256001, cost2=0 :  mean(hits)=0.59, mean(diffs)=0.999818\n",
      "45: eta=0.292221 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.0169001,   cost1=0.0169001, cost2=0 :  mean(hits)=0.62, mean(diffs)=0.999818\n",
      "46: eta=0.146111 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00810009,   cost1=0.00810009, cost2=0 :  mean(hits)=0.659999, mean(diffs)=0.999818\n",
      "47: eta=0.0730554 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00640009,   cost1=0.00640009, cost2=0 :  mean(hits)=0.669999, mean(diffs)=0.999818\n",
      "48: eta=0.0365277 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00640009,   cost1=0.00640009, cost2=0 :  mean(hits)=0.669999, mean(diffs)=0.999818\n",
      "49: eta=0.0182638 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00640009,   cost1=0.00640009, cost2=0 :  mean(hits)=0.669999, mean(diffs)=0.999818\n",
      "50: eta=0.00913192 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.111, 0.756, 7.054, -14.164]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "51: eta=0.0100451 cost=0.00360007 jtype=constrained costheta=-1.000 ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "52: eta=0.00502256 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "53: eta=0.00251128 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "54: eta=0.00125564 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "55: eta=0.000627819 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "56: eta=0.00031391 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "57: eta=0.000156955 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "58: eta=7.84774e-05 cost=0.00360007 jtype=constrained costheta=NaN ps=[3.116, 0.750, 7.054, -14.163]\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n",
      "-- cost=0.00360007,   cost1=0.00360007, cost2=0 :  mean(hits)=0.689999, mean(diffs)=0.999818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1Ã—4 Array{Float64,2}:\n",
       " 2.77878  0.744332  7.0538  -14.1635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function JJ(initUs; theta1=0.15, theta2=0.2, beta=0.003, verbose=false, nderivs=0, difforder=0, \n",
    "    do_plot=false, pre_string=\"\", zero_last_sigmas=0, seedrand=NaN, params...)\n",
    "\n",
    "    if ~isnan(seedrand); srand(seedrand); end\n",
    "    \n",
    "    Vend = ForwardDiffZeros(size(initUs,1), size(initUs,2), nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "    if do_plot; clf(); end;\n",
    "    \n",
    "    for i=1:size(initUs,1)\n",
    "        if false # i>size(initUs,1) - zero_last_sigmas\n",
    "            Ue, Ve, U, V = forwardModel(initUs[i,:]; sigma=0, nderivs=nderivs, difforder=difforder, \n",
    "                do_plot=do_plot, clearfig=false, params...)            \n",
    "        else\n",
    "            Ue, Ve, U, V = forwardModel(initUs[i,:]; nderivs=nderivs, difforder=difforder, \n",
    "                do_plot=do_plot, clearfig=false, params...)\n",
    "        end\n",
    "        Vend[i,:] = Ve\n",
    "    end\n",
    "    \n",
    "    hits = 0.5*(1 + tanh.((Vend[:,1]-Vend[:,2])/theta1))\n",
    "    diffs = tanh.((Vend[:,1]-Vend[:,2])/theta2).^2\n",
    "    \n",
    "    cost1 = (mean(hits) - 0.75).^2 \n",
    "    cost2 = -beta*mean(diffs)\n",
    "    \n",
    "    if verbose\n",
    "        @printf(\"%s\", pre_string)\n",
    "        @printf(\"-- cost=%g,   cost1=%g, cost2=%g :  mean(hits)=%g, mean(diffs)=%g\\n\", \n",
    "            convert(Float64, cost1+cost2), convert(Float64, cost1), convert(Float64, cost2),\n",
    "            convert(Float64, mean(hits)), convert(Float64, mean(diffs)))\n",
    "    end\n",
    "    \n",
    "    return cost1 + cost2\n",
    "end\n",
    "\n",
    "\n",
    "# The following sequence leads to a situation where having only [-0.8, -0.8] as the single finalFluxPoint \n",
    "# leads to the minimization getting stuck.  Adding further finalFluxPoints solves the problem\n",
    "#\n",
    "srand(11)\n",
    "startU=randn(100,2)-3\n",
    "startU=randn(100,2)-3\n",
    "\n",
    "dt = 0.02\n",
    "t = 0:dt:1\n",
    "tau = 0.1\n",
    "nsteps = length(t)\n",
    "t = t[1:nsteps]\n",
    "\n",
    "W = -4\n",
    "noise = 0\n",
    "input = 0\n",
    "sigma = 0\n",
    "\n",
    "\n",
    "model_params = Dict(:dt=>dt, :tau=>tau, :W=>[0 W; W 0], :nsteps=>nsteps, \n",
    ":noise=>noise, :input=>input, :sigma=>sigma, :const_add=>0, :init_add=>0)\n",
    "\n",
    "\n",
    "# WORKING gradient:\n",
    "# ForwardDiff.gradient((x)->JJ(startU; do_plot=true, nderivs=length(x), difforder=1, \n",
    "#    make_dict([[\"init_add\" 2], \"const_add\"], x, model_params)...), [2.9, -2.9, 0.1])\n",
    "\n",
    "\n",
    "\n",
    "# The backward and costfunc functions should turn a single-scalar parameter W into the matrix W\n",
    "# backward always runs with no within-forward noise, i.e., sigma=0\n",
    "backward = (endpoint; do_plot=false, pars...) -> begin\n",
    "    pars = Dict(pars)\n",
    "    if haskey(pars, :W); \n",
    "        W=pars[:W];   # mess with it only if it is not already a matrix:\n",
    "        if length(W)==1; pars=make_dict([\"W\"], [[0 W;W 0]], pars); end;\n",
    "    end;     \n",
    "    backwardsModel(endpoint; do_plot=do_plot, make_dict([\"sigma\"], [0], pars)...)[1]\n",
    "end\n",
    "\n",
    "\n",
    "beta = 0.0001;\n",
    "beta = 0.003;\n",
    "beta = 0.003;\n",
    "beta=0\n",
    "\n",
    "costfunc = (startpoints; do_plot=false, verbose=false, nderivs=0, difforder=0, sr=26, pars...) -> begin\n",
    "    pars = Dict(pars)\n",
    "    if haskey(pars, :W); \n",
    "        W=pars[:W];   # mess with it only if it is not already a matrix:\n",
    "        if length(W)==1; pars=make_dict([\"W\"], [[0 W;W 0]], pars); end;\n",
    "    end;         \n",
    "    JJ(startpoints; seedrand=sr, beta=beta, \n",
    "        do_plot=do_plot, verbose=verbose, nderivs=nderivs, difforder=difforder, pars...)\n",
    "end\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "if beta==0.003;     cost_limit = -0.00288\n",
    "elseif beta<0.001;  cost_limit = -0.0008\n",
    "elseif beta==0.001; cost_limit = -0.000935\n",
    "elseif beta==0.05;  cost_limit = -0.0485\n",
    "else\n",
    "    error(\"Don't know what cost limit goes with beta %g\\n\", beta)\n",
    "end\n",
    "\n",
    "fluxFinalPoint = [-0.8 -0.8; -0.6 -0.6 ; -0.4 -0.4; -0.2 -0.2; 0 0; 0.2 0.2]\n",
    "fluxFinalPoint = zeros(0,2);\n",
    "\n",
    "\n",
    "args = [[\"init_add\" 2], \"const_add\", \"W\"] # , \"sigma\"]\n",
    "seed = [2, 2, 2.1, -1] # , 0.1]\n",
    "\n",
    "\n",
    "\n",
    "clf()\n",
    "print(\"seed = \"); print_vector_g(seed); print(\"\\n\")\n",
    "costfunc(startU; do_plot=true, verbose=true, make_dict(args, seed, model_params)...)\n",
    "\n",
    "# :sigma=>[-0.3, 0.3] does fine but :sigma=>[-0.2, 0.2] gets stuck.\n",
    "# If we fix sigma at 0 it also gets stuck, but dynamics kind of odd, W a bit to big, or decrease dt\n",
    "params, traj = bbox_Hessian_keyword_minimization(seed, args, Dict(:init_add=>[-5.1, 5.1]), # , :sigma=>[-0.2, 0.2]), \n",
    "(;params...) -> costfunc(startU; do_plot=false, verbose=true, merge(model_params, Dict(params))...), \n",
    " verbose=true, start_eta=1, tol=1e-16, hardbox=true )\n",
    "\n",
    "# params, cost, ptraj, gtraj = fluxSense(costfunc, backward, model_params, startU, fluxFinalPoint, args, seed; \n",
    "#    start_eta=0.01, tol=1e-15, maxiter=400, verbose=true, report_every=1, do_plot=false, cost_limit=cost_limit) # cost_limit=-0.000935) # for beta=0.01\n",
    "\n",
    "# And show the final position\n",
    "clf()\n",
    "costfunc(startU; do_plot=true, verbose=true, make_dict(args, params, model_params)...)\n",
    "params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
