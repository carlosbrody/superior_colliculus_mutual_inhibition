{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "This notebook tries to reproduce what Marino did where he got good training even with tens of trials from a variety of starting points.  It uses his run_dynamics function.\n",
    "\n",
    "# ==========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We define functions to convert Duals, the variable types used by ForwardDiff, \\nto Floats. This is useful if we want to print out the value of a variable \\n(since print doesn't know how to Duals). Note that after being converted to a Float, no\\ndifferentiation by ForwardDiff can happen!  e.g. after\\n    x = convert(Float64, y)\\nForwardDiff can still differentiate y, but it can't differentiate x\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "using PyPlot\n",
    "using ForwardDiff\n",
    "using DiffBase\n",
    "\n",
    "pygui(true)\n",
    "\n",
    "import Base.convert\n",
    "convert(::Type{Float64}, x::ForwardDiff.Dual) = Float64(x.value)\n",
    "function convert(::Array{Float64}, x::Array{ForwardDiff.Dual}) \n",
    "    y = zeros(size(x)); \n",
    "    for i in 1:prod(size(x)) \n",
    "        y[i] = convert(Float64, x[i]) \n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "include(\"hessian_utils.jl\")\n",
    "\n",
    "\"\"\"\n",
    "We define functions to convert Duals, the variable types used by ForwardDiff, \n",
    "to Floats. This is useful if we want to print out the value of a variable \n",
    "(since print doesn't know how to Duals). Note that after being converted to a Float, no\n",
    "differentiation by ForwardDiff can happen!  e.g. after\n",
    "    x = convert(Float64, y)\n",
    "ForwardDiff can still differentiate y, but it can't differentiate x\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marino's main model dynamics function  (adapted from model_gradient_kwargs_fast.jl on 20-July-2017)\n",
    "\n",
    "Note that the documenation indicates some default values for the optional parameters; these values need to be updated to what the code actually says below. The actual defaults are much closer to what Marino's May 2017 model has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition run_dynamics() in module Main at In[70]:22 overwritten at In[73]:22.\n",
      "WARNING: Method definition #run_dynamics(Array{Any, 1}, Main.#run_dynamics) in module Main overwritten.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'run_dynamics :: Tuple{}' in module 'Main'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "function cost, vec_ans_out, vec_react = run_dynamics(\n",
    "                       target1=0.9,target2=0.9,target3=0.9,target4=0.6,target5=0.4,target6=0.6,\n",
    "                       vwi=9, hwi=0.25, pro_bias=0.2135, opto_effect=0.9,\n",
    "                       delay_input=0.25, light_input=3, noisefr=0.005, sigma=0.005,\n",
    "                       threshold=0.18, ntrials=50, random_seed=321,\n",
    "                       tau=17.6, dt=10, start_U = [-25, -25, -25, -25],\n",
    "                       g_leak = 1, U_rest = 0, theta1 = 5, beta1 = 50, theta2=0.15, theta3=0.15,\n",
    "                       cue_period = 200, delay_period = 200, choice_period = 200, nderivs=0, difforder=0,\n",
    "                       do_plot = false, fignum=1, plot_trials=[])\n",
    "\n",
    "\"\"\"\n",
    "function run_dynamics( ;target1=0.9,target2=0.9,target3=0.9,target4=0.6,target5=0.4,target6=0.6,\n",
    "                       vwi=9, hwi=0.25, pro_bias=0.2135, opto_effect=0.9,\n",
    "                       delay_input=0.25, light_input=3, noisefr=0.005, sigma=0.005,\n",
    "                       threshold=0.18, ntrials=50, random_seed=321,\n",
    "                       tau=17.6, dt=10, start_U = [-25, -25, -25, -25],\n",
    "                       g_leak = 1, U_rest = 0, theta1 = 5, beta1 = 50, theta2=0.15, theta3=0.15,\n",
    "                       cue_period = 200, delay_period = 200, choice_period = 200, nderivs=0, difforder=0,\n",
    "                       do_plot = false, fignum=1, plot_trials=[])\n",
    "\n",
    "    vec_ans_out = ForwardDiffZeros(ntrials, 6; nderivs=nderivs, difforder=difforder)\n",
    "    vec_reac = ForwardDiffZeros(ntrials,6; nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "    if isempty(plot_trials)\n",
    "        plot_trials = [1:ntrials;]\n",
    "    end\n",
    "    \n",
    "    if !isnan(random_seed)\n",
    "        srand(random_seed)\n",
    "    else  # if the random seed is passed as NaN, use the system time in milliseconds\n",
    "        srand(convert(Int64, round(1000*time())))\n",
    "    end\n",
    "\n",
    "\n",
    "    titles = [\"pro\", \"pro delay\", \"pro choice\", \"anti\", \"anti delay\", \"anti choice\"]\n",
    "    for jjj in [1:6;] #trial types: pro, pro delay, pro chioce, anti, anti delay, anti choice\n",
    "\n",
    "        if (jjj==1)||(jjj==2)||(jjj==3) \n",
    "            trial_type=\"pro\"\n",
    "        else     \n",
    "            trial_type=\"anti\"\n",
    "        end\n",
    "\n",
    "        if (jjj==1)||(jjj==4)\n",
    "            opto_delay=1;\n",
    "            opto_choice=1;\n",
    "        elseif (jjj==2)||(jjj==5)\n",
    "            opto_delay=opto_effect;\n",
    "            opto_choice=1;\n",
    "        elseif (jjj==3)||(jjj==6)\n",
    "            opto_delay=1;\n",
    "            opto_choice=opto_effect;\n",
    "        end\n",
    "        \n",
    "        for iii in [1:ntrials;]\n",
    "            t = [0 : dt : cue_period + delay_period + choice_period;]\n",
    "\n",
    "            V = ForwardDiffZeros(4, length(t); nderivs=nderivs, difforder=difforder)\n",
    "            U = ForwardDiffZeros(4, length(t); nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "            U[:,1] = start_U\n",
    "\n",
    "            W = [0 -vwi -hwi 0; -vwi 0 0 -hwi;\n",
    "                 -hwi 0 0 -vwi; 0 -hwi -vwi 0]\n",
    "\n",
    "            for i in [2:length(t);]  # the funny semicolon appears to be necessary in Julia\n",
    "                dUdt = W * V[:,i-1] + g_leak*(U_rest - U[:,i-1])/tau\n",
    "                \n",
    "                if t[i] < cue_period + delay_period\n",
    "                    if trial_type==\"anti\"\n",
    "                        dUdt[[2,4]] += delay_input\n",
    "                    elseif trial_type == \"pro\"\n",
    "                        dUdt[[1,3]] += delay_input\n",
    "                    else\n",
    "                        error(\"invalid trial type\")\n",
    "                    end\n",
    "                elseif t[i] < cue_period + delay_period + choice_period\n",
    "                    dUdt[[1,2]] += light_input\n",
    "                end\n",
    "                \n",
    "                dUdt[[1,3]] += pro_bias\n",
    "\n",
    "                U[:,i] = U[:,i-1] +  dt*dUdt + sqrt(dt)*sigma*randn(4)\n",
    "                V[:,i] = 0.5*tanh((U[:,i]-theta1)/beta1) + 0.5\n",
    "\n",
    "                if t[i] < cue_period+delay_period\n",
    "                    V[:,i]=V[:,i]*opto_delay\n",
    "                elseif t[i] < cue_period+delay_period+choice_period\n",
    "                    V[:,i]=V[:,i]*opto_choice\n",
    "                end\n",
    "\n",
    "                V[:,i] = V[:,i] + noisefr*sqrt(dt/10)*randn(4)\n",
    "            end\n",
    "\n",
    "            if trial_type==\"anti\"    \n",
    "                answer_out  = 0.5*(1 + tanh.((V[3,end]  - V[1,end])/theta2))\n",
    "            elseif trial_type == \"pro\"\n",
    "                answer_out  = 0.5*(1 + tanh.((V[1,end]  - V[3,end])/theta2))\n",
    "            else\n",
    "                error(\"invalid trial type\")\n",
    "            end\n",
    "            \n",
    "            #compute reaction time\n",
    "            reac=NaN;\n",
    "            for i in [161:length(t)-15;]                \n",
    "                val1=mean(V[1,i-15:i+15]);\n",
    "                val3=mean(V[3,i-15:i+15]);\n",
    "                if(abs(val1-val3)>threshold)\n",
    "                    reac=t[i];\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "\n",
    "            vec_ans_out[iii,jjj]=answer_out;\n",
    "            vec_reac[iii,jjj]=reac;\n",
    "            \n",
    "            if do_plot && ~isempty(find(plot_trials.==iii))\n",
    "                figure(fignum); \n",
    "                ax = subplot(6,1,jjj)\n",
    "\n",
    "                h = plot(t, V'); \n",
    "                setp(h[1], color=[0, 0, 1])\n",
    "                setp(h[2], color=[1, 0, 0])\n",
    "                setp(h[3], color=[1, 0.5, 0.5])\n",
    "                setp(h[4], color=[0, 1, 1])\n",
    "                ylabel(\"V\")\n",
    "\n",
    "                ax = gca()\n",
    "                yl = [ylim()[1], ylim()[2]]\n",
    "                vlines([cue_period, cue_period+delay_period, \n",
    "                    cue_period+delay_period+choice_period], \n",
    "                    -0.05, 1.05, linewidth=2)\n",
    "                if yl[1]<0.02\n",
    "                    yl[1] = -0.02\n",
    "                end\n",
    "                if yl[2]>0.98\n",
    "                    yl[2] = 1.02\n",
    "                end\n",
    "                ylim(yl)\n",
    "                grid(true)\n",
    "                title(titles[jjj])\n",
    "                \n",
    "                if jjj==6; \n",
    "                    xlabel(\"t\");  \n",
    "                else\n",
    "                    setp(ax, xticks=[])\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end  # end loop over trials\n",
    "        \n",
    "            \n",
    "    end # end loop over trial types\n",
    "\n",
    "    cost = (mean(vec_ans_out[:,1]) - target1)^2 + (mean(vec_ans_out[:,2]) - target2)^2 + \n",
    "        (mean(vec_ans_out[:,3]) - target3)^2 + (mean(vec_ans_out[:,4]) - target4)^2 + \n",
    "        (mean(vec_ans_out[:,5]) - target5)^2 + (mean(vec_ans_out[:,6]) - target6)^2 \n",
    "        \n",
    "    if do_plot\n",
    "        for jjj=[1:6;]\n",
    "            subplot(6,1,jjj)\n",
    "            title(titles[jjj] * \" \" * string(round(100*mean(vec_ans_out[:,jjj]))) * \" %\")\n",
    "        end\n",
    "    end\n",
    "    vec_ans_out=mean(vec_ans_out,1)\n",
    "\n",
    "    return cost, vec_ans_out, vec_reac\n",
    "end\n",
    "\n",
    "figure(1); clf();\n",
    "# run_dynamics(ntrials=120, do_plot=true, sigma=0.1, noisefr=0.0005, random_seed=NaN)\n",
    "# MARINO PARAMS: with noise added to V, not U\n",
    "# run_dynamics(ntrials=120, do_plot=true, sigma=0, noisefr=0.005, random_seed=NaN)\n",
    "\n",
    "c = run_dynamics(ntrials=200, do_plot=true, sigma=0, noisefr=0.01, random_seed=NaN, dt=2, plot_trials=1:10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11068650092605362,\n",
       "[0.998313 0.998413 … 0.260838 0.725305],\n",
       "\n",
       "[NaN NaN … NaN NaN; NaN NaN … NaN NaN; … ; NaN NaN … NaN NaN; NaN NaN … NaN NaN])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yep\n"
     ]
    }
   ],
   "source": [
    "a = \"a\"\n",
    "b = [a * \" and this\"]\n",
    "string(23.34566800001)\n",
    "isnan(NaN)\n",
    "\n",
    "function glug(;pt=NaN)\n",
    "    if isnan(pt)\n",
    "        @printf \"Yep\\n\"\n",
    "    end\n",
    "end\n",
    "\n",
    "glug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: eta=0.1 ps=[4.000, 4.000, 0.200, 0.200]\n",
      "1: eta=0.11 cost=1.3264 jtype=constrained costheta=-0.999 ps=[4.000, 3.991, 0.100, 0.202]\n",
      "2: eta=0.121 cost=1.2991 jtype=constrained costheta=-0.999 ps=[4.010, 3.984, -0.009, 0.205]\n",
      "3: eta=0.1331 cost=1.2303 jtype=constrained costheta=-0.998 ps=[4.033, 3.980, -0.128, 0.208]\n",
      "4: eta=0.14641 cost=1.0686 jtype=constrained costheta=-0.998 ps=[4.074, 3.980, -0.254, 0.212]\n",
      "5: eta=0.161051 cost=0.7840 jtype=constrained costheta=-0.996 ps=[4.138, 3.987, -0.386, 0.216]\n",
      "6: eta=0.177156 cost=0.5104 jtype=constrained costheta=-0.988 ps=[4.235, 4.001, -0.513, 0.224]\n",
      "7: eta=0.194872 cost=0.4369 jtype=constrained costheta=-0.684 ps=[4.362, 4.018, -0.558, 0.338]\n",
      "8: eta=0.214359 cost=0.4170 jtype=constrained costheta=-0.861 ps=[4.410, 3.995, -0.514, 0.520]\n",
      "9: eta=0.235795 cost=0.3853 jtype=constrained costheta=-0.917 ps=[4.522, 3.990, -0.419, 0.676]\n",
      "10: eta=0.259374 cost=0.3340 jtype=constrained costheta=-0.848 ps=[4.685, 3.997, -0.323, 0.817]\n",
      "11: eta=0.285312 cost=0.2833 jtype=constrained costheta=-0.653 ps=[4.878, 3.981, -0.260, 0.977]\n",
      "12: eta=0.313843 cost=0.2529 jtype=constrained costheta=-0.292 ps=[4.968, 3.817, -0.275, 1.192]\n",
      "13: eta=0.345227 cost=0.2287 jtype=constrained costheta=-0.415 ps=[5.045, 3.629, -0.300, 1.430]\n",
      "14: eta=0.37975 cost=0.2070 jtype=constrained costheta=-0.642 ps=[5.128, 3.417, -0.328, 1.688]\n",
      "15: eta=0.417725 cost=0.1881 jtype=constrained costheta=-0.654 ps=[5.142, 3.151, -0.371, 1.955]\n",
      "16: eta=0.459497 cost=0.1696 jtype=constrained costheta=-0.992 ps=[5.170, 2.828, -0.412, 2.216]\n",
      "17: eta=0.505447 cost=0.1505 jtype=constrained costheta=-0.985 ps=[5.245, 2.450, -0.452, 2.463]\n",
      "18: eta=0.555992 cost=0.1301 jtype=constrained costheta=-0.977 ps=[5.371, 2.015, -0.489, 2.684]\n",
      "19: eta=0.611591 cost=0.1076 jtype=constrained costheta=-0.967 ps=[5.561, 1.523, -0.523, 2.857]\n",
      "20: eta=0.67275 cost=0.0821 jtype=constrained costheta=-0.947 ps=[5.833, 0.987, -0.555, 2.965]\n",
      "21: eta=0.740025 cost=0.0608 jtype=constrained costheta=-0.830 ps=[6.223, 0.442, -0.599, 3.003]\n",
      "22: eta=0.814027 cost=0.0562 jtype=Newton costheta=-0.275 ps=[6.415, 0.379, -0.640, 2.896]\n",
      "23: eta=0.407014 cost=0.0562 jtype=constrained costheta=NaN ps=[6.415, 0.379, -0.640, 2.896]\n",
      "24: eta=0.203507 cost=0.0562 jtype=constrained costheta=NaN ps=[6.415, 0.379, -0.640, 2.896]\n",
      "25: eta=0.223858 cost=0.0558 jtype=constrained costheta=-0.313 ps=[6.464, 0.377, -0.662, 3.092]\n",
      "26: eta=0.246243 cost=0.0556 jtype=constrained costheta=-0.123 ps=[6.466, 0.385, -0.675, 3.315]\n",
      "27: eta=0.270868 cost=0.0554 jtype=constrained costheta=-0.083 ps=[6.463, 0.395, -0.686, 3.561]\n",
      "28: eta=0.297954 cost=0.0552 jtype=constrained costheta=-0.080 ps=[6.461, 0.404, -0.697, 3.832]\n",
      "29: eta=0.148977 cost=0.0552 jtype=constrained costheta=NaN ps=[6.461, 0.404, -0.697, 3.832]\n",
      "30: eta=0.163875 cost=0.0550 jtype=constrained costheta=-0.082 ps=[6.460, 0.408, -0.702, 3.981]\n",
      "31: eta=0.0819375 cost=0.0550 jtype=constrained costheta=NaN ps=[6.460, 0.408, -0.702, 3.981]\n",
      "32: eta=0.0409687 cost=0.0550 jtype=constrained costheta=NaN ps=[6.460, 0.408, -0.702, 3.981]\n",
      "33: eta=0.0204844 cost=0.0550 jtype=constrained costheta=NaN ps=[6.460, 0.408, -0.702, 3.981]\n",
      "34: eta=0.0225328 cost=0.0550 jtype=constrained costheta=-0.280 ps=[6.460, 0.408, -0.703, 4.001]\n",
      "35: eta=0.0247861 cost=0.0550 jtype=Newton costheta=-0.984 ps=[6.460, 0.408, -0.703, 4.001]\n",
      " 72.106185 seconds (262.30 M allocations: 168.069 GB, 13.20% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05733695207051093"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args=[\"vwi\", \"hwi\", \"pro_bias\", \"delay_input\"];\n",
    "goods=[4.0, 4.0, 0.2 ,0.2];\n",
    "bbox = [-10   10;\n",
    "        -10   10;\n",
    "        -4    4;\n",
    "        -4    4]\n",
    "\n",
    "func = (;pars...) -> run_dynamics(;ntrials=100, target1=0.8, target2=0.8, target3=0.8, \n",
    "target4=0.7, target5=0.5, target6=0.7, dt=2, noisefr=0.015, pars...)[1]\n",
    "\n",
    "@time params, trajectory = bbox_Hessian_keyword_minimization(goods, args, bbox, func, verbose=true, \n",
    "start_eta=0.1, tol=1e-12)\n",
    "\n",
    "figure(1); clf();\n",
    "func(; do_plot=true, ntrials=1000, plot_trials=1:10, make_dict(args, params)...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05716030970507975"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(1); ax =subplot(6,1,1)\n",
    "setp(ax, xticks=[])\n",
    "\n",
    "func = (;pars...) -> run_dynamics(;ntrials=100, target1=0.8, target2=0.8, target3=0.8, \n",
    "target4=0.7, target5=0.5, target6=0.7, dt=2, noisefr=0.005, pars...)[1]\n",
    "\n",
    "figure(1); clf();\n",
    "func(; do_plot=true, ntrials=1000, plot_trials=1:10, make_dict(args, params)...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_dict (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_dict(args, x::Vector)\n",
    "    kwargs = Dict();    \n",
    "    for i in [1:length(args);]    \n",
    "        kwargs = merge(kwargs, Dict(Symbol(args[i]) => x[i]))        \n",
    "    end    \n",
    "    return kwargs\n",
    "end \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094960145662674"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(1); clf();\n",
    "func(; do_plot=true, ntrials=10, plot_trials=1:10, delay_period=220, # noisefr=0.005*sqrt(0.5), dt=5, \n",
    "    sigma=0.1, dt=1, noisefr=0,\n",
    "    opto_effect=0.948, \n",
    "    make_dict(args, [6.336, -1.292, 0.274, 0.310])...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: eta=0.022881, cost=0.14007, params=[4.834, 3.819, -0.027, 0.942]\n",
      "GRADIENT\n",
      "[-0.114364,0.0568412,-0.0154793,-0.0819561]\n",
      "RESULTS\n",
      "[0.761156 0.846898 0.80333 0.4524 0.499643 0.322676]\n",
      "*********************\n",
      "*********************\n",
      "200: eta=0.063229, cost=0.10024, params=[5.060, 3.519, 0.006, 1.134]\n",
      "GRADIENT\n",
      "[-0.00649711,0.0379099,-0.00110136,-0.00700344]\n",
      "RESULTS\n",
      "[0.858891 0.92714 0.842813 0.513528 0.576572 0.363587]\n",
      "*********************\n",
      "*********************\n",
      "300: eta=0.004433, cost=0.09502, params=[5.071, 3.340, 0.006, 1.136]\n",
      "GRADIENT\n",
      "[0.0232605,0.0218964,-0.174215,0.0112899]\n",
      "RESULTS\n",
      "[0.882063 0.922636 0.834386 0.537525 0.586192 0.373473]\n",
      "*********************\n",
      "*********************\n",
      "400: eta=0.001994, cost=0.09202, params=[5.084, 3.208, 0.010, 1.117]\n",
      "GRADIENT\n",
      "[0.00322983,0.0184863,-0.0434583,0.00600916]\n",
      "RESULTS\n",
      "[0.894429 0.921359 0.830187 0.539561 0.577592 0.373146]\n",
      "*********************\n",
      "*********************\n",
      "500: eta=0.869254, cost=0.09045, params=[5.097, 3.129, 0.013, 1.100]\n",
      "GRADIENT\n",
      "[-0.00345036,0.0175377,-0.0005442,0.00397192]\n",
      "RESULTS\n",
      "[0.900463 0.921656 0.828494 0.539072 0.572049 0.372945]\n",
      "*********************\n",
      "*********************\n",
      "600: eta=0.007223, cost=0.08874, params=[5.117, 3.038, 0.016, 1.078]\n",
      "GRADIENT\n",
      "[-0.00417318,0.0162511,0.000503934,0.0042294]\n",
      "RESULTS\n",
      "[0.905079 0.921358 0.825621 0.541144 0.569214 0.374992]\n",
      "*********************\n",
      "*********************\n",
      "700: eta=0.442073, cost=0.08732, params=[5.138, 2.960, 0.019, 1.056]\n",
      "GRADIENT\n",
      "[-0.00439248,0.0154162,-0.00060838,0.00451097]\n",
      "RESULTS\n",
      "[0.908489 0.92146 0.823419 0.542567 0.56703 0.377004]\n",
      "*********************\n",
      "*********************\n",
      "800: eta=0.001671, cost=0.08601, params=[5.160, 2.886, 0.022, 1.034]\n",
      "GRADIENT\n",
      "[-0.00475218,0.0148231,-0.000172498,0.0046341]\n",
      "RESULTS\n",
      "[0.911454 0.921859 0.821594 0.543489 0.564941 0.378977]\n",
      "*********************\n",
      "*********************\n",
      "900: eta=0.002704, cost=0.08438, params=[5.191, 2.795, 0.026, 1.004]\n",
      "GRADIENT\n",
      "[-0.00342118,0.0139765,-0.0121751,0.00568148]\n",
      "RESULTS\n",
      "[0.91454 0.922355 0.819216 0.545212 0.563332 0.382136]\n",
      "*********************\n",
      "*********************\n",
      "1000: eta=0.094480, cost=0.08348, params=[5.209, 2.744, 0.028, 0.986]\n",
      "GRADIENT\n",
      "[-0.00517476,0.0139366,-0.000622859,0.00488465]\n",
      "RESULTS\n",
      "[0.91663 0.923187 0.818505 0.544739 0.561174 0.383216]\n",
      "*********************\n",
      "*********************\n",
      "1100: eta=0.008878, cost=0.08207, params=[5.240, 2.663, 0.032, 0.957]\n",
      "GRADIENT\n",
      "[-0.00439132,0.0133894,-0.00819957,0.00559469]\n",
      "RESULTS\n",
      "[0.919153 0.924042 0.816823 0.545693 0.559676 0.38608]\n",
      "*********************\n",
      "*********************\n",
      "1200: eta=0.088563, cost=0.08117, params=[5.261, 2.612, 0.034, 0.938]\n",
      "GRADIENT\n",
      "[-0.0055662,0.0133375,-0.000613561,0.00501994]\n",
      "RESULTS\n",
      "[0.92102 0.924963 0.816173 0.54534 0.557859 0.387474]\n",
      "*********************\n",
      "*********************\n",
      "1300: eta=0.005710, cost=0.07990, params=[5.292, 2.540, 0.038, 0.911]\n",
      "GRADIENT\n",
      "[-0.00631933,0.0131594,0.00354402,0.00470242]\n",
      "RESULTS\n",
      "[0.923429 0.92621 0.815198 0.545228 0.555807 0.389778]\n",
      "*********************\n",
      "*********************\n",
      "1400: eta=0.059697, cost=0.07904, params=[5.314, 2.491, 0.040, 0.892]\n",
      "GRADIENT\n",
      "[-0.00590406,0.0129023,-0.00059665,0.00510338]\n",
      "RESULTS\n",
      "[0.924869 0.926964 0.81444 0.545597 0.554942 0.391648]\n",
      "*********************\n",
      "*********************\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      " in .*(::Float64, ::Array{Float64,1}) at ./arraymath.jl:91",
      " in * at ./operators.jl:138 [inlined]",
      " in #run_dynamics#42(::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Int64, ::Float64, ::Float64, ::Float64, ::Int64, ::Int64, ::Float64, ::Int64, ::Array{Int64,1}, ::Int64, ::Int64, ::Int64, ::Int64, ::Float64, ::Float64, ::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Bool, ::Int64, ::Array{Any,1}, ::#run_dynamics) at ./In[2]:81",
      " in (::#kw##run_dynamics)(::Array{Any,1}, ::#run_dynamics) at ./<missing>:0",
      " in macro expansion; at ./In[5]:27 [inlined]",
      " in anonymous at ./<missing>:?"
     ]
    }
   ],
   "source": [
    "eta = 0.5;\n",
    "\n",
    "params1=[\"vwi\", \"hwi\", \"pro_bias\", \"delay_input\"];\n",
    "params2=[4.0,4.0,0.2,0.2];\n",
    "\n",
    "\n",
    "out = DiffBase.GradientResult(params2)  # out must be same length as whatever we will differentiate w.r.t.\n",
    "keyword_gradient!(out, (;pars...) -> run_dynamics(;pars...)[1], params1, params2)  # note initial values must be floats\n",
    "grad = DiffBase.gradient(out)\n",
    "cost    = DiffBase.value(out)\n",
    "\n",
    "badstuff,results=run_dynamics(vwi=params2[1],hwi=params2[2],pro_bias=params2[3],delay_input=params2[4])\n",
    "\n",
    "\n",
    "\n",
    "i=0; \n",
    "while eta > 1e-6\n",
    "\n",
    "    i=i+1\n",
    "    new_params2 = params2 - eta*grad\n",
    "\n",
    "    out = DiffBase.GradientResult(new_params2)  # out must be same length as whatever we will differentiate w.r.t.\n",
    "    keyword_gradient!(out, (;pars...) -> run_dynamics(;pars...)[1], params1, new_params2)  # note initial values must be floats\n",
    "    grad = DiffBase.gradient(out)\n",
    "    new_cost    = DiffBase.value(out)\n",
    "\n",
    "    new_cost2,new_results=run_dynamics(vwi=new_params2[1],hwi=new_params2[2],pro_bias=new_params2[3],delay_input=new_params2[4])    \n",
    "    if abs(new_cost-new_cost2)>0.0001\n",
    "        println((new_cost-new_cost2)/new_cost)\n",
    "        error(\"yyy\")\n",
    "    end\n",
    "\n",
    "    new_grad=grad;\n",
    "    if new_cost < cost\n",
    "        params2 = new_params2\n",
    "        cost   = new_cost\n",
    "        grad   = new_grad\n",
    "        results = new_results\n",
    "        eta = eta*1.1\n",
    "    else    \n",
    "        eta = eta/2\n",
    "    end\n",
    "\n",
    "\n",
    "    if rem(i, 100)==0\n",
    "        @printf \"%d: eta=%f, cost=%.5f, params=[%.3f, %.3f, %.3f, %.3f]\\n\" i eta cost params2[1] params2[2] params2[3] params2[4]\n",
    "        # println(\"eta\")\n",
    "        # println(eta)\n",
    "        # println(\"cost\")\n",
    "        # println(cost)\n",
    "        # println(\"params\")\n",
    "        # println(params2)\n",
    "        println(\"GRADIENT\")\n",
    "        println(grad)\n",
    "        println(\"RESULTS\")\n",
    "        println(results)\n",
    "        println(\"*********************\")\n",
    "        println(\"*********************\")\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
