{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tired of working with notebooks but having to manually make copies of cells where you define functions so other notebooks or other scripts can use them?  The solution is in this notebook.**\n",
    "\n",
    "This notebook contains the code for \"scraper.jl\", a facility that periodically (every 2 secs) scans jupyter notebooks in a directory, looking within them for code cells that start with a line \"#@include_me filename\". The code in that cell is copied into that filename. (If multiple cells in a notebook use the same #@include_me and filename, they are all appended into that filename.)\n",
    "\n",
    "The system maintain a database of when it last scraped each notebook; scraping of a notebook only runs if the notebook has been modified more recently than its last scraping, which happens infrequently, so the CPU load is very light.\n",
    "\n",
    "To run the system, put it in a directory, make sure that this notebook itself has been scraped into the file scraper.jl (you could run \"scrape_notebook(\"Scraper.ipynb\"; verbose=true)\" to do that), and then, within that directory run\n",
    "\n",
    "shell>  julia scraper.jl &\n",
    "\n",
    "This will do the periodic scraping in the background. All you have to do is to remember to include the first line #@include_me  filename  in cells that you want put into files, the rest is taken care of automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">TABLE OF CONTENTS</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "**Updates to the table of contents are periodic, but run the cell below to first start or force an update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "macro javascript_str(s) display(\"text/javascript\", s); end\n",
    "\n",
    "javascript\"\"\"\n",
    "$.getScript('https://sites.google.com/site/brodylabhome/files/make_table_of_contents.js')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@include_me   scraper.jl\n",
    "\n",
    "using JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that scrapes a single notebook for julia code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scrape_notebook"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me   scraper.jl\n",
    "\n",
    "# Scrape a notebook for julia code that should be written into an indicated file\n",
    "\n",
    "\"\"\"\n",
    "filenames_written = scrape_notebook(notebook_filename; verbose=false, includemagic=\"#@include_me\")\n",
    "\n",
    "Goes through a file notebook_filename, assuming it is an ipynb, and looks for code cells that start with\n",
    "includemagic, followed by whitespace, followed by a string (which we shall call filename). \n",
    "When such a code cell is found, its contents are written into filename.\n",
    "\n",
    "If more than one cell uses the same filename, then the first one starts the file, and subsequent cells\n",
    "append to it.\n",
    "\n",
    "Returns an array with the written filenames\n",
    "\n",
    "\"\"\"\n",
    "function scrape_notebook(notebook_filename; verbose=false, includemagic=\"#@include_me\")\n",
    "\n",
    "    filenames = [];    # List of output files found in this notebook\n",
    "    A = JSON.parse(readstring(notebook_filename))\n",
    "    \n",
    "    for mycell in A[\"cells\"]\n",
    "        if mycell[\"cell_type\"] == \"code\"   \n",
    "            lines = mycell[\"source\"]\n",
    "            if length(lines)>0           # We only consider code cells that are not empty\n",
    "                m= match(Regex(@sprintf(\"(?<include>%s)\\\\s*(?<filename>\\\\S*)\", includemagic)), lines[1])\n",
    "                if typeof(m)!=Void && length(m[\"filename\"])>0  # proceed if we got a match and got a filename\n",
    "                    if any(filenames .== m[\"filename\"]); \n",
    "                        f = open(m[\"filename\"], \"a\")           # we'll append if we already had that filename\n",
    "                        if verbose; @printf(\"Appending to file %s\\n\", m[\"filename\"]); end\n",
    "                    else\n",
    "                        f = open(m[\"filename\"], \"w\")           # otherwise open fresh for writing\n",
    "                        filenames = [filenames ; m[\"filename\"]]\n",
    "                        if verbose; @printf(\"Writing out file %s\\n\", m[\"filename\"]); end\n",
    "                    end\n",
    "                    # Now write out the contents of the cell, with a warning at the top:\n",
    "                    write(f, @sprintf(\"# DON'T MODIFY THIS FILE -- the source is in file %s\\n\\n\", notebook_filename))\n",
    "                    for i=2:length(lines)\n",
    "                        write(f, lines[i])\n",
    "                    end\n",
    "                    write(f, \"\\n\\n\\n\")\n",
    "                    close(f)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return filenames\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out file scraper.jl\n",
      "Appending to file scraper.jl\n",
      "Appending to file scraper.jl\n",
      "Appending to file scraper.jl\n",
      "Appending to file scraper.jl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " \"scraper.jl\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_notebook(\"Scraper.ipynb\"; verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the database of scraped notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me   scraper.jl\n",
    "\n",
    "# Get database of scraped files\n",
    "\n",
    "\"\"\"\n",
    "latest = latest_scrapedict(; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\")\n",
    "\n",
    "Returns a dictionary that maps filenames to strings representing when they were\n",
    "last scraped.  This information is stored in a human-readable text file, scrapedir/scrapefile\n",
    "\n",
    "\"\"\"\n",
    "function latest_scrapedict(; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\")\n",
    "    if !isdir(scrapedir); mkdir(scrapedir); end;\n",
    "    sfile = scrapedir * \"/\" * scrapefile\n",
    "    if !isfile(sfile);\n",
    "        return Dict()\n",
    "    end\n",
    "    \n",
    "    answer = Dict()\n",
    "    try\n",
    "        A = readdlm(sfile, ',')\n",
    "        for i=1:size(A,1)\n",
    "            get!(answer, lstrip(A[i,2]), A[i,1])\n",
    "        end\n",
    "    catch\n",
    "        answer = Dict()\n",
    "    end\n",
    "    return answer\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "write_scrapedict(latest; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\")\n",
    "\n",
    "Writes a dictionary containing filename-latest_scrape_time_string pairs into a file\n",
    "\n",
    "\"\"\"\n",
    "function write_scrapedict(latest; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\")\n",
    "\n",
    "    sfile = scrapedir * \"/\" * scrapefile\n",
    "    sf = open(sfile, \"w\")\n",
    "    for k in keys(latest)\n",
    "        write(sf, @sprintf(\"%s, %s\\n\", latest[k], k))\n",
    "    end\n",
    "    close(sf)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latest_scrapedict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over all notebooks in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me   scraper.jl\n",
    "\n",
    "# Go through all notebooks in directory and scrape them if they've been modified after their last\n",
    "# scrape time.\n",
    "\n",
    "\"\"\"\n",
    "rescraped = scrape_all_notebooks(; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\", verbose=false)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function scrape_all_notebooks(; scrapedir=\".scrapedir\", scrapefile=\"scrapelist\", verbose=false)\n",
    "\n",
    "    latest = latest_scrapedict(scrapedir=scrapedir, scrapefile=scrapefile)\n",
    "\n",
    "    rescraped = []\n",
    "    for f in filter(x -> endswith(x, \".ipynb\"), readdir())\n",
    "        if ~haskey(latest, f) || DateTime(latest[f]) < Dates.unix2datetime(stat(f).mtime) - Dates.Hour(4)\n",
    "            if verbose; @printf(\"Will look into notebook %s\\n\", f); end\n",
    "            rescraped = [rescraped; f]\n",
    "            scrape_notebook(f)\n",
    "            if haskey(latest, f)\n",
    "                latest[f] = string(now())\n",
    "            else\n",
    "                get!(latest, f, string(now()))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    write_scrapedict(latest; scrapedir=scrapedir, scrapefile=scrapefile)\n",
    "    \n",
    "    return rescraped\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrape_all_notebooks(; verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periodically run yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@include_me  scraper.jl\n",
    "\n",
    "function scraperobot()\n",
    "    while true\n",
    "        scrape_all_notebooks()\n",
    "        sleep(2)\n",
    "    end\n",
    "end\n",
    "\n",
    "scraperobot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
