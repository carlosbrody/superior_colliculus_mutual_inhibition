{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUNNING AND OPTIMIZING PRO_ANTI**\n",
    "\n",
    "The definition of the ProAnti network, as well functions to run it and evaluate the cost of a set of runs, get extracted into\n",
    "\n",
    "    pro_anti.jl\n",
    "    \n",
    "At that point we're reaching current development as opposed to stable files.\n",
    "One cell, an example of running farm F, gets extracted into\n",
    "\n",
    "    farming.jl\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">TABLE OF CONTENTS</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "**Updates to the table of contents are periodic, but run the cell below to first start or force an update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('make_table_of_contents.js')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "macro javascript_str(s) display(\"text/javascript\", s); end\n",
    "\n",
    "javascript\"\"\"\n",
    "$.getScript('make_table_of_contents.js')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProAnti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backwardsModel"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me pro_anti.jl\n",
    "\n",
    "include(\"rate_networks.jl\")  # that will also include genera_utils.jl, constrained_parabolic_minimization.jl, and hessian_utils.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_PA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me  pro_anti.jl\n",
    "\n",
    "\"\"\"\n",
    "    plot_PA(t, U, V; fignum=1, clearfig=true, rule_and_delay_period=1, target_period=1, post_target_period=1,\n",
    "        other_unused_params...)\n",
    "\n",
    "Helper function for plotting ProAnti results. Given a time axia and nunits-by-nsteps U and V matrices, will \n",
    "plot them (first clearing the figure if clearfig=true but overlaying if clearfig=false) in three vertically-\n",
    "arranged subplots. The top one has V as a function of time, with the two Pro units in blues and the two Anti \n",
    "units in reds, dark colors for the left side of the brain, light colors for the right.  The middle subplot\n",
    "has Us. And the bottom subplot shows the difference between the two Pro units as a function of time.\n",
    "\n",
    "\"\"\"\n",
    "function plot_PA(t, U, V; fignum=1, clearfig=true, rule_and_delay_period=1, target_period=1, post_target_period=1,\n",
    "    other_unused_params...)\n",
    "    figure(fignum)\n",
    "    if clearfig; clf(); end\n",
    "    \n",
    "    ax1 = subplot(3,1,1)\n",
    "    h = plot(t, V'); \n",
    "    setp(h[1], color=[0, 0, 1])\n",
    "    setp(h[2], color=[1, 0, 0])\n",
    "    setp(h[3], color=[1, 0.5, 0.5])\n",
    "    setp(h[4], color=[0, 1, 1])\n",
    "    ylabel(\"V\")\n",
    "\n",
    "    ax = gca()\n",
    "    oldlims = [ylim()[1]+0.1, ylim()[2]-0.1]\n",
    "    ylim(minimum([V[:];oldlims[1]])-0.1, maximum([V[:];oldlims[2]])+0.1)\n",
    "    yl = [ylim()[1], ylim()[2]]\n",
    "    vlines([rule_and_delay_period, \n",
    "            rule_and_delay_period+target_period,\n",
    "            rule_and_delay_period+target_period+post_target_period], \n",
    "            -0.05, 1.05, linewidth=2)\n",
    "    if yl[1]<0.02\n",
    "        yl[1] = -0.02\n",
    "    end\n",
    "    if yl[2]>0.98\n",
    "        yl[2] = 1.02\n",
    "    end\n",
    "    ylim(yl)\n",
    "    grid(true)\n",
    "    remove_xtick_labels(ax1)\n",
    "        \n",
    "    ax2 = subplot(3,1,2)\n",
    "    hu = plot(t, U')\n",
    "    oldlims = [ylim()[1]+0.1, ylim()[2]-0.1]\n",
    "    ylim(minimum([U[:];oldlims[1]])-0.1, maximum([U[:];oldlims[2]])+0.1)\n",
    "    setp(hu[1], color=[0, 0, 1])\n",
    "    setp(hu[2], color=[1, 0, 0])\n",
    "    setp(hu[3], color=[1, 0.5, 0.5])\n",
    "    setp(hu[4], color=[0, 1, 1])\n",
    "    ylabel(\"U\"); \n",
    "    vlines([rule_and_delay_period, \n",
    "            rule_and_delay_period+target_period,\n",
    "            rule_and_delay_period+target_period+post_target_period], \n",
    "            ylim()[1], ylim()[2], linewidth=2)\n",
    "    remove_xtick_labels(ax2)\n",
    "\n",
    "    grid(true)\n",
    "    \n",
    "    subplot(3,1,3)\n",
    "    delta = V[1,:] - V[4,:]\n",
    "    hr = plot(t, delta)\n",
    "    oldlims = [ylim()[1]+0.1, ylim()[2]-0.1]\n",
    "    ylim(minimum([delta[:];oldlims[1]])-0.1, maximum([delta[:];oldlims[2]])+0.1)\n",
    "    vlines([rule_and_delay_period, \n",
    "            rule_and_delay_period+target_period,\n",
    "            rule_and_delay_period+target_period+post_target_period], \n",
    "            ylim()[1], ylim()[2], linewidth=2)\n",
    "    xlabel(\"t\"); ylabel(\"Pro R - Pro L\")\n",
    "    grid(true)\n",
    "        \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing symbols in opto times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parse_opto_times"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me   pro_anti.jl\n",
    "\n",
    "\"\"\"\n",
    "parsed_times = parse_opto_times(opto_times, model_params)\n",
    "\n",
    "This function takes period specified with symbols and turns them into times in secs. Each element in the \n",
    "opto_times parameter can be a number (time in secs) or a string. This string will be parsed and\n",
    "evaluated. Four special symbols are available: trial_start (which is really zero), target_start, \n",
    "target_end, and trial_end.  To compute these, IT IS ASSUMED that model_params will contain entries\n",
    "for :rule_and_delay_period, :target period, and :post_target_period\n",
    "\n",
    "In addition, for backwards compatibility with Alex's code, some numbers are special:\n",
    "20 means end of trial (but we prefer the string \"trial_end\"), 100 mens end of rule and delay (but we prefer\n",
    "\"target_start\", and 200 means end of target (we prfer \"target_end\").\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "* opto_times, an n-by-2 matrix where each row of the matrix specifies af starting time and an ending time. Entries can be numbers or strings representing expressions to be evaluated.\n",
    "\n",
    "* model_params  a Dict which must contain key-value pairs with the keys :rule_and_delay_period, :target_period, and :post_target_period\n",
    "\n",
    "# RETURNS\n",
    "\n",
    "* a matrix the same size as opto_times, but with all strings parsed and evaluated.\n",
    "\n",
    "# EXAMPLE\n",
    "\n",
    "> model_params[:target_period] = 1  ; model_params[:rule_and_delay_period] = 1\n",
    "> opto_times = [\"exp(target_end)\" 3; 6 8]\n",
    "> parse_opto_times(opto_times, model_params)\n",
    "\n",
    "7.38906   3\n",
    " 6         8\n",
    "\n",
    "\"\"\"\n",
    "function parse_opto_times(opto_times2, model_params)\n",
    "    # Make a copy so we don't futz with the original:\n",
    "    opto_times = copy(opto_times2)\n",
    "    # we want to be able to stash floats and numbers in by the end:\n",
    "    if typeof(opto_times)<:Array{String}\n",
    "        opto_times = convert(Array{Any}, opto_times)\n",
    "    end\n",
    "\n",
    "    \n",
    "    # Let's define the time markers\n",
    "    trial_start = target_start = target_end = trial_end = 0   # just define them here so vars are available ourside try/catch\n",
    "    try\n",
    "        trial_start  = 0\n",
    "        target_start = model_params[:rule_and_delay_period]\n",
    "        target_end   = target_start + model_params[:target_period]\n",
    "        trial_end    = target_end   + model_params[:post_target_period]\n",
    "    catch y\n",
    "        @printf(\"\\n\\nwhoa, are you sure your model_params had all three of :rule_and_delay_period, :target_period, and :post_target_period?\\n\\n\")\n",
    "        error(y)\n",
    "    end\n",
    "    \n",
    "    function replacer(P)   # run through an expression tree, replacing known symbols with their values, then evaluate\n",
    "        if typeof(P)<:Symbol\n",
    "            if P == :trial_start;  P = trial_start; end;                    \n",
    "            if P == :target_start; P = target_start; end;                    \n",
    "            if P == :target_end;   P = target_end; end;                    \n",
    "            if P == :trial_end;    P = trial_end; end;                    \n",
    "            return P\n",
    "        end        \n",
    "        for i=1:length(P.args)\n",
    "            if typeof(P.args[i])<:Expr\n",
    "                P.args[i] = replacer(P.args[i])\n",
    "            else\n",
    "                if P.args[i] == :trial_start;  P.args[i] = trial_start; end;                    \n",
    "                if P.args[i] == :target_start || P.args[i]==100;  P.args[i] = target_start; end;                    \n",
    "                if P.args[i] == :target_end   || P.args[i]==200;  P.args[i] = target_end; end;                    \n",
    "                if P.args[i] == :trial_end    || P.args[i]==20;   P.args[i] = trial_end; end;                    \n",
    "            end\n",
    "        end\n",
    "        return eval(P)\n",
    "    end\n",
    "    \n",
    "    for i=1:length(opto_times)\n",
    "        if typeof(opto_times[i])==String\n",
    "            # @printf(\"Got a string, and it is: %s\\n\", opto_times[i])\n",
    "            # @printf(\"Parsing turned it into: \");  print(parse(opto_times[i])); print(\"\\n\")\n",
    "            # @printf(\"Replacer turned it into: \"); print(replacer(parse(opto_times[i]))); print(\"\\n\")\n",
    "            opto_times[i] = replacer(parse(opto_times[i]))\n",
    "        elseif typeof(opto_times[i])==Int64\n",
    "            if opto_times[i]==100; opto_times[i] = target_start; end;\n",
    "            if opto_times[i]==200; opto_times[i] = target_end;   end;\n",
    "            if opto_times[i]==20;  opto_times[i] = trial_end;    end;\n",
    "        end            \n",
    "    end\n",
    "    return opto_times\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of parsing symbols in opto times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Any,2}:\n",
       " 7.38906   3\n",
       " 6         8\n",
       " 9        10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mp = Dict(:target_period=>1, :rule_and_delay_period=>1, :post_target_period=>0.5)\n",
    "\n",
    "opto_times = [\"exp(target_end)\" 3; 6 8; 9 10]\n",
    "\n",
    "parse_opto_times(opto_times, mp)\n",
    "\n",
    "# Or, using, Alex's special time codes:\n",
    "#\n",
    "# opto_times = [100 5]\n",
    "# parse_opto_times(opto_times, mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opto_times[1]==100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining default model params, and make_input() and run_ntrials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_ntrials"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me  pro_anti.jl\n",
    "\n",
    "model_params = Dict(\n",
    ":dt     =>  0.02,    # timestep, in secs\n",
    ":tau    =>  0.1,     # tau, in ms\n",
    ":vW     =>  -1.7,    # vertical weight\n",
    ":hW     =>  -1.7,    # horizontal weight\n",
    ":sW     =>  0.2,     # self-connection weight\n",
    ":dW     =>  0,       # diagonal weight\n",
    ":nsteps =>  2,       # number of timesteps in the simulation\n",
    ":noise  =>  [],      # noise added during simulation. Can be empty matrix, or an nunits-by-nsteps matrix\n",
    ":sigma  =>  0.08,    # standard deviation of Gaussian noise added (will be scaled by sqrt(dt) to be relatively dt-INsensitive)\n",
    ":input  =>  0,       # input current. Can be scalar, nunits-by-1, or nunits-by-nsteps matrix\n",
    ":g_leak =>  0.25,    # leak conductance\n",
    ":U_rest =>  -1,      # resting membrane potential\n",
    ":theta  =>  1,       # inverse slope of g() function\n",
    ":beta   =>  1,       # offset to g() function\n",
    ":constant_excitation      => 0.19,   # constant input, added to all units at all timesteps\n",
    ":anti_rule_strength       => 0.1,    # input added only to anti units during rule_and_delay_period in Anti trials\n",
    ":pro_rule_strength        => 0.1,    # input added only to pro units during rule_and_delay_period in Pro trials\n",
    ":const_pro_bias           => 0,      # input added only to pro units during all times in all trial types\n",
    ":target_period_excitation => 0.2,      # input added to all units during target_period\n",
    ":right_light_excitation   => 0.3,    # input added to the Anti and the Pro unit on one side during the target_period\n",
    ":right_light_pro_extra    => 0,      # input added to the right side Pro unit alone during the target_period\n",
    ":rule_and_delay_period    => 0.4,    # duration of rule_and_delay_period, in secs\n",
    ":target_period            => 0.1,    # duration of target_period, in secs\n",
    ":post_target_period       => 0.5,    # duration of post_target_period, in secs\n",
    ":const_add => 0,  # from rate_networks.jl, unused here\n",
    ":init_add  => 0,  # from rate_networks.jl, unused here \n",
    ":opto_strength            => 1,      # fraction by which to scale V outputs\n",
    ":opto_times               => [],     # n-by-2 matrix, indicating start and stop times for opto_strength effect, all within the same trial\n",
    ":opto_units               => 1:4,    # ids of the units that will be affected by opto_strength effect\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input, t, nsteps = make_input(trial_type; dt=0.02, nderivs=0, difforder=0, constant_excitation=0.19, anti_rule_strength=0.1, \n",
    "    pro_rule_strength=0.1, target_period_excitation=1, right_light_excitation=0.5, right_light_pro_extra=0, \n",
    "    rule_and_delay_period=0.4, target_period=0.1, post_target_period=0.4, const_pro_bias=0,\n",
    "    other_unused_params...)\n",
    "\"\"\"\n",
    "function make_input(trial_type; dt=0.02, nderivs=0, difforder=0, constant_excitation=0.19, anti_rule_strength=0.1, \n",
    "    pro_rule_strength=0.1, target_period_excitation=1, right_light_excitation=0.5, right_light_pro_extra=0, \n",
    "    rule_and_delay_period=0.4, target_period=0.1, post_target_period=0.4, const_pro_bias=0,\n",
    "    other_unused_params...)\n",
    "\n",
    "    T = rule_and_delay_period + target_period + post_target_period\n",
    "    t = 0:dt:T\n",
    "    nsteps = length(t)\n",
    "\n",
    "    input = constant_excitation + ForwardDiffZeros(4, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    if trial_type==\"Anti\"\n",
    "        input[2:3, t.<rule_and_delay_period] += anti_rule_strength\n",
    "    elseif trial_type==\"Pro\"\n",
    "        input[[1,4], t.<rule_and_delay_period] += pro_rule_strength\n",
    "    else\n",
    "        error(\"make_input: I don't recognize input type \\\"\" * trial_type * \"\\\"\")\n",
    "    end\n",
    "    \n",
    "    input[:,     (rule_and_delay_period.<=t) & (t.<rule_and_delay_period+target_period)] += target_period_excitation\n",
    "    input[1:2,   (rule_and_delay_period.<=t) & (t.<rule_and_delay_period+target_period)] += right_light_excitation\n",
    "    input[1,     (rule_and_delay_period.<=t) & (t.<rule_and_delay_period+target_period)] += right_light_pro_extra\n",
    "    \n",
    "    input[[1,4],:] += const_pro_bias\n",
    "    \n",
    "    return input, t, nsteps\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "proVs, antiVs, pro_fullV, anti_fullV, opto_fraction, pro_input, anti_input = \n",
    "    run_ntrials(nPro, nAnti; plot_list=[], start_pro=[-0.5,-0.5,-0.5,-0.5], start_anti=[-0.5,-0.5,-0.5,-0.5],\n",
    "        profig=1, antifig=2,\n",
    "        opto_units = 1:4, nderivs=0, difforder=0, model_params...)\n",
    "\n",
    "Runs a set of proAnti model trials.  See model_params above for definition of all the parameters. In addition,\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "- nPro    number of Pro tials to run\n",
    "\n",
    "- nAnti   number of Anti trials to run\n",
    "\n",
    "# OPTIONAL PARAMETERS\n",
    "\n",
    "- plot_list    A list of trials to plot on the figures. If empty nothing is plotted\n",
    "\n",
    "- profig       The figure number on which Pro traces will be drawn\n",
    "\n",
    "- antifig      The figure number on which Anti traces will be drawn\n",
    "\n",
    "- start_pro    A 4-by-1 vector of starting U values on Pro trials for the 4 units\n",
    "\n",
    "- start_anti   A 4-by-1 vector of starting U values on Anti trials for the 4 units\n",
    "\n",
    "- nderivs      For ForwardDiff\n",
    "\n",
    "- difforder    For ForwardDiff\n",
    "\n",
    "- model_params   Further optional params, will be passed onto forwardModel() (e.g., opto times)\n",
    "\n",
    "\n",
    "# RETURNS\n",
    "\n",
    "- proVs    final V for the four units on Pro trials\n",
    "\n",
    "- antiVs   final V for the four units on Anti trials\n",
    "\n",
    "- pro_fullVs   all Vs, across all times, for all Pro trials (4-by-nsteps-by-nPro)\n",
    "\n",
    "- anti_fullVs  all Vs, across all times, for all Anti trials (4-by-nsteps-by-nAnti)\n",
    "\n",
    "\"\"\"\n",
    "function run_ntrials(nPro, nAnti; plot_list=[], start_pro=[-0.5,-0.5,-0.5,-0.5], start_anti=[-0.5,-0.5,-0.5,-0.5],\n",
    "    profig=1, antifig=2,\n",
    "    opto_units = 1:4, nderivs=0, difforder=0, model_params...)\n",
    "    \n",
    "    pro_input,  t, nsteps = make_input(\"Pro\" ; nderivs=nderivs, difforder=difforder, model_params...)\n",
    "    anti_input, t, nsteps = make_input(\"Anti\"; nderivs=nderivs, difforder=difforder, model_params...)\n",
    "    \n",
    "    model_params = Dict(model_params)\n",
    "    sW = model_params[:sW]\n",
    "    hW = model_params[:hW]\n",
    "    vW = model_params[:vW]\n",
    "    dW = model_params[:dW]\n",
    "    model_params = make_dict([\"nsteps\", \"W\"], [nsteps, [sW vW dW hW; vW sW hW dW; dW hW sW vW; hW dW vW sW]], \n",
    "        model_params)\n",
    "    model_params = make_dict([\"nderivs\", \"difforder\"], [nderivs, difforder], model_params)\n",
    "    model_params[:opto_times] = parse_opto_times(model_params[:opto_times], model_params)\n",
    "    \n",
    "    proVs  = ForwardDiffZeros(4, nPro, nderivs=nderivs, difforder=difforder)\n",
    "    antiVs = ForwardDiffZeros(4, nAnti, nderivs=nderivs, difforder=difforder)\n",
    "    proVall  = zeros(4, nsteps, nPro);\n",
    "    antiVall = zeros(4, nsteps, nAnti);\n",
    "    \n",
    "    # --- PRO ---\n",
    "    if length(plot_list)>0; figure(profig); clf(); end\n",
    "    model_params = make_dict([\"input\"], [pro_input], model_params)\n",
    "    for i=1:nPro\n",
    "        Uend, Vend, pro_fullU, proVall[:,:,i] = forwardModel(start_pro, do_plot=false, opto_units=opto_units; model_params...)\n",
    "        proVs[:,i] = Vend\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, pro_fullU, proVall[:,:,i]; fignum=profig, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"PRO\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- ANTI ---\n",
    "    if length(plot_list)>0; figure(antifig); clf(); end\n",
    "    model_params = make_dict([\"input\"], [anti_input], model_params)\n",
    "    for i=1:nAnti\n",
    "        startU = [-0.5, -0.5, -0.5, -0.5]\n",
    "        Uend, Vend, anti_fullU, antiVall[:,:,i] = forwardModel(start_anti, do_plot=false, opto_units=opto_units; model_params...)\n",
    "        antiVs[:,i] = Vend\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, anti_fullU, antiVall[:,:,i]; fignum=antifig, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"ANTI\")\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    if haskey(model_params, :opto_fraction)\n",
    "        opto_fraction = model_params[:opto_fraction]\n",
    "    else\n",
    "        opto_fraction = 1\n",
    "    end\n",
    "    \n",
    "    return proVs, antiVs, proVall, antiVall, opto_fraction, pro_input, anti_input\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- work in progress -- plotting runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> This was farm_LA0001.mat"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition plot_farm(Any) in module Main at In[11]:4 overwritten at In[12]:6.\n",
      "WARNING: Method definition histoit(Any) in module Main at In[11]:25 overwritten at In[12]:27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "STDIN> q\n"
     ]
    }
   ],
   "source": [
    "#@include_me  farm_plotting_carlos.jl\n",
    "\n",
    "# for fname in filter(x -> startswith(x, \"farm_\"), readdir(\"goodfarms\"))\n",
    "\n",
    "function plot_farm(fname)\n",
    "    model_params, F, nPro, nAnti = load_run(fname, farmdir=\"goodfarms\");\n",
    "\n",
    "    # proFullVs = Array{Array{Float64}}(3,1)\n",
    "\n",
    "    proVs, antiVs, proFullVs, antiFullVs = \n",
    "          run_ntrials(10, 10; plot_list=[1:10;], opto_times=model_params[:opto_periods][1,:], model_params...);\n",
    "    figure(1); subplot(3,1,1); title(\"PRO -- control\")\n",
    "    figure(2); subplot(3,1,1); title(\"ANTI -- control\")\n",
    "    proVs, antiVs, proFullVs, antiFullVs = \n",
    "          run_ntrials(10, 10; plot_list=[1:10;], opto_times=model_params[:opto_periods][4,:], \n",
    "            profig=3, antifig=4, model_params...);\n",
    "    figure(3); subplot(3,1,1); title(\"PRO -- delay\")\n",
    "    figure(4); subplot(3,1,1); title(\"ANTI -- delay\")\n",
    "    proVs, antiVs, proFullVs, antiFullVs = \n",
    "          run_ntrials(10, 10; plot_list=[1:10;], opto_times=model_params[:opto_periods][5,:], \n",
    "            profig=5, antifig=6, model_params...);\n",
    "    figure(5); subplot(3,1,1); title(\"PRO -- choice\")\n",
    "    figure(6); subplot(3,1,1); title(\"ANTI -- choice\")\n",
    "end\n",
    "\n",
    "function histoit(F)\n",
    "    hP = zeros(5,1)\n",
    "    hA = zeros(5,1)\n",
    "\n",
    "    for i=1:5,\n",
    "        VR = F[\"runs_pro\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_pro\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hP[i] = mean(sign(VR-VL))\n",
    "\n",
    "        VR = F[\"runs_anti\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_anti\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hA[i] = mean(sign(VL-VR))\n",
    "    end\n",
    "    figure(7); clf()\n",
    "    bar(1:3, hP[[1,4,5]], 0.25)\n",
    "    bar((1:3)+0.25, hA[[1,4,5]], 0.25)\n",
    "end\n",
    "\n",
    "pygui(true)\n",
    "\n",
    "for resname in filter(x -> startswith(x, \"res_\"), readdir(\"../for_carlos_without_runs/goodfarms\"))\n",
    "    F = matread(\"../for_carlos_without_runs/goodfarms/\" * resname)\n",
    "    histoit(F)\n",
    "    fname = F[\"orig_file\"]\n",
    "    plot_farm(fname)\n",
    "    \n",
    "    @printf(\"==> This was %s\\n\\n\", fname)\n",
    "    q = readline()\n",
    "    if startswith(q, \"q\") || startswith(q, \"Q\")\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition histoit(Any) in module Main at In[130]:25 overwritten at In[132]:6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "histoit (generic function with 1 method)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [\"control\", \"full\", \"rule\", \"delay\", \"choice\"]\n",
    "\n",
    "F = matread(\"../for_carlos_without_runs/goodfarms/res_0005.mat\")\n",
    "\n",
    "function histoit(F)\n",
    "    hP = zeros(5,1)\n",
    "    hA = zeros(5,1)\n",
    "\n",
    "    for i=1:5,\n",
    "        VR = F[\"runs_pro\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_pro\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hP[i] = mean(sign(VR-VL))\n",
    "\n",
    "        VR = F[\"runs_anti\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_anti\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hA[i] = mean(sign(VL-VR))\n",
    "    end\n",
    "    figure(7); clf()\n",
    "    bar(1:3, hP[1,4,5], 0.25)\n",
    "    bar((1:3)+0.25, hA[1,4,5], 0.25)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF = load_run(\"farm_LA0003\", farmdir=\"../for_carlos_without_runs/goodfarms\")[1];\n",
    "\n",
    "FF[:post_target_periods]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.316"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "        VR = F[\"runs_pro\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_pro\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hP[i] = mean(sign(VR-VL))\n",
    "\n",
    "        VR = F[\"runs_anti\"][:,end,:,i,1][1,:]\n",
    "        VL = F[\"runs_anti\"][:,end,:,i,1][4,:]\n",
    "\n",
    "        hA[i] = mean(sign(VL-VR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(10); clf();\n",
    "plot(F[\"runs_anti\"][1,:,1:10,1,1], \"r\");\n",
    "plot(F[\"runs_anti\"][4,:,1:10,1,1], \"b\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of running run_ntrials() with opto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pygui(true)\n",
    "nPro = 10; nAnti = 5;\n",
    "\n",
    "# middle fifth of target period:\n",
    "opto_times = [\"target_start + 0.4*(target_end-target_start)\"  \"target_start + 0.6*(target_end-target_start)\"]\n",
    "\n",
    "# middle third of rule and delay\n",
    "opto_times = [\"0.333*target_start\"  \"0.666*target_start\"]\n",
    "\n",
    "my_params = merge(model_params, Dict(:opto_strength=>0.01, :opto_times=>opto_times))\n",
    "\n",
    "proVs, antiVs, pro_fullV, anti_fullV, opto_strength, pro_input, anti_input = \n",
    "    @time(run_ntrials(nPro, nAnti; plot_list=[1:5;], my_params...))\n",
    "\n",
    "@printf(\"Pro %% correct = %g%%\\n\", 100*length(find(proVs[1,:].>proVs[4,:]))/nPro)\n",
    "@printf(\"Anti %% correct = %g%% \\n\", 100*length(find(antiVs[1,:].<antiVs[4,:]))/nAnti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opto_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining JJ(), the cost function\n",
    "\n",
    "Below is a cost function `JJ()` with two terms. Let $C$ be the target fraction \"Go Right\" trials, and $V_R$ and $V_L$ represent the final value of the $V$ variable for the \"Pro Go Right\" and \"Pro Go Left\" units, respectively.\n",
    "\n",
    "$$\n",
    "cost_1 = \\left( \\left\\langle \\frac{1}{2} + \\frac{1}{2}\\tanh(\\frac{V_R - V_L}{\\theta_1}) \\right\\rangle_{trials} - C \\right)^2\n",
    "$$\n",
    "\n",
    "In the limit of $\\theta_1$ very small, the network's ouput is binarized, decisions go like the sign of $V_R-V_L$, and this cost function is minimized at the desired fraction correct. However, the perfectly binary network is not differentiable. So we keep $\\theta1$ smal but non-zero.\n",
    "\n",
    "To try to make sure that output decisions are clear, we have another component to the cost function\n",
    "\n",
    "$$\n",
    "cost_2 = - \\left\\langle \\left( \\tanh(\\frac{V_R - V_L}{\\theta_2}) \\right)^2 \\right \\rangle_{trials}\n",
    "$$\n",
    "\n",
    "This component is minimized when the difference between $V_R$ and $V_L$ is large, but if differences are much bigger than $\\theta_2$, it stops caring about them.\n",
    "\n",
    "We've been using a cost function that is a combination of the two:\n",
    "\n",
    "$$\n",
    "J_{\\rm total} = cost_1 + \\beta \\cdot cost_2\n",
    "$$\n",
    "\n",
    "Meaning our total cost function has three parameters, $\\theta_1$, $\\theta_2$, and $\\beta$, which is a bit of a mess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(1); clf();\n",
    "th1 = 0.05\n",
    "th2 = 0.25\n",
    "b   = 0.01\n",
    "C   = 0.7\n",
    "\n",
    "p   = 1\n",
    "\n",
    "vrmvl = -1:0.01:1\n",
    "cost1 = (0.5 + 0.5*tanh(vrmvl/th1) - C).^2\n",
    "cost2 = -tanh((vrmvl/th2).^p).^2\n",
    "\n",
    "ax1 = subplot(3,1,1); plot(vrmvl, cost1)\n",
    "remove_xtick_labels(ax1)\n",
    "ylabel(\"cost_1\")\n",
    "title(\"single-trial cost_1, shown here, not so meaningful\")\n",
    "\n",
    "ax2 = subplot(3,1,2); plot(vrmvl, cost2)\n",
    "remove_xtick_labels(ax2)\n",
    "ylabel(\"cost_2\")\n",
    "\n",
    "ax3 = subplot(3,1,3); plot(vrmvl, cost1 + b*cost2)\n",
    "xlabel(\"V_R - V_L\")\n",
    "ylabel(\"cost_1 + beta*cost_2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JJ"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me  pro_anti.jl\n",
    "\n",
    "\"\"\"\n",
    "cost, cost1s, cost2s, hP, hA, dP, dA, hBP, hBA = JJ(nPro, nAnti; pro_target=0.9, anti_target=0.7, \n",
    "    opto_targets = Array{Float64}(2,0), opto_periods = Array{Float64}(2,0), \n",
    "    model_details = false,\n",
    "    theta1=0.025, theta2=0.035, cbeta=0.003, verbose=false, \n",
    "    pre_string=\"\", zero_last_sigmas=0, seedrand=NaN, \n",
    "    rule_and_delay_periods = [0.4], target_periods = [0.1], post_target_periods = [0.5],\n",
    "    plot_conditions=false, plot_list = [],\n",
    "    nderivs=0, difforder=0, model_params...)\n",
    "\n",
    "Runs a proAnti network, if desired across multiple opto conditions and multiple period durations and returns\n",
    "resulting cost\n",
    "\n",
    "# PARAMETERS (INCOMPLETE DOCS!!!):\n",
    "\n",
    "??\n",
    "\n",
    "# RETURNS (INCOMPLETE DOCS!!!):\n",
    "\n",
    "- cost   The net cost, composed of squared error cost (promoting performance close to the desired one) plus difference cost (promoting Pro_R and Pro_L differences at the end of the trial)\n",
    "\n",
    "- cost1s  A vector, for each opto condition, the squared error cost\n",
    "\n",
    "- cost2s  for each opto condition, the differences costc\n",
    "\n",
    "- hP     Pro \"hits\", as computed with the theta1 sigmoid\n",
    "    \n",
    "- hA     Anti \"hits\"\n",
    "\n",
    "- dP     Pro \"diffs\", as computed with the theta2 sigmoid\n",
    "    \n",
    "- dA     Anti \"diffs\"\n",
    "\n",
    "- hBP    Pro binarized hits, as computed by binarizing (equivalent to theta1->0)\n",
    "    \n",
    "- hBA    Anti binarized hits\n",
    "\n",
    "If model_details is set to true, also returns proValls, antiValls, opto_fraction, pro_input, anti_input\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function JJ(nPro, nAnti; pro_target=0.9, anti_target=0.7, \n",
    "    opto_targets = Array{Float64}(2,0), opto_periods = Array{Float64}(2,0), \n",
    "    model_details = false,\n",
    "    theta1=0.025, theta2=0.035, cbeta=0.003, verbose=false, \n",
    "    pre_string=\"\", zero_last_sigmas=0, seedrand=NaN, \n",
    "    rule_and_delay_periods = [0.4], target_periods = [0.1], post_target_periods = [0.5],\n",
    "    plot_conditions=false, plot_list = [],\n",
    "    nderivs=0, difforder=0, model_params...)\n",
    "\n",
    "    \n",
    "    \n",
    "    if size(opto_targets,1)==0  || size(opto_periods,1)==0 # if there's no opto that is being asked for\n",
    "        # Then tun with only a single opto_period request, with no opto, and control targets as our targets\n",
    "        opto_targets = [pro_target anti_target]\n",
    "        opto_periods = [-1, -1]   # opto effect is before time zero, i.e., is nothing\n",
    "    end\n",
    "    \n",
    "    if ~(size(opto_targets) == size(opto_periods)); \n",
    "        error(\"opto parameters are bad -- need a Pro and Anti performance target for each requested period\"); \n",
    "    end\n",
    "\n",
    "    noptos     = size(opto_periods,1)  # of opto conditions\n",
    "    nruns_each = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)    # runs per opto condition\n",
    "    nruns      = nruns_each*noptos  # total conditions\n",
    "    \n",
    "    cost1s = ForwardDiffZeros(noptos, nruns, nderivs=nderivs, difforder=difforder)\n",
    "    cost2s = ForwardDiffZeros(noptos, nruns, nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "    hP  = zeros(noptos, nruns_each);   # Pro \"hits\", as computed with the theta1 sigmoid\n",
    "    hA  = zeros(noptos, nruns_each);   # Anti \"hits\"\n",
    "    dP  = zeros(noptos, nruns_each);   # Pro \"diffs\", as computed with the theta2 sigmoid\n",
    "    dA  = zeros(noptos, nruns_each);   # Anti \"diffs\"\n",
    "    hBP = zeros(noptos, nruns_each);   # Pro binarized hits, as computed by binarizing (equivalent to theta1->0)\n",
    "    hBA = zeros(noptos, nruns_each);   # Anti binarized hits\n",
    "\n",
    "    proValls         = [];\n",
    "    antiValls        = [];\n",
    "    opto_fraction    = [];\n",
    "    pro_input        = [];\n",
    "    anti_input       = [];\n",
    "    \n",
    "    for nopto=1:noptos # iterate over each opto inactivation period\n",
    "        \n",
    "        # reset random number generator for each opto period, so it cant over fit noise samples\n",
    "        if ~isnan(seedrand); srand(seedrand); end\n",
    "\n",
    "        n = 0  # n is a counter over all period duration conditions\n",
    "        totHitsP = totHitsA = totDiffsP = totDiffsA = 0\n",
    "        for i in rule_and_delay_periods\n",
    "            for j in target_periods\n",
    "                for k = post_target_periods\n",
    "                    n += 1\n",
    "\n",
    "                    # include this opto inactivation in the parameters to pass on\n",
    "                    my_params = make_dict([\"rule_and_delay_period\",\"target_period\",\"post_target_period\"], [i,j,k])\n",
    "                    my_params = make_dict([\"opto_times\"], [reshape(opto_periods[nopto,:], 1, 2)], my_params)\n",
    "                    my_params = merge(Dict(model_params), my_params)  # my_params takes precedence\n",
    "\n",
    "                    my_plot_list = [];\n",
    "                    if typeof(plot_conditions)==Bool && plot_conditions\n",
    "                        my_plot_list = plot_list;\n",
    "                    elseif typeof(plot_conditions)<:Array && plot_conditions[nopto]\n",
    "                        my_plot_list = plot_list;\n",
    "                    end\n",
    "\n",
    "                    # print(\"model params is \" ); print(model_params); print(\"\\n\")\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input =\n",
    "                        run_ntrials(nPro, nAnti; plot_list=my_plot_list, \n",
    "                            nderivs=nderivs, difforder=difforder, my_params...)\n",
    "                        # run_ntrials_opto(nPro, nAnti; nderivs=nderivs, difforder=difforder, my_params...)\n",
    "                    if length(proValls)==0\n",
    "                        proValls = zeros(4, size(proVall,2), size(proVall,3), noptos)\n",
    "                    end\n",
    "                    if length(antiValls)==0\n",
    "                        antiValls = zeros(4, size(antiVall,2), size(antiVall,3), noptos)\n",
    "                    end\n",
    "                    proValls[:,:,:,nopto]  = proVall\n",
    "                    antiValls[:,:,:,nopto] = antiVall\n",
    "                    # @printf(\"size of proValls is \"); print(size(proValls)); print(\"\\n\")\n",
    "                    \n",
    "                    hitsP  = 0.5*(1 + tanh.((proVs[1,:]-proVs[4,:,])/theta1))\n",
    "                    diffsP = tanh.((proVs[1,:,]-proVs[4,:])/theta2).^2\n",
    "                    hitsA  = 0.5*(1 + tanh.((antiVs[4,:]-antiVs[1,:,])/theta1))\n",
    "                    diffsA = tanh.((antiVs[4,:,]-antiVs[1,:])/theta2).^2\n",
    "\n",
    "                   # set up storage  \n",
    "                    hP[nopto, n] = mean(hitsP);\n",
    "                    hA[nopto, n] = mean(hitsA);\n",
    "                    dP[nopto, n] = mean(diffsP);\n",
    "                    dA[nopto, n] = mean(diffsA);\n",
    "                    hBP[nopto, n] = sum(proVs[1,:] .>= proVs[4,:,])/nPro;\n",
    "                    hBA[nopto, n] = sum(proVs[4,:] .>  proVs[1,:,])/nAnti;                    \n",
    "                    \n",
    "                    if nPro>0 && nAnti>0\n",
    "                        cost1s[nopto, n] = (nPro*(mean(hitsP) - opto_targets[nopto,1]).^2  \n",
    "                                    + nAnti*(mean(hitsA) - opto_targets[nopto,2]).^2)/(nPro+nAnti)\n",
    "                        cost2s[nopto, n] = -cbeta*(nPro*mean(diffsP) + nAnti*mean(diffsA))/(nPro+nAnti)\n",
    "                    elseif nPro>0\n",
    "                        cost1s[nopto, n] = (mean(hitsP) - opto_targets[nopto,1]).^2\n",
    "                        cost2s[nopto, n] = -cbeta*mean(diffsP)\n",
    "                    else\n",
    "                        cost1s[nopto, n] = (mean(hitsA) - opto_targets[nopto,2]).^2\n",
    "                        cost2s[nopto, n] = -cbeta*mean(diffsA)\n",
    "                    end\n",
    "\n",
    "                    totHitsP  += mean(hitsP);  totHitsA  += mean(hitsA); \n",
    "                    totDiffsP += mean(diffsP); totDiffsA += mean(diffsA);\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        hitsP = totHitsP/n; hitsA = totHitsA/n; diffsP = totDiffsP/n; diffsA = totDiffsA/n\n",
    "    \n",
    "        if verbose\n",
    "            pcost1 = mean(cost1s[nopto,:])   # partial costs\n",
    "            pcost2 = mean(cost2s[nopto,:])            \n",
    "            \n",
    "            @printf(\"%s\", pre_string)\n",
    "            @printf(\"Opto condition # %d\\n\", nopto)\n",
    "            @printf(\"     - %d - cost=%g, cost1=%g, cost2=%g\\n\", nopto,\n",
    "                convert(Float64, pcost1+pcost2), convert(Float64, pcost1), convert(Float64, pcost2))\n",
    "            if nPro>0 && nAnti>0\n",
    "                @printf(\"     - %d - mean(hitsP)=%g, mean(diffsP)=%g mean(hitsA)=%g, mean(diffsA)=%g\\n\", nopto,\n",
    "                    convert(Float64, mean(hitsP)), convert(Float64, mean(diffsP)),\n",
    "                    convert(Float64, mean(hitsA)), convert(Float64, mean(diffsA)))\n",
    "            elseif nPro>0\n",
    "                @printf(\"     - %d - mean(hitsP)=%g, mean(diffsP)=%g (nAnti=0)\\n\", nopto,\n",
    "                    convert(Float64, mean(hitsP)), convert(Float64, mean(diffsP)))\n",
    "            else\n",
    "                @printf(\"     - %d - (nPro=0) mean(hitsA)=%g, mean(diffsA)=%g\\n\", nopto,\n",
    "                    convert(Float64, mean(hitsA)), convert(Float64, mean(diffsA)))\n",
    "            end        \n",
    "        end\n",
    "    end\n",
    "        \n",
    "    \n",
    "    cost1 = mean(cost1s)\n",
    "    cost2 = mean(cost2s)\n",
    "\n",
    "    if verbose\n",
    "        @printf(\"%s\", pre_string)\n",
    "        @printf(\"OVERALL\\n\")\n",
    "        @printf(\"     -- cost=%g, cost1=%g, cost2=%g\\n\", \n",
    "            convert(Float64, cost1+cost2), convert(Float64, cost1), convert(Float64, cost2))\n",
    "    end\n",
    "    \n",
    "    if model_details\n",
    "        return cost1 + cost2, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA, \n",
    "            proValls, antiValls, opto_fraction, pro_input, anti_input\n",
    "    else\n",
    "        return cost1 + cost2, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of loading a farm and running JJ() on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pygui(true); hP = 0; hA = 0\n",
    "\n",
    "F = matread(\"FarmFields/farm_LD0003.mat\")\n",
    "model_params = symbol_key_ize(F[\"model_params\"])\n",
    "model_params[:rule_and_delay_periods] = F[\"rule_and_delay_periods\"]\n",
    "model_params[:post_target_periods] = F[\"post_target_periods\"]\n",
    "model_params[:seedrand]=F[\"test_sr\"]\n",
    "model_params[:cbeta] =F[\"cb\"]\n",
    "model_params[:start_pro] = [-0.5, -0.5, -0.5, -0.5]\n",
    "model_params[:start_anti] = [-0.5, -0.5, -0.5, -0.5]\n",
    "model_params = make_dict(F[\"args\"], F[\"pars\"], model_params)\n",
    "\n",
    "\n",
    "cost, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA = JJ(100, 100; \n",
    "plot_list=[1:10;], plot_conditions=[true,false,false,false, false], verbose=true, model_params...);\n",
    "\n",
    "[[\"control\", \"full\", \"rule\", \"delay\", \"target\"] hP hA]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining load_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_run"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me  pro_anti.jl\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model_params, F, nPro, nAnti = load_run(run_name; farmdir=\"FarmFields\")\n",
    "\n",
    "Loads a run and sets everything into a self-contained model_params so that you could then run it directly:\n",
    "\n",
    "    JJ(model_params[:nPro], model_params[:nAnti]; model_params...);\n",
    "\n",
    "If the model_params for the run included :start_pro and :start_anti entries (or \"start_pro\" and\n",
    "\"start_anti\" entries in F), it uses those. Otherwise\n",
    "sets :start_pro and :start_anti to a default of [-0.5, -0.5, -0.5, -0.5]\n",
    "\n",
    "\n",
    "# PARAMETERS:\n",
    "\n",
    "- run_name   A string representing the run. If it doesn't end in .mat, the .mat is added to it\n",
    "\n",
    "# OPTIONAL PARAMETERS:\n",
    "\n",
    "- farmdir   A string representing the directory in which the run is found\n",
    "\n",
    "# RETURNS:\n",
    "\n",
    "- model_params    The dictionary with all necessary params\n",
    "\n",
    "- F               A dictionary with the raw matread of the run file\n",
    "\n",
    "- nPro            equals model_params[:nPro]\n",
    "\n",
    "- nAnti           equals model_params[:nAnti]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function load_run(run_name; farmdir=\"FarmFields\")\n",
    "\n",
    "    default_U_start = [-0.5, -0.5, -0.5, -0.5]\n",
    "    \n",
    "    if !endswith(run_name, \".mat\")\n",
    "        run_name = run_name * \".mat\"\n",
    "    end\n",
    "    \n",
    "    F = matread(farmdir * \"/\" * run_name)\n",
    "    model_params = symbol_key_ize(F[\"model_params\"])\n",
    "    model_params[:rule_and_delay_periods] = F[\"rule_and_delay_periods\"]\n",
    "    model_params[:rule_and_delay_period]  = model_params[:rule_and_delay_periods][1]\n",
    "    model_params[:target_period]          = model_params[:target_period]\n",
    "    model_params[:post_target_periods]    = F[\"post_target_periods\"]\n",
    "    model_params[:post_target_period]     = model_params[:post_target_periods][1]\n",
    "    model_params[:seedrand]=F[\"test_sr\"]\n",
    "    model_params[:cbeta] =F[\"cb\"]\n",
    "    if ~haskey(model_params, :start_pro)\n",
    "        if ~haskey(F, \"start_pro\")\n",
    "            model_params[:start_pro] = default_U_start\n",
    "        else\n",
    "            model_params[:start_pro] = F[\"start_pro\"]\n",
    "        end\n",
    "    end\n",
    "    if ~haskey(model_params, :start_anti)\n",
    "        if ~haskey(F, \"start_anti\")\n",
    "            model_params[:start_anti] = default_U_start\n",
    "        else\n",
    "            model_params[:start_anti] = F[\"start_antia\"]\n",
    "        end\n",
    "    end\n",
    "    model_params = make_dict(F[\"args\"], F[\"pars\"], model_params)\n",
    "\n",
    "    nPro = model_params[:nPro]\n",
    "    nAnti = model_params[:nAnti]\n",
    "    \n",
    "    return model_params, F, nPro, nAnti\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of using load_run() and then JJ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opto condition # 1\n",
      "     - 1 - cost=-0.00371337, cost1=0.000642214, cost2=-0.00435558\n",
      "     - 1 - mean(hitsP)=0.897109, mean(diffsP)=0.131787 mean(hitsA)=0.780086, mean(diffsA)=0.957108\n",
      "Opto condition # 2\n",
      "     - 2 - cost=-0.00333682, cost1=0.000549782, cost2=-0.0038866\n",
      "     - 2 - mean(hitsP)=0.925007, mean(diffsP)=0.167603 mean(hitsA)=0.569803, mean(diffsA)=0.804047\n",
      "Opto condition # 3\n",
      "     - 3 - cost=-0.00390223, cost1=0.000392943, cost2=-0.00429517\n",
      "     - 3 - mean(hitsP)=0.898375, mean(diffsP)=0.133241 mean(hitsA)=0.762664, mean(diffsA)=0.940552\n",
      "Opto condition # 4\n",
      "     - 4 - cost=-0.00148963, cost1=0.00270506, cost2=-0.00419468\n",
      "     - 4 - mean(hitsP)=0.907641, mean(diffsP)=0.144525 mean(hitsA)=0.664293, mean(diffsA)=0.904146\n",
      "Opto condition # 5\n",
      "     - 5 - cost=-0.00372485, cost1=0.00041339, cost2=-0.00413824\n",
      "     - 5 - mean(hitsP)=0.912765, mean(diffsP)=0.149296 mean(hitsA)=0.763016, mean(diffsA)=0.885264\n",
      "OVERALL\n",
      "     -- cost=-0.00323338, cost1=0.000940677, cost2=-0.00417405\n"
     ]
    }
   ],
   "source": [
    "model_params, F, nPro, nAnti = load_run(\"farm_LD0003\");\n",
    "\n",
    "cost, cost1s, cost2s, hP, hA, dP, dA, hBP, hBA, proValls, antiValls = JJ(nPro, nAnti; verbose=true, \n",
    "    model_details=true, model_params...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opto condition # 1\n",
      "     - 1 - cost=-0.00391013, cost1=0.000250449, cost2=-0.00416058\n",
      "     - 1 - mean(hitsP)=0.849956, mean(diffsP)=0.0962574 mean(hitsA)=0.700239, mean(diffsA)=0.943888\n",
      "Opto condition # 2\n",
      "     - 2 - cost=0.000163742, cost1=0.00317111, cost2=-0.00300736\n",
      "     - 2 - mean(hitsP)=0.889289, mean(diffsP)=0.126419 mean(hitsA)=0.322246, mean(diffsA)=0.625422\n",
      "Opto condition # 3\n",
      "     - 3 - cost=-0.00300316, cost1=0.00124411, cost2=-0.00424727\n",
      "     - 3 - mean(hitsP)=0.850564, mean(diffsP)=0.0967087 mean(hitsA)=0.600014, mean(diffsA)=0.965108\n",
      "Opto condition # 4\n",
      "     - 4 - cost=-0.00300287, cost1=0.00113944, cost2=-0.00414231\n",
      "     - 4 - mean(hitsP)=0.862882, mean(diffsP)=0.106591 mean(hitsA)=0.600083, mean(diffsA)=0.928987\n",
      "Opto condition # 5\n",
      "     - 5 - cost=-0.00380482, cost1=7.13396e-05, cost2=-0.00387616\n",
      "     - 5 - mean(hitsP)=0.873296, mean(diffsP)=0.110639 mean(hitsA)=0.700523, mean(diffsA)=0.858401\n",
      "OVERALL\n",
      "     -- cost=-0.00271145, cost1=0.00117529, cost2=-0.00388674\n"
     ]
    }
   ],
   "source": [
    "model_params, F, nPro, nAnti = load_run(\"farm_LA0003\", farmdir=\"../for_carlos_without_runs/goodfarms\");\n",
    "\n",
    "JJ(10, 10; plot_list=[1:10;], plot_conditions=[false, false, false, true, false], verbose=true, model_params...);\n",
    "# JJ(10, 10; plot_list=[1:10;], plot_conditions=[true, false, false, false, false], verbose=true, model_params...);\n",
    "# JJ(30, 30; plot_list=[1:30;], plot_conditions=[false, false, false, false, true], verbose=true, model_params...);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2 Array{Float64,2}:\n",
       " -1.0  -1.0\n",
       "  0.0  20.0\n",
       "  0.0   0.2\n",
       "  0.2   0.4\n",
       "  0.4  20.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params[:opto_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 52 entries:\n",
       "  \"t_opto_hitsP\"           => [0.885539; 0.941221; … ; 0.892355; 0.935654]\n",
       "  \"cpm_traj\"               => [12.0 17.0 … 136.0 141.0; 0.0 0.0 … 0.0 0.0]\n",
       "  \"opto_hitsP\"             => [0.886032; 0.941549; … ; 0.892831; 0.936005]\n",
       "  \"t_opto_bA\"              => [0.0; 0.0; … ; 0.0; 0.0]\n",
       "  \"rule_and_delay_periods\" => 0.4\n",
       "  \"scost2\"                 => -0.00452198\n",
       "  \"value\"                  => -0.00341585\n",
       "  \"theta2\"                 => 0.15\n",
       "  \"hitsA\"                  => 0.894977\n",
       "  \"opto_bA\"                => [0.0; 0.0; … ; 0.0; 0.0]\n",
       "  \"test_sr\"                => 1506868634\n",
       "  \"t_opto_scost2\"          => [-0.0209498; 0.0; … ; 0.0; 0.0]\n",
       "  \"t_opto_scost1\"          => [0.000109366; 0.000849592; … ; 0.0016792; 0.00083…\n",
       "  \"cb\"                     => 0.04\n",
       "  \"t_opto_hitsA\"           => [0.703102; 0.49984; … ; 0.557445; 0.679834]\n",
       "  \"scost\"                  => 0.0145843\n",
       "  \"scost1\"                 => 0.0191063\n",
       "  \"opto_bP\"                => [1.0; 1.0; … ; 1.0; 1.0]\n",
       "  \"opto_hitsA\"             => [0.755813; 0.559971; … ; 0.659119; 0.734834]\n",
       "  \"sr\"                     => 1506833023\n",
       "  \"args\"                   => Any[\"sW\"; \"vW\"; … ; \"sigma\"; \"opto_strength\"]\n",
       "  \"theta1\"                 => 0.05\n",
       "  \"diffsA\"                 => 0.117542\n",
       "  \"bbox\"                   => Dict{String,Any}(Pair{String,Any}(\"sigma\",[0.01 0…\n",
       "  \"str\"                    => \"good0040\"\n",
       "  ⋮                        => ⋮"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = matread(\"goodfarms_new/good0040.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params, F, nPro, nAnti = load_run(\"farm_LD0003\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and plot a farm run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opto condition # 1\n",
      "     - 1 - cost=-0.00425733, cost1=1.77463e-05, cost2=-0.00427508\n",
      "     - 1 - mean(hitsP)=0.890143, mean(diffsP)=0.127457 mean(hitsA)=0.708961, mean(diffsA)=0.941313\n",
      "Opto condition # 2\n",
      "     - 2 - cost=-0.0035013, cost1=4.17834e-05, cost2=-0.00354308\n",
      "     - 2 - mean(hitsP)=0.916478, mean(diffsP)=0.155625 mean(hitsA)=0.487905, mean(diffsA)=0.730145\n",
      "Opto condition # 3\n",
      "     - 3 - cost=-0.00429781, cost1=9.36858e-06, cost2=-0.00430718\n",
      "     - 3 - mean(hitsP)=0.890623, mean(diffsP)=0.127972 mean(hitsA)=0.6976, mean(diffsA)=0.948824\n",
      "Opto condition # 4\n",
      "     - 4 - cost=-0.0028981, cost1=0.00144505, cost2=-0.00434315\n",
      "     - 4 - mean(hitsP)=0.900473, mean(diffsP)=0.139184 mean(hitsA)=0.620209, mean(diffsA)=0.946604\n",
      "Opto condition # 5\n",
      "     - 5 - cost=-0.00393827, cost1=1.5074e-05, cost2=-0.00395335\n",
      "     - 5 - mean(hitsP)=0.903543, mean(diffsP)=0.138283 mean(hitsA)=0.688245, mean(diffsA)=0.850053\n",
      "OVERALL\n",
      "     -- cost=-0.00377856, cost1=0.000305805, cost2=-0.00408437\n"
     ]
    }
   ],
   "source": [
    "model_params, F, nPro, nAnti = load_run(\"farm_LA0003\", farmdir=\"goodfarms\");\n",
    "\n",
    "cost, cost1s, cost2s, hP, hA, proVall, antiVall = JJ(nPro, nAnti; verbose=true, model_details=true, model_params...);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.axes._subplots.AxesSubplot object at 0x33030f5d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure(1); subplot(3,1,1) title(\"PRO -- delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(proVall[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---END OF CODE FOR LIBRARY AND USE BY OTHERS --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to JJ_opto_plot as taken from CARLOS_GET_DETAILS_TEST_CONTROL.jl\n",
    "\n",
    "First define the JJ_opto_plot() function, copied here from the script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From pro_anti_opto.jl:  definitions of forwardModel_opto(), make_opto_input(), and run_ntrials_opto()\n",
    "\n",
    "Copied here so we don't include(\"pro_anti_opto.jl\"), which overwrites JJ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as forwardModel, except it takes the opto_Fraction vector as an input, and the starting conditions as input. \n",
    "function forwardModel_opto(startU, opto_fraction; dt=0.01, tau=0.1, nsteps=100, input=[], noise=[], W=[0 -5;-5 0], \n",
    "    init_add=0, start_add=0, const_add=0, do_plot=false, nderivs=0, difforder=0, clearfig=true, fignum=1,\n",
    "    dUdt_mag_only=false, sigma=0, g_leak=1, U_rest=0, theta=0, beta=1, \n",
    "    warn_if_unused_params=false, other_unused_params...)\n",
    "\n",
    "    if warn_if_unused_params && length(other_unused_params)>0\n",
    "        @printf(\"\\n\\n=== forwardModel warning, had unused params \")\n",
    "        for k in keys(Dict(other_unused_params))\n",
    "            @printf(\"%s, \", k)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    \"\"\"\n",
    "    o = g(z)    squashing tanh function, running from 0 to 1, is equal to 0.5 when input is 0.\n",
    "    \"\"\"\n",
    "    function g(z)\n",
    "        return 0.5*tanh.(z)+0.5\n",
    "    end\n",
    "   \n",
    "\n",
    " \n",
    "    my_input = ForwardDiffZeros(size(input,1), size(input,2), nderivs=nderivs, difforder=difforder)\n",
    "    for i=1:prod(size(input)); my_input[i] = input[i]; end\n",
    "    input = my_input;\n",
    "   \n",
    "    my_opto = ForwardDiffZeros(size(opto_fraction,1), size(opto_fraction,2), nderivs=nderivs, difforder=difforder)\n",
    "    for i=1:prod(size(opto_fraction)); my_opto[i] = opto_fraction[i]; end\n",
    "    opto_fraction = my_opto;\n",
    "    opto_fraction = opto_fraction.*(1+ForwardDiffZeros(size(opto_fraction,1), nsteps, nderivs=nderivs, difforder=difforder))\n",
    " \n",
    "    nunits = length(startU)\n",
    "    if size(startU,2) > size(startU,1)\n",
    "        error(\"startU must be a column vector\")\n",
    "    end\n",
    "    \n",
    "    # --- formatting input ---\n",
    "    if ~(typeof(input)<:Array) || prod(size(input))==1  # was a scalar\n",
    "        input = input[1]*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(input)==0 # was the empty matrix\n",
    "        input = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(input,2)==1     # was a column vector\n",
    "        input = input*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    # --- formatting noise ---\n",
    "    if ~(typeof(noise)<:Array) || prod(size(noise))==1  # was a scalar\n",
    "        noise = noise*(1+ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    elseif length(noise)==0 # was the empty matrix\n",
    "        noise = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    elseif size(noise,2)==1     # was a column vector\n",
    "        noise = noise*(1+ForwardDiffZeros(1, nsteps, nderivs=nderivs, difforder=difforder))\n",
    "    end    \n",
    "    \n",
    "    U = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    V = ForwardDiffZeros(nunits, nsteps, nderivs=nderivs, difforder=difforder)\n",
    "    \n",
    "    if ~(typeof(W)<:Array); W = [W]; end\n",
    "\n",
    "    W     = reshape(W, nunits, nunits)\n",
    "    U     = reshape(U, nunits, nsteps)\n",
    "    V     = reshape(V, nunits, nsteps)\n",
    "    input = reshape(input, nunits, nsteps)\n",
    "    noise = reshape(noise, nunits, nsteps)\n",
    "\n",
    "    input[:,1] += init_add\n",
    "    input      += const_add\n",
    "\n",
    "    #@printf(\"size(U) is (%d,%d), and size(startU) is (%d,%d) and size(noise) is (%d,%d)\", \n",
    "    #    size(U,1), size(U,2), size(startU,1), size(startU,2), size(noise,1), size(noise,2))\n",
    "    # @printf(\"U[1]=%g, noise[1]=%g\\n\", startU, noise[1])\n",
    "    U[:,1] = startU + noise[:,1] + start_add; # @printf(\"Resulting U=%g\\n\", U[1])\n",
    "    V[:,1] = g((U[:,1]-theta)/beta); # @printf(\"Resulting V=%g\\n\", V[1])\n",
    "    V[:,1] = V[:,1].*opto_fraction[:,1];\n",
    "    \n",
    "    for i=2:nsteps\n",
    "        dUdt = g_leak*(U_rest -U[:,i-1]) + W*V[:,i-1] + input[:,i-1]\n",
    "        if dUdt_mag_only; return sum(dUdt.*dUdt); end;\n",
    "        # @printf(\"dUdt=%g\\n\", dUdt[1])\n",
    "        # @printf(\"i=%g\\n\", i)\n",
    "        # @printf(\"noise[2]=%g\\n\", noise[2])\n",
    "        U[:,i] = U[:,i-1] + (dt/tau)*dUdt + noise[:,i] + sigma*sqrt(dt)*randn(size(U,1),1)\n",
    "        # @printf(\"Resulting U[2]=%g\\n\", U[2])\n",
    "        V[:,i] = g((U[:,i]-theta)/beta)\n",
    "        V[:,i] = V[:,i].*opto_fraction[:,i]\n",
    "        # @printf(\"Resulting V[2]=%g\\n\", V[2])\n",
    "    end\n",
    "\n",
    "    if do_plot\n",
    "        figure(fignum)\n",
    "        if length(startU)==1\n",
    "            if clearfig; clf(); end;\n",
    "            t = (0:nsteps-1)*dt\n",
    "            plot(t, V[1,:], \"b-\")\n",
    "            plot(t[1], V[1,1], \"g.\")\n",
    "            plot(t[end], V[1,end], \"r.\")\n",
    "            xlabel(\"t\"); ylabel(\"V1\"); ylim([-0.01, 1.01])\n",
    "        elseif length(startU)>=2\n",
    "            if clearfig; clf(); end;\n",
    "            plot(V[1,:], V[2,:], \"b-\")\n",
    "            plot(V[1,1], V[2,1], \"g.\")\n",
    "            plot(V[1,end], V[2,end], \"r.\")\n",
    "            xlabel(\"V1\"); ylabel(\"V2\"); \n",
    "            xlim([-0.01, 1.01]); ylim([-0.01, 1.01])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return U[:,end], V[:,end], U, V\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# returns a vector of the inhibition fraction for each node given the opto period and opto strength\n",
    "# right now, it always computes bilateral inactivations\n",
    "function make_opto_input(nsteps; dt = 0.02, opto_strength=1, opto_period=[-1 1],nderivs=0,difforder=0, other_unused_params...);\n",
    "       \n",
    "    strength = ForwardDiffZeros(1,1,nderivs=nderivs, difforder=difforder);\n",
    "    strength[1] = strength[1] + opto_strength;\n",
    "\n",
    "    if opto_period[2] < 0 # no opto, return all ones\n",
    "        opto_fraction = 1+ForwardDiffZeros(4,nsteps,nderivs=nderivs, difforder=difforder);\n",
    "#        print(\"0 0 out of \")\n",
    "#        print(nsteps*dt)\n",
    "#        print(\" with command \")\n",
    "#        print(opto_period)  \n",
    "#        println()\n",
    "    else # opto, compute fraction vector\n",
    "        # check for variable inputs\n",
    "        other_unused_params = Dict(other_unused_params);\n",
    "        end_rd =     other_unused_params[:rule_and_delay_period];\n",
    "        end_rule =   other_unused_params[:rule_and_delay_period]/2;\n",
    "        end_target = other_unused_params[:rule_and_delay_period]+other_unused_params[:target_period]; \n",
    "        if opto_period[1]==100\n",
    "            opto_period[1] = end_rd;\n",
    "        elseif opto_period[1]==50\n",
    "            opto_period[1] = end_rule;\n",
    "        elseif opto_period[1]==200\n",
    "            opto_period[1] = end_target;\n",
    "        end        \n",
    "        if opto_period[2]==100\n",
    "            opto_period[2] = end_rd;\n",
    "        elseif opto_period[2]==50\n",
    "            opto_period[2] = end_rule;\n",
    "        elseif opto_period[2]==200\n",
    "            opto_period[2] = end_target;\n",
    "        end        \n",
    "\n",
    "        # check for start and end of trial flags\n",
    "        start_step = round(opto_period[1]/dt);\n",
    "        if start_step < 1; start_step = 1; end\n",
    "        end_step = round(opto_period[2]/dt);\n",
    "        if end_step > nsteps; end_step = nsteps; end\n",
    "        if end_step < 1; end_step = 1; end\n",
    "\n",
    "#        print(start_step*dt)\n",
    "#        print(\" \")\n",
    "#        print(end_step*dt)\n",
    "#        print(\" out of \")\n",
    "#        print(nsteps*dt)\n",
    "#        print(\" with command \")\n",
    "#        print(opto_period)\n",
    "#        println()       \n",
    " \n",
    "        # compute the fraction\n",
    "        opto_fraction = 1+ForwardDiffZeros(4,nsteps,nderivs=nderivs, difforder=difforder);\n",
    "        opto_fraction[:,Int(start_step):Int(end_step)] = repeat(strength,outer=[4,Int(end_step)-Int(start_step)+1]);\n",
    "    end\n",
    "    \n",
    "    return opto_fraction\n",
    "end\n",
    "\n",
    "\n",
    "# same as normal run_ntrials_opto, but passes opto parameters through, and computes the opto_fraction using make_opto_input\n",
    "# Also takes the starting conditions \"start_pro\" and \"start_anti\" as optional parameters\n",
    "# returns two matrices which are all model trajectories\n",
    "function run_ntrials_opto(nPro, nAnti; plot_list=[], nderivs=0, difforder=0,start_pro=[-0.3, -0.7, -0.7, -0.3], \n",
    "    start_anti=[-0.7, -0.3, -0.3, -0.7],  opto_periods=[-1 -1],model_params...)\n",
    "    pro_input,  t, nsteps = make_input(\"Pro\" ; nderivs=nderivs, difforder=difforder, model_params...);\n",
    "    anti_input, t, nsteps = make_input(\"Anti\"; nderivs=nderivs, difforder=difforder, model_params...);\n",
    "    #### make opto fraction vector\n",
    "    opto_fraction = make_opto_input(nsteps; nderivs=nderivs,difforder=difforder, model_params...);\n",
    "    model_params = Dict(model_params)\n",
    "    sW = model_params[:sW]\n",
    "    hW = model_params[:hW]\n",
    "    vW = model_params[:vW]\n",
    "    dW = model_params[:dW]\n",
    "    model_params = make_dict([\"nsteps\", \"W\"], [nsteps, [sW vW dW hW; vW sW hW dW; dW hW sW vW; hW dW vW sW]], model_params)\n",
    "    model_params = make_dict([\"nderivs\", \"difforder\"], [nderivs, difforder], model_params)\n",
    "    \n",
    "    ## include opto fraction in model_params dictionary\n",
    "    model_params = make_dict([\"opto_fraction\"], [opto_fraction], model_params);\n",
    "\n",
    "    proVs  = ForwardDiffZeros(4, nPro, nderivs=nderivs, difforder=difforder)\n",
    "    antiVs = ForwardDiffZeros(4, nAnti, nderivs=nderivs, difforder=difforder)\n",
    "    proVall  = zeros(4, nsteps, nPro);\n",
    "    antiVall = zeros(4, nsteps, nAnti);\n",
    "\n",
    "    # --- PRO ---\n",
    "    if length(plot_list)>0; figure(1); clf(); end\n",
    "    model_params = make_dict([\"input\"], [pro_input], model_params)\n",
    "    for i=1:nPro\n",
    "        startU = start_pro;\n",
    "        Uend, Vend, U, V = forwardModel_opto(startU, opto_fraction, do_plot=false; model_params...)\n",
    "        proVs[:,i] = Vend\n",
    "        proVall[:,:,i] = V;\n",
    "\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, U, V; fignum=1, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"PRO\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- ANTI ---\n",
    "    if length(plot_list)>0; figure(2); clf(); end\n",
    "    model_params = make_dict([\"input\"], [anti_input], model_params)\n",
    "    for i=1:nAnti\n",
    "        startU = start_anti;\n",
    "        Uend, Vend, U, V = forwardModel_opto(startU,opto_fraction, do_plot=false; model_params...)\n",
    "        antiVs[:,i] = Vend\n",
    "        antiVall[:,:,i] = V\n",
    "\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, U, V; fignum=2, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"ANTI\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return proVs, antiVs, proVall, antiVall,opto_fraction,pro_input, anti_input \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And definition of JJ_opto_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "function JJ_opto_plot(nPro, nAnti; opto_targets=[0.9 0.7], theta1=0.025, theta2=0.035, cbeta=0.003, verbose=false, pre_string=\"\", zero_last_sigmas=0, seedrand=NaN, rule_and_delay_periods = [0.4], target_periods = [0.1], post_target_periods = [0.5], opto_periods = [-1 -1],opto_strength=1, nderivs=0, difforder=0,plot_conditions=false,model_details=false, model_params...) #set opto defaults!\n",
    "\n",
    "    if ~(size(opto_targets) == size(opto_periods)); error(\"opto parameters are bad\"); end\n",
    "\n",
    "    nruns = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)*size(opto_periods)[1]\n",
    "    nruns_each = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)\n",
    "    \n",
    "    cost1s = ForwardDiffZeros(size(opto_periods)[1], nruns_each, nderivs=nderivs, difforder=difforder)\n",
    "    cost2s = ForwardDiffZeros(size(opto_periods)[1], nruns_each, nderivs=nderivs, difforder=difforder)\n",
    "    hP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hA = zeros(size(opto_periods)[1], nruns_each);\n",
    "    dP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    dA = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hBP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hBA = zeros(size(opto_periods)[1], nruns_each);\n",
    "\n",
    "    if model_details\n",
    "        proVall         = [];\n",
    "        antiVall        = [];\n",
    "        opto_fraction   = [];\n",
    "        pro_input       = [];\n",
    "        anti_input      = [];\n",
    "    end\n",
    "\n",
    "    n = totHitsP = totHitsA = totDiffsP = totDiffsA =nopto= 0\n",
    "    for kk=1:size(opto_periods)[1] # iterate over each opto inactivation period\n",
    "    nopto = 0;\n",
    "\n",
    "    # reset random number generator for each opto period, so it cant over fit noise samples\n",
    "    if ~isnan(seedrand); srand(seedrand); end\n",
    "\n",
    "    for i in rule_and_delay_periods\n",
    "        for j in target_periods\n",
    "            for k = post_target_periods\n",
    "                nopto += 1\n",
    "                \n",
    "                # include this opto inactivation in the parameters to pass on\n",
    "                my_params = make_dict([\"rule_and_delay_period\", \"target_period\", \"post_target_period\",\"opto_period\",\"opto_strength\"], [i, j, k, opto_periods[kk,:], opto_strength], Dict(model_params))\n",
    "    \n",
    "                # print(\"model params is \" ); print(model_params); print(\"\\n\")\n",
    "                if typeof(plot_conditions)==Bool && ~plot_conditions\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input  = run_ntrials_opto(nPro, nAnti; nderivs=nderivs, difforder=difforder, my_params...)\n",
    "                elseif typeof(plot_conditions)==Bool\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input  = run_ntrials_opto(nPro, nAnti; plot_list=1:10, nderivs=nderivs, difforder=difforder, my_params...)                        \n",
    "                elseif plot_conditions[kk]\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input  = run_ntrials_opto(nPro, nAnti; plot_list=1:10, nderivs=nderivs, difforder=difforder, my_params...)                        \n",
    "                else\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input  = run_ntrials_opto(nPro, nAnti; nderivs=nderivs, difforder=difforder, my_params...)                                                \n",
    "                end\n",
    "\n",
    "                hitsP  = 0.5*(1 + tanh.((proVs[1,:]-proVs[4,:,])/theta1))\n",
    "                diffsP = tanh.((proVs[1,:,]-proVs[4,:])/theta2).^2\n",
    "                hitsA  = 0.5*(1 + tanh.((antiVs[4,:]-antiVs[1,:,])/theta1))\n",
    "                diffsA = tanh.((antiVs[4,:,]-antiVs[1,:])/theta2).^2\n",
    "               \n",
    "                # set up storage  \n",
    "                hP[kk,nopto] = mean(hitsP);\n",
    "                hA[kk,nopto] = mean(hitsA);\n",
    "                dP[kk,nopto] = mean(diffsP);\n",
    "                dA[kk,nopto] = mean(diffsA);\n",
    "                hBP[kk,nopto] = sum(proVs[1,:] .>= proVs[4,:,])/nPro;\n",
    "                hBA[kk,nopto] = sum(proVs[4,:] .>  proVs[1,:,])/nAnti;\n",
    "\n",
    "                if nPro>0 && nAnti>0\n",
    "                    cost1s[kk,nopto] = (nPro*(mean(hitsP) - opto_targets[kk,1]).^2  + nAnti*(mean(hitsA) - opto_targets[kk,2]).^2)/(nPro+nAnti)\n",
    "                    cost2s[kk,nopto] = -cbeta*(nPro*mean(diffsP) + nAnti*mean(diffsA))/(nPro+nAnti)\n",
    "                elseif nPro>0\n",
    "                    cost1s[kk,nopto] = (mean(hitsP) - opto_targets[kk,1]).^2\n",
    "                    cost2s[kk,nopto] = -cbeta*mean(diffsP)\n",
    "                else\n",
    "                    cost1s[kk,nopto] = (mean(hitsA) - opto_targets[kk,2]).^2\n",
    "                    cost2s[kk,nopto] = -cbeta*mean(diffsA)\n",
    "                end\n",
    "\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    end\n",
    "    \n",
    "    cost1 = mean(cost1s)\n",
    "    cost2 = mean(cost2s)\n",
    "    if model_details\n",
    "        return cost1 + cost2, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA, proVall, antiVall, opto_fraction, pro_input, anti_input\n",
    "    else\n",
    "        return cost1 + cost2, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run as in Alex's script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = matread(\"FarmFields/farm_LD0003.mat\")\n",
    "model_params = symbol_key_ize(F[\"model_params\"])\n",
    "model_params[:start_pro] = [-0.5, -0.5, -0.5, -0.5]\n",
    "model_params[:start_anti] = [-0.5, -0.5, -0.5, -0.5]\n",
    "\n",
    "\n",
    "cost, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA =  JJ_opto_plot(model_params[:nPro],model_params[:nAnti]; \n",
    "rule_and_delay_periods=F[\"rule_and_delay_periods\"], post_target_periods=F[\"post_target_periods\"],  \n",
    "seedrand=F[\"test_sr\"], cbeta=F[\"cb\"], \n",
    "verbose=true,plot_conditions=[false,false,false,false,true],model_details=true,  \n",
    "merge(make_dict(F[\"args\"],F[\"pars\"], model_params))...);\n",
    "\n",
    "[[\"control\", \"full\", \"rule\", \"delay\", \"target\"] hP hA]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of taking the gradient and Hessian of the cost function JJ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = [\"sW\", \"vW\", \"hW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\", \"const_pro_bias\"]\n",
    "seed = [0.2,   -1.7, -1.7,      0.39,                0.15,                       0.1,                       0.1]\n",
    "\n",
    "func = (;params...) -> JJ(100, 10; rule_and_delay_periods = [0.4, 0.8], seedrand=30, cbeta=0.01, \n",
    "plot_list = [], verbose=false, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "cost, grad, hess = keyword_vgh(func, args, seed)\n",
    "\n",
    "# func(;make_dict(args, seed+ [1,0.2,0,0,0,0,0])...) - func(;make_dict(args, seed)...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looking into Alex's farms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"pro_anti_opto.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function run_ntrials_opto(nPro, nAnti; plot_list=[], nderivs=0, difforder=0, opto_periods=[-1 -1],model_params...)\n",
    "    pro_input,  t, nsteps = make_input(\"Pro\" ; model_params...);\n",
    "    anti_input, t, nsteps = make_input(\"Anti\"; model_params...);\n",
    "\n",
    "    #### make opto fraction vector\n",
    "    opto_fraction = make_opto_input(nsteps; nderivs=nderivs,difforder=difforder, model_params...);\n",
    "    model_params = Dict(model_params)\n",
    "    sW = model_params[:sW]\n",
    "    hW = model_params[:hW]\n",
    "    vW = model_params[:vW]\n",
    "    dW = model_params[:dW]\n",
    "    model_params = make_dict([\"nsteps\", \"W\"], [nsteps, [sW vW dW hW; vW sW hW dW; dW hW sW vW; hW dW vW sW]], model_params)\n",
    "    model_params = make_dict([\"nderivs\", \"difforder\"], [nderivs, difforder], model_params)\n",
    "    \n",
    "    ## include opto fraction in model_params dictionary\n",
    "    model_params = make_dict([\"opto_fraction\"], [opto_fraction], model_params);\n",
    "\n",
    "    proVs  = ForwardDiffZeros(4, nPro, nderivs=nderivs, difforder=difforder)\n",
    "    antiVs = ForwardDiffZeros(4, nAnti, nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "    # --- PRO ---\n",
    "    if length(plot_list)>0; figure(1); clf(); end\n",
    "    model_params = make_dict([\"input\"], [pro_input], model_params)\n",
    "    for i=1:nPro\n",
    "        startU = [-0.3, -0.7, -0.7, -0.3]\n",
    "        Uend, Vend, U, V = forwardModel_opto(startU, opto_fraction, do_plot=false; model_params...)\n",
    "        proVs[:,i] = Vend\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, U, V; fignum=1, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"PRO\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- ANTI ---\n",
    "    if length(plot_list)>0; figure(2); clf(); end\n",
    "    model_params = make_dict([\"input\"], [anti_input], model_params)\n",
    "    for i=1:nAnti\n",
    "        startU = [-0.7, -0.3, -0.3, -0.7]\n",
    "        Uend, Vend, U, V = forwardModel_opto(startU,opto_fraction, do_plot=false; model_params...)\n",
    "        antiVs[:,i] = Vend\n",
    "        if any(plot_list.==i) \n",
    "            plot_PA(t, U, V; fignum=2, clearfig=false, model_params...)\n",
    "            subplot(3,1,1); title(\"ANTI\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return proVs, antiVs\n",
    "end\n",
    "\n",
    "function JJ_opto(nPro, nAnti; opto_targets=[0.9 0.7], theta1=0.025, theta2=0.035, cbeta=0.003, \n",
    "    verbose=false, pre_string=\"\", zero_last_sigmas=0, seedrand=NaN, \n",
    "    rule_and_delay_periods = [0.4], target_periods = [0.1], post_target_periods = [0.5], \n",
    "    opto_periods = [-1 -1],opto_strength=1, nderivs=0, difforder=0, \n",
    "    plot_conditions = false,\n",
    "    model_params...) #set opto defaults!\n",
    "\n",
    "    if ~(size(opto_targets) == size(opto_periods)); error(\"opto parameters are bad\"); end\n",
    "\n",
    "    nruns = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)*size(opto_periods)[1]\n",
    "    nruns_each = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)\n",
    "    \n",
    "    cost1s = ForwardDiffZeros(size(opto_periods)[1], nruns_each, nderivs=nderivs, difforder=difforder)\n",
    "    cost2s = ForwardDiffZeros(size(opto_periods)[1], nruns_each, nderivs=nderivs, difforder=difforder)\n",
    "    hP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hA = zeros(size(opto_periods)[1], nruns_each);\n",
    "    dP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    dA = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hBP = zeros(size(opto_periods)[1], nruns_each);\n",
    "    hBA = zeros(size(opto_periods)[1], nruns_each);\n",
    "\n",
    "    n = totHitsP = totHitsA = totDiffsP = totDiffsA =nopto= 0\n",
    "    for kk=1:size(opto_periods)[1] # iterate over each opto inactivation period\n",
    "        nopto = 0;\n",
    "\n",
    "        # reset random number generator for each opto period, so it cant over fit noise samples\n",
    "        if ~isnan(seedrand); srand(seedrand); end\n",
    "\n",
    "        for i in rule_and_delay_periods\n",
    "            for j in target_periods\n",
    "                for k = post_target_periods\n",
    "                    nopto += 1\n",
    "\n",
    "                    # include this opto inactivation in the parameters to pass on\n",
    "                    my_params = make_dict([\"rule_and_delay_period\", \"target_period\", \"post_target_period\",\"opto_period\",\"opto_strength\"], [i, j, k, opto_periods[kk,:], opto_strength], Dict(model_params))\n",
    "\n",
    "                    # print(\"model params is \" ); print(model_params); print(\"\\n\")\n",
    "                    if typeof(plot_conditions)==Bool && ~plot_conditions\n",
    "                        proVs, antiVs = run_ntrials_opto(nPro, nAnti; nderivs=nderivs, difforder=difforder, my_params...)\n",
    "                    elseif typeof(plot_conditions)==Bool\n",
    "                        proVs, antiVs = run_ntrials_opto(nPro, nAnti; plot_list=1:10,\n",
    "                            nderivs=nderivs, difforder=difforder, my_params...)                        \n",
    "                    elseif plot_conditions[kk]\n",
    "                        proVs, antiVs = run_ntrials_opto(nPro, nAnti; plot_list=1:10,\n",
    "                            nderivs=nderivs, difforder=difforder, my_params...)                        \n",
    "                    else\n",
    "                        proVs, antiVs = run_ntrials_opto(nPro, nAnti; nderivs=nderivs, difforder=difforder, my_params...)                                                \n",
    "                    end\n",
    "                    hitsP  = 0.5*(1 + tanh.((proVs[1,:]-proVs[4,:,])/theta1))\n",
    "                    diffsP = tanh.((proVs[1,:,]-proVs[4,:])/theta2).^2\n",
    "                    hitsA  = 0.5*(1 + tanh.((antiVs[4,:]-antiVs[1,:,])/theta1))\n",
    "                    diffsA = tanh.((antiVs[4,:,]-antiVs[1,:])/theta2).^2\n",
    "\n",
    "                    # set up storage  \n",
    "                    hP[kk,nopto] = mean(hitsP);\n",
    "                    hA[kk,nopto] = mean(hitsA);\n",
    "                    dP[kk,nopto] = mean(diffsP);\n",
    "                    dA[kk,nopto] = mean(diffsA);\n",
    "                    hBP[kk,nopto] = sum(proVs[1,:] .>= proVs[4,:,])/nPro;\n",
    "                    hBA[kk,nopto] = sum(proVs[4,:] .>  proVs[1,:,])/nAnti;\n",
    "\n",
    "                    if nPro>0 && nAnti>0\n",
    "                        cost1s[kk,nopto] = (nPro*(mean(hitsP) - opto_targets[kk,1]).^2  + nAnti*(mean(hitsA) - opto_targets[kk,2]).^2)/(nPro+nAnti)\n",
    "                        if kk ==1\n",
    "                        cost2s[kk,nopto] = -cbeta*(nPro*mean(diffsP) + nAnti*mean(diffsA))/(nPro+nAnti)\n",
    "                        end\n",
    "                    elseif nPro>0\n",
    "                        cost1s[kk,nopto] = (mean(hitsP) - opto_targets[kk,1]).^2\n",
    "                        if kk == 1\n",
    "                        cost2s[kk,nopto] = -cbeta*mean(diffsP)\n",
    "                        end\n",
    "                    else\n",
    "                        cost1s[kk,nopto] = (mean(hitsA) - opto_targets[kk,2]).^2\n",
    "                        if kk == 1\n",
    "                        cost2s[kk,nopto] = -cbeta*mean(diffsA)\n",
    "                        end\n",
    "                    end\n",
    "\n",
    "                  #  totHitsP  += mean(hitsP);  totHitsA  += mean(hitsA); \n",
    "                  #  totDiffsP += mean(diffsP); totDiffsA += mean(diffsA);\n",
    "                end\n",
    "            end \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    cost1 = mean(cost1s)\n",
    "    cost2 = mean(cost2s)\n",
    "#    print(cost1s)\n",
    "    \n",
    "#    print(cost2s)\n",
    "#    hitsP = totHitsP/n; hitsA = totHitsA/n; diffsP = totDiffsP/n; diffsA = totDiffsA/n\n",
    "    \n",
    "    \n",
    "#    if verbose\n",
    "#        @printf(\"%s\", pre_string)\n",
    "#        @printf(\"     -- cost=%g,   cost1=%g, cost2=%g\\n\", \n",
    "#            convert(Float64, cost1+cost2), convert(Float64, cost1), convert(Float64, cost2))\n",
    "#        if nPro>0 && nAnti>0\n",
    "#            @printf(\"     -- mean(hitsP)=%g, mean(diffsP)=%g mean(hitsA)=%g, mean(diffsA)=%g\\n\", \n",
    "#                convert(Float64, mean(hitsP)), convert(Float64, mean(diffsP)),\n",
    "#                convert(Float64, mean(hitsA)), convert(Float64, mean(diffsA)))\n",
    "#        elseif nPro>0\n",
    "#            @printf(\"     -- mean(hitsP)=%g, mean(diffsP)=%g (nAnti=0)\\n\", \n",
    "#                convert(Float64, mean(hitsP)), convert(Float64, mean(diffsP)))\n",
    "#        else\n",
    "#            @printf(\"     -- (nPro=0) mean(hitsA)=%g, mean(diffsA)=%g\\n\", \n",
    "#                convert(Float64, mean(hitsA)), convert(Float64, mean(diffsA)))\n",
    "#        end        \n",
    "#    end \n",
    "    \n",
    "    return cost1 + cost2, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = matread(\"FarmFields/farm_L0059.mat\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params = symbol_key_ize(G[\"model_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func =  (;params...) -> JJ_opto(model_params[:nPro], model_params[:nAnti]; \n",
    "rule_and_delay_periods=G[\"rule_and_delay_periods\"], \n",
    "theta1=model_params[:theta1], theta2=model_params[:theta2], \n",
    "post_target_periods=G[\"post_target_periods\"], plot_conditions=[false, false, false, true, false],\n",
    "seedrand=G[\"sr\"], cbeta=G[\"cb\"], verbose=true, \n",
    "merge(make_dict(G[\"args\"], G[\"pars\"], merge(model_params, Dict(params))), Dict(:sigma=>0.5))...)\n",
    "\n",
    "\n",
    "total_cost, cost1s, cost2s, hP,hA,dP,dA,hBP,hBA = func()\n",
    "\n",
    "[epochs hP hA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[epochs model_params[:opto_targets]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### above will run one of the farm animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding the best farm animal\n",
    "\n",
    "fnames = filter(x -> startswith(x, \"farm_L\"), readdir(\"FarmFields/\"))\n",
    "costs = zeros(size(fnames))\n",
    "for i=1:length(fnames)\n",
    "    G = matread(\"FarmFields/\" * fnames[i])\n",
    "    costs[i] = G[\"cost\"]\n",
    "end\n",
    "\n",
    "find(costs .== minimum(costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge(make_dict(G[\"args\"], G[\"pars\"], model_params), Dict(:sigma=>0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_dict(G[\"args\"], G[\"pars\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = [\"control\"; \"full\"; \"rule\"; \"delay\"; \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pygui(true); figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# mixed_sign_hessian_farm_F_analysis.jl  -- Looking into Hessians with mixed-sign eigenvalues\n",
    "\n",
    "**RESULT: The mixed-sign Hessian eigenvalues are due to the walls**\n",
    "\n",
    "There are 122 farm F animals that stopped before their 400-iteration limit.  Of those, if we look at the Hessian for only those parameters that had not reached a bounding wall, all but one farm animal had all-positive eigenvalues (including F_0564). [Thus, for example, for a file in which 2 parameters had reached a bounding wall and 7 parameters had not, we're looking at a 7x7 Hessian.]\n",
    "\n",
    "The single example with mixed-sign eigenvalues is F_0534. The solution in this farm animal is not terrible, but it ranks as the 203rd best solution out of 751 (27th percentile), far from what we would usually consider. If we took the top 20% solutions we wouldn't even be considering this lone example.\n",
    "\n",
    "Given that, I think I'm going to proceed working on the assumption that for most files, the walls are the issue; the rare files for which that is not true I propose we just toss, and if those become not rare in the future then I will revisit.\n",
    "\n",
    "Code: [`mixed_sign_hessian_farm_F_analysis.jl`](http://localhost:8888/edit/mixed_sign_hessian_farm_F_analysis.jl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me   mixed_sign_hessian_farm_F_analysis.jl\n",
    "\n",
    "\"\"\"\n",
    "walled, free = id_pars_at_walls(bbox, args, pars; tol=1e-3)\n",
    "\n",
    "Returns a list of elements in pars that are within tol of their bounds described in the bbox Dict(),\n",
    "and a list of those not within tol of their bounds.  The union of walled and free will be equal to 1:length(pars).\n",
    "\n",
    "\"\"\"\n",
    "function id_pars_at_walls(bbox, args, pars; tol=1e-3)\n",
    "    walled = Array{Int}(0)\n",
    "    free   = Array{Int}(0)\n",
    "    i = 1; while i<=length(args)\n",
    "        if typeof(args[i])<:String && haskey(bbox, Symbol(args[i]))\n",
    "            range = bbox[Symbol(args[i])]\n",
    "            if any(abs(pars[i]-range).<tol)\n",
    "                walled = [walled; i]\n",
    "            else\n",
    "                free = [free; i]\n",
    "            end    \n",
    "        elseif typeof(args[i])<:String\n",
    "            free = [free; i]\n",
    "        elseif haskey(bbox, Symbol(args[i][1]))\n",
    "            range = bbox[Symbol(args[i][1])]\n",
    "            for j=1:args[i][2]\n",
    "                if any(abs(pars[i+j-1]-range).<tol)\n",
    "                    walled = [walled; i+j-1]\n",
    "                else\n",
    "                    free = [free; i+j-1]\n",
    "                end    \n",
    "            end\n",
    "            i = i+args[i][2]-1\n",
    "        else\n",
    "            for j=1:args[i][2]; free = [free; i+j-1]; end\n",
    "            i = i+args[i][2]-1\n",
    "        end\n",
    "    i=i+1; end    \n",
    "    \n",
    "    return walled, free\n",
    "end\n",
    "\n",
    "\n",
    "walled, free = id_pars_at_walls(Dict(:a=>[1, 2], :b=>[0.1, 0.2]), [\"c\", \"a\", [\"b\" 2]], [10, 1.9999, 0.1, 0.15])\n",
    "\n",
    "walled, free = id_pars_at_walls(bbox, args, pars; tol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@include_me   mixed_sign_hessian_farm_F_analysis.jl\n",
    "\n",
    "# ========  This is copied from the code for farm F, telling us how it was run ==============================\n",
    "\n",
    "# ======= ARGUMENTS AND SEED VALUES:\n",
    "args = [\"sW\", \"vW\", \"hW\", \"dW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\"]\n",
    "seed = [0.2,   1,   0.2,  1,    0.39,                0.15,                       0.1]\n",
    "\n",
    "args = [args ; [\"const_pro_bias\", \"sigma\"]]\n",
    "seed = [seed ; [0.1,               0.1]]\n",
    "\n",
    "\n",
    "# ======= BOUNDING BOX:\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :dW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :const_pro_bias=>[-2 2],\n",
    ":sigma=>[0.01 0.2])\n",
    "\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5))\n",
    "# seed = [0.0840597,  -1.32677,  -0.437334,  -0.324835,  0.567997, 0.712216,  0.0500075,  0.0858569,  0.25]\n",
    "\n",
    "\n",
    "# ======== SEARCH ZONE:\n",
    "\n",
    "sbox = Dict(:sW=>[0.001 0.5], :vW=>[-0.5 0.5], :hW=>[-0.5 0.5], :dW=>[-0.5 0.5],\n",
    ":constant_excitation=>[-0.5 0.5], :right_light_excitation=>[0.1 0.5], :target_period_excitation=>[0.1 0.5],\n",
    ":const_pro_bias=>[0 0.2], :sigma=>[0.02 0.19])\n",
    "\n",
    "# ========  END  --   This is copied from the code for farm F, telling us how it was run ===================\n",
    "\n",
    "# Now read all the files to get all there costs and iteration numbers\n",
    "\n",
    "fnames = filter(x -> startswith(x, \"farm_F\"), readdir(\"FarmFields/\"))\n",
    "scosts = zeros(size(fnames))\n",
    "niters = zeros(size(fnames))\n",
    "for i=1:length(fnames) \n",
    "    A = matread(\"FarmFields/\" * fnames[i])  \n",
    "    scosts[i] = A[\"scost\"]\n",
    "    niters[i] = size(A[\"traj\"],2)\n",
    "end\n",
    "\n",
    "pygui(true)\n",
    "figure(1); clf();\n",
    "plot(scosts, niters, \".\")\n",
    "xlabel(\"cost at standard beta=0.01\")\n",
    "ylabel(\"number of iterations run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me   mixed_sign_hessian_farm_F_analysis.jl\n",
    "\n",
    "\n",
    "# #################  FINALLY TO THE ANALYSIS PART   ################\n",
    "\n",
    "goodies = find((niters.<400)) #  & (scosts.<-0.007))\n",
    "mixed_sign = Array{String}(0)\n",
    "\n",
    "for i=1:length(goodies)\n",
    "    A = matread(\"FarmFields/\" * fnames[goodies[i]])\n",
    "\n",
    "    args = A[\"args\"]\n",
    "    pars = A[\"pars\"]\n",
    "    nPro = A[\"nPro\"]\n",
    "    nAnti = A[\"nAnti\"]\n",
    "    rule_and_delay_periods = A[\"rule_and_delay_periods\"]\n",
    "    post_target_periods    = A[\"post_target_periods\"]\n",
    "    theta1 = A[\"theta1\"]\n",
    "    theta2 = A[\"theta2\"]\n",
    "    sr = A[\"sr\"]\n",
    "    cb = A[\"cb\"]\n",
    "    sbox = symbol_key_ize(A[\"sbox\"])\n",
    "    bbox = symbol_key_ize(A[\"bbox\"])\n",
    "    model_params = symbol_key_ize(A[\"model_params\"])\n",
    "\n",
    "\n",
    "    func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "        theta1=theta1, theta2=theta2,\n",
    "        post_target_periods=post_target_periods,\n",
    "        seedrand=sr, cbeta=cb, verbose=false, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "    standard_func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "        theta1=theta1, theta2=theta2,\n",
    "        post_target_periods=post_target_periods,\n",
    "        seedrand=sr, cbeta=0.01, verbose=false, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "\n",
    "    value, grad, hess = keyword_vgh(func, args, pars)\n",
    "\n",
    "    walled, free = id_pars_at_walls(bbox, args, pars)\n",
    "    L, V = eig(hess[free,free])\n",
    "    @printf(\"%d/%d: file %s had %d free parameters, with hessian eigenvalues \", \n",
    "        i, length(goodies), fnames[goodies[i]], length(free))\n",
    "    print_vector_g(L); print(\"\\n\")\n",
    "    \n",
    "    if any(L.<0)\n",
    "        @printf(\"\\n    *** File %s had off-wall mixed sign eigenvalues!\\n\\n\", fnames[goodies[i]])\n",
    "        mixed_sign = [mixed_sign ; fnames[goodies[i]]]\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find(fnames.==\"farm_F_0534\")\n",
    "scosts[534]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = matread(\"FarmFields/farm_F_0007\")\n",
    "\n",
    "args = A[\"args\"]\n",
    "pars = A[\"pars\"]\n",
    "nPro = A[\"nPro\"]\n",
    "nAnti = A[\"nAnti\"]\n",
    "rule_and_delay_periods = A[\"rule_and_delay_periods\"]\n",
    "post_target_periods    = A[\"post_target_periods\"]\n",
    "theta1 = A[\"theta1\"]\n",
    "theta2 = A[\"theta2\"]\n",
    "sr = A[\"sr\"]\n",
    "cb = A[\"cb\"]\n",
    "sbox = symbol_key_ize(A[\"sbox\"])\n",
    "bbox = symbol_key_ize(A[\"bbox\"])\n",
    "model_params = symbol_key_ize(A[\"model_params\"])\n",
    "\n",
    "\n",
    "func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "    theta1=theta1, theta2=theta2,\n",
    "    post_target_periods=post_target_periods,\n",
    "    seedrand=sr, cbeta=cb, verbose=true, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "standard_func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "    theta1=theta1, theta2=theta2,\n",
    "    post_target_periods=post_target_periods,\n",
    "seedrand=sr, cbeta=0.01, verbose=true, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "\n",
    "value, grad, hess = keyword_vgh(func, args, pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = matread(\"FarmFields/farm_F_0534\")\n",
    "\n",
    "args = A[\"args\"]\n",
    "pars = A[\"pars\"]\n",
    "nPro = A[\"nPro\"]\n",
    "nAnti = A[\"nAnti\"]\n",
    "rule_and_delay_periods = A[\"rule_and_delay_periods\"]\n",
    "post_target_periods    = A[\"post_target_periods\"]\n",
    "theta1 = A[\"theta1\"]\n",
    "theta2 = A[\"theta2\"]\n",
    "sr = A[\"sr\"]\n",
    "cb = A[\"cb\"]\n",
    "sbox = symbol_key_ize(A[\"sbox\"])\n",
    "bbox = symbol_key_ize(A[\"bbox\"])\n",
    "model_params = symbol_key_ize(A[\"model_params\"])\n",
    "\n",
    "\n",
    "func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "    theta1=theta1, theta2=theta2,\n",
    "    post_target_periods=post_target_periods,\n",
    "    seedrand=sr, cbeta=cb, verbose=true, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "standard_func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "    theta1=theta1, theta2=theta2,\n",
    "    post_target_periods=post_target_periods,\n",
    "seedrand=sr, cbeta=0.01, verbose=true, merge(model_params, Dict(params))...)[1]\n",
    "\n",
    "\n",
    "value, grad, hess = keyword_vgh(func, args, pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length(find(scosts.<scosts[534]))/length(scosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length(scosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a ProAnti optimization  \n",
    "\n",
    "This is the code that ran farm F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me   farming.jl\n",
    "\n",
    "# ======= ARGUMENTS AND SEED VALUES:\n",
    "args = [\"sW\", \"vW\", \"hW\", \"dW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\"]\n",
    "seed = [0.2,   1,   0.2,  1,    0.39,                0.15,                       0.1]\n",
    "\n",
    "args = [args ; [\"const_pro_bias\", \"sigma\"]]\n",
    "seed = [seed ; [0.1,               0.1]]\n",
    "\n",
    "\n",
    "# ======= BOUNDING BOX:\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :dW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :const_pro_bias=>[-2 2],\n",
    ":sigma=>[0.01 0.2])\n",
    "\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5))\n",
    "# seed = [0.0840597,  -1.32677,  -0.437334,  -0.324835,  0.567997, 0.712216,  0.0500075,  0.0858569,  0.25]\n",
    "\n",
    "\n",
    "# ======== SEARCH ZONE:\n",
    "\n",
    "sbox = Dict(:sW=>[0.001 0.5], :vW=>[-0.5 0.5], :hW=>[-0.5 0.5], :dW=>[-0.5 0.5],\n",
    ":constant_excitation=>[-0.5 0.5], :right_light_excitation=>[0.1 0.5], :target_period_excitation=>[0.1 0.5],\n",
    ":const_pro_bias=>[0 0.2], :sigma=>[0.02 0.19])\n",
    "\n",
    "cbetas = [0.02, 0.04]\n",
    "\n",
    "fbasename = \"FarmFields/farm_F_\"\n",
    "\n",
    "while true\n",
    "    myseed = seed;\n",
    "    sr = convert(Int64, round(time()))\n",
    "\n",
    "    myseed = copy(seed);\n",
    "    for i=1:length(args)\n",
    "        sym = Symbol(args[i])\n",
    "        if haskey(sbox, sym)\n",
    "            myseed[i] = sbox[sym][1] + diff(sbox[sym],2)[1]*rand()\n",
    "        end\n",
    "    end\n",
    "    nPro=100; nAnti=100\n",
    "\n",
    "    rule_and_delay_periods = [0.4, 1.2]\n",
    "    post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "    theta1 = 0.15; theta2 = 0.25\n",
    "\n",
    "    for cb in cbetas\n",
    "        func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "            theta1=theta1, theta2=theta2,\n",
    "            post_target_periods=post_target_periods,\n",
    "            seedrand=sr, cbeta=cb, verbose=false, merge(model_params, Dict(params))...)[1]\n",
    "        \n",
    "        # And at the standard cb=0.01 for comparison to other cbs\n",
    "        standard_func =  (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "            theta1=theta1, theta2=theta2,\n",
    "            post_target_periods=post_target_periods,\n",
    "            seedrand=sr, cbeta=0.01, verbose=false, merge(model_params, Dict(params))...)[1]        \n",
    "                \n",
    "        @printf(\"Going with seed = \"); print_vector_g(myseed); print(\"\\n\")\n",
    "        pars, traj, cost, cpm_traj = bbox_Hessian_keyword_minimization(myseed, args, bbox, func,\n",
    "            start_eta = 0.01, tol=1e-12, verbose=true, verbose_every=10, maxiter=400)\n",
    "        @printf(\"Came out with cost %g and pars = \", cost); print_vector_g(pars); print(\"\\n\\n\")\n",
    "\n",
    "        value, grad, hess = keyword_vgh(func, args, pars)\n",
    "        scost = standard_func(;make_dict(args, pars, model_params)...)\n",
    "        \n",
    "        myfilename = next_file(fbasename, 4)\n",
    "\n",
    "        matwrite(myfilename, Dict(\"args\"=>args, \"myseed\"=>myseed, \"pars\"=>pars, \"traj\"=>traj,\n",
    "        \"cost\"=>cost, \"cpm_traj\"=>cpm_traj, \"nPro\"=>nPro, \"nAnti\"=>nAnti, \"sr\"=>sr, \"cb\"=>cb,\n",
    "        \"theta1\"=>theta1, \"theta2\"=>theta2,\n",
    "        \"scost\"=>scost, \"value\"=>value, \"grad\"=>grad, \"hess\"=>hess,\n",
    "        \"model_params\"=>ascii_key_ize(model_params), \"bbox\"=>ascii_key_ize(bbox), \"sbox\"=>ascii_key_ize(sbox),\n",
    "        \"rule_and_delay_periods\"=>rule_and_delay_periods, \"post_target_periods\"=>post_target_periods))\n",
    "\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alex's farm G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me alex_farm_g0011.jl\n",
    "\n",
    "include(\"pro_anti.jl\")\n",
    "\n",
    "A = matread(\"FarmFields/farm_G_1.mat0011\")\n",
    "\n",
    "model_params = symbol_key_ize(A[\"model_params\"])\n",
    "for k in keys(A); print(k); print(\"  \"); end\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[args[:]  A[\"myseed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me alex_farm_g0011.jl\n",
    "\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :dW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :const_pro_bias=>[-2 2],\n",
    ":sigma=>[0.01 0.2]);\n",
    "\n",
    "model_params = symbol_key_ize(A[\"model_params\"])\n",
    "\n",
    "    rule_and_delay_periods = [0.4, 1.2]\n",
    "    post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "    standard_func =  (;params...) -> JJ(model_params[:nPro], model_params[:nAnti]; \n",
    "    rule_and_delay_periods=rule_and_delay_periods, theta1=model_params[:theta1], theta2=model_params[:theta2], \n",
    "    post_target_periods=post_target_periods,  seedrand=A[\"sr\"], cbeta=0.01, verbose=true, \n",
    "    merge(model_params, Dict(params))...)[1]        \n",
    "\n",
    "value, grad, hess = keyword_vgh(standard_func, A[\"args\"], A[\"myseed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me alex_farm_g0011.jl\n",
    "\n",
    "pars, traj, cost, cpm_traj = bbox_Hessian_keyword_minimization(A[\"myseed\"], A[\"args\"], bbox, standard_func,\n",
    "        start_eta = 0.03, tol=1e-18, verbose=true, verbose_every=1, maxiter=4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fnames = readdir(\"FarmFields/\")\n",
    "for f in filter(x -> startswith(x, \"farm_G_1.mat\"), readdir(\"FarmFields/\"))\n",
    "\n",
    "    A = matread(\"FarmFields/\" * f)\n",
    "    model_params = symbol_key_ize(A[\"model_params\"])\n",
    "\n",
    "    rule_and_delay_periods = [0.4, 1.2]\n",
    "    post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "    standard_func =  (;params...) -> JJ(model_params[:nPro], model_params[:nAnti]; \n",
    "    rule_and_delay_periods=rule_and_delay_periods, theta1=model_params[:theta1], theta2=model_params[:theta2], \n",
    "    post_target_periods=post_target_periods,  seedrand=A[\"sr\"], cbeta=0.01, verbose=true, \n",
    "    merge(model_params, Dict(params))...)[1]        \n",
    "\n",
    "    standard_func(;make_dict(A[\"args\"], A[\"pars\"])...)\n",
    "\n",
    "    @printf(\"File %s, niters was %d\\n\\n\", f, size(A[\"traj\"],2))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox -- the in flux crazy wilds from here on\n",
    "\n",
    "various things in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next_file(\"FarmFields/farm_E_\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cost = standard_cost(args, pars, sr, model_params)\n",
    "\n",
    "Computes the cost as if cb had been 0.01 and theta1=0.15 and theta2=0.25\n",
    "\"\"\"\n",
    "function standard_cost(args, pars, sr, model_params)\n",
    "    cb = 0.01\n",
    "    theta1 = 0.15\n",
    "    theta2 = 0.25\n",
    "    nPro=100; nAnti=100\n",
    "\n",
    "    rule_and_delay_periods = [0.4, 1.2]\n",
    "    post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "    func = (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "            post_target_periods=post_target_periods,\n",
    "            theta1=theta1, theta2=theta2, \n",
    "            seedrand=sr, cbeta=cb, verbose=false, merge(model_params, Dict(params))...)\n",
    "    \n",
    "    return func(;make_dict(args, pars)...)\n",
    "end\n",
    "    \n",
    "\"\"\"\n",
    "cost = standard_cost(filename)\n",
    "\n",
    "Returns the standard cost (at cb=0.01, theta1=0.15, theta2=0.25) and inserts it into the file with \n",
    "key \"scost2\" if it wasn't there already\n",
    "\"\"\"\n",
    "function standard_cost(filename; verbose=false)\n",
    "    A = matread(filename)\n",
    "    if !haskey(A, \"scost2\")\n",
    "        get!(A, \"scost2\", standard_cost(A[\"args\"], A[\"pars\"], A[\"sr\"], symbol_key_ize(A[\"model_params\"])))\n",
    "        if verbose\n",
    "            @printf(\"File %s did not have scost, adding its value %g\\n\", filename, A[\"scost\"])\n",
    "        end\n",
    "        matwrite(filename, A)\n",
    "    end\n",
    "    return A[\"scost\"]\n",
    "end\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "value, grad, hess = standard_vgh(args, pars, sr, model_params)\n",
    "\n",
    "Computes the value, gradient, and hessian as if cb had been 0.01 and theta1=0.15 and theta2=0.25\n",
    "\"\"\"\n",
    "function standard_vgh(args, pars, sr, model_params; theta1=0.025, theta2=0.035)\n",
    "    cb = 0.01\n",
    "    nPro=100; nAnti=100\n",
    "\n",
    "    rule_and_delay_periods = [0.4, 1.2]\n",
    "    post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "    func = (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "            post_target_periods=post_target_periods,\n",
    "            theta1=theta1, theta2=theta2, \n",
    "            seedrand=sr, cbeta=cb, verbose=false, merge(model_params, Dict(params))...)\n",
    "\n",
    "    value, grad, hess = keyword_vgh(func, args, pars)\n",
    "    \n",
    "    return value, grad, hess\n",
    "end\n",
    "\n",
    "func = (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods, verbose=true,\n",
    "            post_target_periods=post_target_periods,\n",
    "            theta1=theta1, theta2=theta2,\n",
    "            seedrand=sr, cbeta=cb, verbose=false, merge(my_params, Dict(params))...)[1]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "value, grad, hess = standard_vgh(filename)\n",
    "\n",
    "Returns the standard cost (at cb=0.01, theta1=0.15, theta2=0.25), gradient, and hessian\n",
    "and inserts them into the file with key \"scost2\", \"grad\" and \"hess\" if they weren't there already\n",
    "\"\"\"\n",
    "function standard_vgh(filename; verbose=false, force=false)\n",
    "    A = matread(filename)\n",
    "    if !haskey(A, \"theta1\"); get!(A, \"theta1\", 0.025); end\n",
    "    if !haskey(A, \"theta2\"); get!(A, \"theta2\", 0.035); end\n",
    "    if !haskey(A, \"rule_and_delay_periods\"); get!(A, \"rule_and_delay_periods\", [0.4, 1.2]); end;\n",
    "    if !haskey(A, \"post_target_periods\");    get!(A, \"post_target_periods\",    [0.5, 1.5]); end;\n",
    "      \n",
    "    if force || !haskey(A, \"value\") || !haskey(A, \"grad\")  || !haskey(A, \"hess\")\n",
    "        value, grad, hess = standard_vgh(A[\"args\"], A[\"pars\"], A[\"sr\"], \n",
    "        symbol_key_ize(A[\"model_params\"]); theta1=A[\"theta1\"], theta2=A[\"theta2\"]) \n",
    "        if !haskey(A, \"value\"); get!(A, \"value\", value); else A[\"value\"] = value; end;\n",
    "        if !haskey(A, \"grad\"); get!(A, \"grad\", grad); else A[\"grad\"] = grad; end;\n",
    "        if !haskey(A, \"hess\"); get!(A, \"hess\", hess); else A[\"hess\"] = hess; end;\n",
    "        if verbose\n",
    "            @printf(\"File %s did not have value or grad or hess, adding its value %g\\n\", filename, A[\"value\"])\n",
    "        end\n",
    "        matwrite(filename, A)\n",
    "    end\n",
    "    return A[\"value\"], A[\"grad\"], A[\"hess\"]\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A = matread(\"FarmFields/farm_E_0001\")\n",
    "# value, grad, hess = standard_vgh(A[\"args\"], A[\"pars\"], A[\"sr\"], symbol_key_ize(A[\"model_params\"]))\n",
    "standard_vgh(\"FarmFields/farm_A_0001\"; verbose=true, force=true)\n",
    "A = matread(\"FarmFields/farm_A_0001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval(Symbol(\"hess\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standard_vgh(\"FarmFields/farm_A_0001\", verbose=true)\n",
    "A = matread(\"FarmFields/farm_A_0001\")\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = matread(\"farm_A_0001\")\n",
    "@printf(\"At cb=0.002, cost was %g. At cb=0.01, cost was %g\\n\", A[\"cost\"], standard_cost(\"farm_A_0001\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the next three cells, in sequence, to see results of an individual farm animal and to see computation of gradient and hessian of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = matread(\"FarmFields/farm_G_1.mat0001\")\n",
    "model_params = symbol_key_ize(A[\"model_params\"])\n",
    "args         = A[\"args\"];\n",
    "nAnti        = A[\"nAnti\"]\n",
    "nPro         = A[\"nPro\"]\n",
    "pars         = A[\"pars\"]\n",
    "sr           = A[\"sr\"]\n",
    "traj         = A[\"traj\"]\n",
    "cpm_traj     = A[\"cpm_traj\"]\n",
    "cb           = A[\"cb\"]\n",
    "theta1       = A[\"theta1\"]\n",
    "theta2       = A[\"theta2\"]\n",
    "rule_and_delay_periods = A[\"rule_and_delay_periods\"]\n",
    "post_target_periods    = A[\"post_target_periods\"]\n",
    "\n",
    "\n",
    "@printf(\"Cost went from %g to %g (at standard beta=0.01, cost ended at %g); max iters on cpm was %d\\n\\n\", \n",
    "traj[2,1], traj[2,end], A[\"scost\"], maximum(cpm_traj[1,:]))\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_seed = [0.0840597,  -1.32677,  -0.437334,  -0.324835,  0.567997, 0.712216,  0.0500075,  0.0858569,  0.25]\n",
    "\n",
    "[args pars good_seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NOW EVALUATE RESULTS HERE\n",
    "# --------------------\n",
    "\n",
    "my_params = make_dict([args; \"plot_list\"; \"post_target_period\"; \"rule_and_delay_period\"; \"dt\"], \n",
    "[pars; [[1:10;]]; 0.2; 0.4; 0.02], model_params)\n",
    "\n",
    "run_factor = 2\n",
    "\n",
    "proVs, antiVs = @time(run_ntrials(nPro*run_factor, nAnti*run_factor; plot_list=[], my_params...))\n",
    "\n",
    "if nPro>0;  @printf(\"Pro %% correct = %g%%\\n\", 100*length(find(proVs[1,:].>proVs[4,:]))/(nPro*run_factor)); end;\n",
    "if nAnti>0; @printf(\"Anti %% correct = %g%% \\n\", 100*length(find(antiVs[1,:].<antiVs[4,:]))/(nAnti*run_factor)); end;\n",
    "\n",
    "\n",
    "figure(3); clf();\n",
    "ax1 = subplot(2,1,1)\n",
    "h = plt[:hist](proVs[1,:]-proVs[4,:],-1:0.02:1)\n",
    "title(\"PRO Vr - Vl\")\n",
    "remove_xtick_labels(ax1)\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "ax2 = subplot(2,1,2)\n",
    "h = plt[:hist](antiVs[1,:]-antiVs[4,:],-1:0.02:1)\n",
    "title(\"ANTI Vr - Vl\")\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "figure(1); clf(); figure(2); clf();\n",
    "\n",
    "JJ(nPro, nAnti; verbose=true, seedrand=sr, rule_and_delay_periods=my_params[:rule_and_delay_period], \n",
    "post_target_periods=my_params[:post_target_period], my_params...)\n",
    "\n",
    "\n",
    "# A function that takes only keyword-value pairs and returns a scalar. Its default parameter values are the result\n",
    "# of the farm (as put into my_params, which hold the farm's output)\n",
    "func = (;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods, verbose=true,\n",
    "            post_target_periods=post_target_periods,\n",
    "            theta1=theta1, theta2=theta2,\n",
    "            seedrand=sr, cbeta=cb, verbose=false, merge(my_params, Dict(params))...)[1]\n",
    "\n",
    "# keyword_vgh takes that kind of function\n",
    "cost, grad, hess = keyword_vgh(func, args, pars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traj[:,end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the results across many farm animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basename = \"farm_G_1.mat\"\n",
    "fnames = readdir(\"FarmFields\")\n",
    "matched_filenames = Array{Bool}(length(fnames))\n",
    "for i=1:length(fnames)\n",
    "    matched_filenames[i] = ismatch(Regex(@sprintf(\"^%s\", basename)), fnames[i])\n",
    "end\n",
    "myguys = fnames[find(matched_filenames)]\n",
    "costs  = zeros(size(myguys))\n",
    "cbs    = zeros(size(myguys))\n",
    "nsteps = zeros(size(myguys)) \n",
    "for i=1:length(myguys)\n",
    "    A = matread(\"FarmFields/\" * myguys[i])\n",
    "    costs[i]  = A[\"cost\"] # standard_cost(myguys[i]; verbose=true)\n",
    "    cbs[i]    = A[\"cb\"]\n",
    "    nsteps[i] = size(A[\"traj\"],2)\n",
    "end\n",
    "\n",
    "\n",
    "cbset = unique(cbs)\n",
    "\n",
    "figure(3); clf();\n",
    "for i=1:length(cbset)    \n",
    "    ax1 = subplot(length(cbset),1,i)\n",
    "    h1 = plt[:hist](costs[find(cbs.==cbset[i])]) # , -0.02:0.001:0.008);\n",
    "    ylabel(\"# of runs\")\n",
    "    title(@sprintf(\"cb=%g  (%d total)\", cbset[i], length(find(cbs.==cbset[i]))))\n",
    "    if i < length(cbset)\n",
    "        remove_xtick_labels(ax1)\n",
    "    end\n",
    "    if i==length(cbset)\n",
    "        xlabel(\"final cost\")\n",
    "    end\n",
    "end\n",
    "        \n",
    "unique(cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(3); clf()\n",
    "plt[:hist](nsteps, 0:2:400);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = matread(\"FarmFields/farm_G_1.mat0001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of 9-param, including diagonal weight and sigma, and robust across 3x in rule/delay period and post-target period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = [\"sW\", \"vW\", \"hW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\", \"sigma\"]\n",
    "seed = [0.2,   -1.7, -1.7,      0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   0.17,  0.17,      0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   -1.7, -1.7,      -0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   -1.7, -1.7,      0.39,                0.15,                       0.1,                     0.1]\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :sigma=>[0.05 1])\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5))\n",
    "\n",
    "\n",
    "# Now with constant_pro_bias and a fixed sigma=0.1\n",
    "args = [\"sW\", \"vW\", \"hW\", \"dW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\"]\n",
    "seed = [0.2,   -1.7, -1.7,  0,    0.39,                0.15,                       0.1]\n",
    "args = [args ; [\"const_pro_bias\", \"sigma\"]]\n",
    "seed = [seed ; [0.1,               0.1]]\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5))\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :dW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :const_pro_bias=>[-2 2],\n",
    ":sigma=>[0.01 0.25])\n",
    "\n",
    "# seed = [0.0840597,  -1.32677,  -0.437334,  -0.324835,  0.567997, 0.712216,  0.0500075,  0.0858569,  0.25]\n",
    "\n",
    "# ==========\n",
    "\n",
    "nPro=100; nAnti=100\n",
    "\n",
    "rule_and_delay_periods = [0.4, 1.2]\n",
    "post_target_periods    = [0.5, 1.5]\n",
    "\n",
    "pars, traj, cost, cpm_traj = bbox_Hessian_keyword_minimization(seed, args, bbox, \n",
    "(;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "post_target_periods=post_target_periods,\n",
    "seedrand=31, cbeta=0.01, verbose=true, merge(model_params, Dict(params))...),\n",
    "start_eta = 0.01, tol=1e-9, verbose=true)\n",
    "\n",
    "pars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[args pars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NOW EVALUATE RESULTS HERE\n",
    "# --------------------\n",
    "\n",
    "my_params = make_dict([args; \"plot_list\"; \"post_target_period\"; \"rule_and_delay_period\"; \"dt\"], \n",
    "[pars; [[1:10;]]; 1.5; 1; 0.01], model_params)\n",
    "\n",
    "run_factor = 10\n",
    "\n",
    "proVs, antiVs = @time(run_ntrials(nPro*run_factor, nAnti*run_factor; plot_list=[], my_params...))\n",
    "\n",
    "if nPro>0;  @printf(\"Pro %% correct = %g%%\\n\", 100*length(find(proVs[1,:].>proVs[4,:]))/(nPro*run_factor)); end;\n",
    "if nAnti>0; @printf(\"Anti %% correct = %g%% \\n\", 100*length(find(antiVs[1,:].<antiVs[4,:]))/(nAnti*run_factor)); end;\n",
    "\n",
    "\n",
    "figure(3); clf();\n",
    "ax1 = subplot(2,1,1)\n",
    "h = plt[:hist](proVs[1,:]-proVs[4,:],-1:0.02:1)\n",
    "title(\"PRO Vr - Vl\")\n",
    "remove_xtick_labels(ax1)\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "ax2 = subplot(2,1,2)\n",
    "h = plt[:hist](antiVs[1,:]-antiVs[4,:],-1:0.02:1)\n",
    "title(\"ANTI Vr - Vl\")\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "figure(1); clf(); figure(2); clf();\n",
    "\n",
    "JJ(nPro, nAnti; rule_and_delay_periods=my_params[:rule_and_delay_period], \n",
    "post_target_periods=my_params[:post_target_period], my_params...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a ProAnti network optimization\n",
    "\n",
    "This one uses two rule periods and two post_target_periods to try to get some stability in the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = [\"sW\", \"vW\", \"hW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\", \"sigma\"]\n",
    "seed = [0.2,   -1.7, -1.7,      0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   0.17,  0.17,      0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   -1.7, -1.7,      -0.19,                0.5,                       1,                       0.1]\n",
    "seed = [0.2,   -1.7, -1.7,      0.39,                0.15,                       0.1,                       0.1]\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :sigma=>[0.05 1])\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5))\n",
    "\n",
    "\n",
    "# Now with constant_pro_bias and a fixed sigma=0.1\n",
    "args = [\"sW\", \"vW\", \"hW\", \"constant_excitation\", \"right_light_excitation\", \"target_period_excitation\", \"const_pro_bias\"]\n",
    "seed = [0.2,   -1.7, -1.7,      0.39,                0.15,                       0.1,                       0.1]\n",
    "model_params = merge(model_params, Dict(:post_target_period=>0.5, :sigma=>0.1))\n",
    "bbox = Dict(:sW=>[0 3], :vW=>[-3 3], :hW=>[-3 3], :constant_excitation=>[-2 2],\n",
    ":right_light_excitation=>[0.05 4], :target_period_excitation=>[0.05 4], :const_pro_bias=>[-2 2])\n",
    "\n",
    "# ==========\n",
    "\n",
    "nPro=100; nAnti=100\n",
    "\n",
    "rule_and_delay_periods = [0.4, 0.8]\n",
    "post_target_periods    = [0.5, 1]\n",
    "\n",
    "pars, traj, cost, cpm_traj = bbox_Hessian_keyword_minimization(seed, args, bbox, \n",
    "(;params...) -> JJ(nPro, nAnti; rule_and_delay_periods=rule_and_delay_periods,\n",
    "post_target_periods=post_target_periods,\n",
    "seedrand=31, cbeta=0.01, verbose=true, merge(model_params, Dict(params))...),\n",
    "start_eta = 0.01, tol=1e-12, verbose=true, maxiter=2)\n",
    "\n",
    "pars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NOW EVALUATE RESULTS HERE\n",
    "# --------------------\n",
    "\n",
    "my_params = make_dict([args; \"plot_list\"; \"post_target_period\"; \"rule_and_delay_period\"; \"dt\"], \n",
    "[pars; [[1:10;]]; 1.5; 0.5; 0.02], model_params)\n",
    "\n",
    "run_factor = 10\n",
    "\n",
    "proVs, antiVs = @time(run_ntrials(nPro*run_factor, nAnti*run_factor; plot_list=[], my_params...))\n",
    "\n",
    "if nPro>0;  @printf(\"Pro %% correct = %g%%\\n\", 100*length(find(proVs[1,:].>proVs[4,:]))/(nPro*run_factor)); end;\n",
    "if nAnti>0; @printf(\"Anti %% correct = %g%% \\n\", 100*length(find(antiVs[1,:].<antiVs[4,:]))/(nAnti*run_factor)); end;\n",
    "\n",
    "\n",
    "figure(3); clf();\n",
    "ax1 = subplot(2,1,1)\n",
    "h = plt[:hist](proVs[1,:]-proVs[4,:],-1:0.02:1)\n",
    "title(\"PRO Vr - Vl\")\n",
    "remove_xtick_labels(ax1)\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "ax2 = subplot(2,1,2)\n",
    "h = plt[:hist](antiVs[1,:]-antiVs[4,:],-1:0.02:1)\n",
    "title(\"ANTI Vr - Vl\")\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "figure(1); clf(); figure(2); clf();\n",
    "\n",
    "JJ(nPro, nAnti; rule_and_delay_periods=my_params[:rule_and_delay_period], \n",
    "post_target_periods=my_params[:post_target_period], my_params...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#                                                    #\n",
    "#         BBOX_HESSIAN_KEYWORD_MINIMIZATION          #\n",
    "#                                                    #\n",
    "######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pdict = wallwrap(bdict, pdict)\n",
    "Given bdict, a dictionary of symbols to [minval, maxval] vectors, and pdict, a dictionary of symbols\n",
    "to values (or, alternatively, an Array of (Symbol, value) tuples], goes through each of the symbols in \n",
    "bdict and modifies the corresponding value in pdict putting it through a tanh so the final output lies \n",
    "within the limits in bdict.  Returns the new pdict.  Makes a copy of pdict so as not to modify the original.\n",
    "\"\"\"\n",
    "function wallwrap(bdict, epdict)\n",
    "    local pdict = two_level_copy(epdict)\n",
    "    if typeof(pdict)<:Array\n",
    "        pdict = Dict(pdict)\n",
    "    end\n",
    "\n",
    "    allkeys = keys(bdict)\n",
    "\n",
    "    for k in allkeys\n",
    "        local bbox = bdict[k]\n",
    "        d = 0.5*(bbox[2] - bbox[1])\n",
    "        m = 0.5*(bbox[2] + bbox[1])\n",
    "\n",
    "        pdict[k] = bbox[1] + d*(tanh((pdict[k]-m)/d)+1)\n",
    "    end\n",
    "    return pdict\n",
    "end\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "params = vector_wrap(bbox, args, eparams)\n",
    "Given bdict, a dictionary of symbols to [minval, maxval] vectors, args, an array of strings representing\n",
    "symbols, and params, an array of values corresponding to the args list, puts each param that has an entry \n",
    "in bdict through the tanh-walling mechanism, and returns the result. Does not modify the contents of the \n",
    "original params vector (or bdict or args).\n",
    "\"\"\"\n",
    "function vector_wrap(bbox, args, eparams)\n",
    "    local params = two_level_copy(eparams)\n",
    "    pdict = wallwrap(bbox, make_dict(args, params))\n",
    "    i=1; j=1\n",
    "    for i=1:length(args)\n",
    "        if typeof(args[i])<:Array\n",
    "            params[j:j+args[i][2]-1] = pdict[Symbol(args[i][1])]\n",
    "            j += args[i][2]-1\n",
    "        else\n",
    "            params[j] = pdict[Symbol(args[i])]\n",
    "        end\n",
    "    j = j+1\n",
    "    end\n",
    "    return params\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "params = inverse_wall(bdict, args, wparams)\n",
    "Given bdict, a dictionary of symbols to [minval, maxval] vectors, args, an array of strings representing\n",
    "symbols, and wparams, an array of values corresponding to the args list where each param that has an entry \n",
    "in bdict has alreadt been through the tanh-walling mechanism, UNwalls the ones that have a bdict entry and\n",
    "returns the result. Does not modify the contents of the original params vector (or bdict or args).\n",
    "\"\"\"\n",
    "function inverse_wall(bdict, args, wparams)\n",
    "    local params = two_level_copy(wparams)\n",
    "    pdict = inverse_wall(bdict, make_dict(args, params))\n",
    "    i=1; j=1\n",
    "    for i=1:length(args)\n",
    "        if typeof(args[i])<:Array\n",
    "            params[j:j+args[i][2]-1] = pdict[Symbol(args[i][1])]\n",
    "            j += args[i][2]-1\n",
    "        else\n",
    "            params[j] = pdict[Symbol(args[i])]\n",
    "        end\n",
    "        j = j+1\n",
    "    end\n",
    "    return params    \n",
    "end\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "pdict = inverse_wall(bdict, wdict)\n",
    "Given bdict, a dictionary of symbols to [minval, maxval] vectors, and wdict, a dictionary of symbols to values\n",
    "(or vectors of values)  UNwalls the ones that have a bdict entry and\n",
    "returns the result. Does not modify the contents of any dictionaries.\n",
    "\"\"\"\n",
    "function inverse_wall(bdict, wdict)\n",
    "    local pdict = two_level_copy(wdict)\n",
    "\n",
    "    allkeys = keys(bdict)\n",
    "    for k in allkeys\n",
    "        local bbox = bdict[k]\n",
    "        d = 0.5*(bbox[2] - bbox[1])\n",
    "        m = 0.5*(bbox[2] + bbox[1])\n",
    "\n",
    "        try\n",
    "            pdict[k] = m + d*0.5*log((pdict[k]-bbox[1])./(2*d - pdict[k] + bbox[1]))\n",
    "        catch\n",
    "            error(@sprintf(\"Had trouble with key %s\", string(k)))\n",
    "        end\n",
    "    end\n",
    "    return(pdict)\n",
    "end\n",
    "  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function bbox_Hessian_keyword_minimization(seed, args, bbox, func; wallwidth=NaN, start_eta=10, tol=1e-6, \n",
    "    maxiter=400, verbose=false)\n",
    "\n",
    "Like constrained_Hessian_minimization, but uses keyword_hessian!(). \n",
    "\n",
    "# PARAMETERS:\n",
    "\n",
    "- seed        column vector, representing the starting value of the parameters.\n",
    "\n",
    "- args        List of strings identifying parameters for differentiation, e.g., [\"const_E\", \"w_self]\n",
    "\n",
    "- bbox        If softbox=true (the default), should then be a Dict of Symbol=>[minval maxval] entries. An entry\n",
    "            in this Dict indicates that the corresponding parameter is to be bounded, as indicated by the associated \n",
    "            [minval maxval] vector. The bbox dictionary can have fewer entries than the number of parameters, and its\n",
    "            default value is Dict(), indicating an unbounded search.\n",
    "                If softbox=false, then bbox should be an nargs-by-2 matrix indicating the range for each argument,\n",
    "            with the minima (first column) and maxima (second column), and entries for ALL parameters.\n",
    "\n",
    "- func        func must take only optional keyword args, and must \n",
    "            take nderivs=0, difforder=0  and declare any new matrices using ForwardDiffZeros() instead of zeros()\n",
    "\n",
    "\n",
    "# OPTIONAL PARAMETERS:\n",
    "\n",
    "- start_eta    Starting value of the radius.  It's good to start with somethibg biggish, if it is\n",
    "             too much, it'll quickly get cut down.\n",
    "\n",
    "- tol=1e-6     Numerical tolerance. If a proposed jump produces a change in func that is less than\n",
    "             this, the minimization stops.\n",
    "\n",
    "- maxiter=400  Maximum number of iterations to do before stopping\n",
    "\n",
    "- verbose=false   If true, print out a report on each iteration of iteration number, radius size (eta),\n",
    "                what type jump was proposed (\"Newton\" means going straight to global min, \"constrained\" means jump has \n",
    "                norm eta, failed means that finding the minimum at a given radius somehow didn't work). Will also\n",
    "                print out the cosine of the angle between the proposed jump and the gradient.\n",
    "\n",
    "- verbose_level   If less than 2, regular verbose output, if 2 or greater, very verbose, for debugging.\n",
    "\n",
    "- softbox         If true, then bbox must be a Dict() and we use the tanh() mechanism for putting a fixed limit\n",
    "                on the parameters.\n",
    "\n",
    "- hardbox=false   If true, ignores wallwidth, and just rests parameter values to the bounding box if they go outside it.\n",
    "                If false, adds cost function \"walls\" to implement the bounding box.\n",
    "\n",
    "- walldith=NaN     Used for putting up cost function \"walls\" that implement the bounding box limits. Can be NaN.\n",
    "                If it is NaN, then the wallwidth is a constant factor of the range width for each argument. If not NaN, must\n",
    "                be an nargs-long vector that indicates the actual wall widths.\n",
    "\n",
    "- wallwidth_factor=0.18   Only relevant if wallwidth is NaN, otherwise ignored. For each arg, the wall width\n",
    "                is going to be wall_width_factor*(bbox[i,2] - bbox[i,1])\n",
    "\n",
    "\n",
    "# RETURNS:\n",
    "\n",
    "- params       A vector the size of seed that has the last values of the minimizing parameters for func\n",
    "- trajectory   A (2+length(params))-by-nsteps matrix. Each column corresponds to an iteration step, and contains\n",
    "                 the value of eta used, the cost, and the value of the parameters at that iteration\n",
    "- cost         Final value of objective function\n",
    "- cpm_traj     A 2-by-nsteps matrix, containing reports from the contrained parabolic minimization at each timestep.\n",
    "             The first row is niters (how many iterations cpm's 1-d minimization ran for) and the second row is\n",
    "             Dlambda, the last change in the parameter being minimized in cpm's internal search\n",
    "\n",
    "\n",
    "# EXAMPLE:\n",
    "\n",
    "```\n",
    "function tester(;x=5, y=10, z=20, nderivs=0, difforder=0)\n",
    "    return x^2*y + z/tanh(y)\n",
    "end\n",
    "\n",
    "params, trajectory = bbox_Hessian_keyword_minimization([0.5, 0.5], [\"x\", \"y\"], [1.1 2 ; 1.1 4], tester, \n",
    "    verbose=true, tol=1e-12, start_eta=1);\n",
    "```\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function bbox_Hessian_keyword_minimization(seed, args, bbox, func; start_eta=0.1, tol=1e-6, maxiter=400,\n",
    "    verbose=false, verbose_level=1, verbose_every=1, \n",
    "    softbox=true, hardbox=false, wallwidth=NaN, wallwidth_factor=0.18)\n",
    "\n",
    "      \n",
    "    \"\"\"\n",
    "    Given args, a list of string representing the arguments of interest, a bounding box for each,\n",
    "    and a Symbol=>value dictionary with the corresponding parameters, computes and returns a high cost for \n",
    "    being outside the bounding box\n",
    "    \"\"\"\n",
    "    function wall_cost(args, bbox; wallwidth=NaN, nderivs=0, difforder=0, pars...) \n",
    "        myparams = ForwardDiffZeros(length(pars), 1, nderivs=nderivs, difforder=difforder)\n",
    "        pars2 = Dict()\n",
    "        for i in [1:length(pars);]\n",
    "            pars2[string(pars[i][1])] = pars[i][2]\n",
    "        end\n",
    "        for i in [1:length(args);]\n",
    "            myparams[i] = pars2[args[i]]\n",
    "        end\n",
    "        \n",
    "        if isnan(wallwidth)\n",
    "            # We know that we're going to be taking hessian for params, so declare zeros accordingly:\n",
    "            wallwidth = ForwardDiffZeros(length(myparams), 1, nderivs=nderivs, difforder=difforder)\n",
    "\n",
    "            for i in [1:length(myparams);]\n",
    "                wallwidth[i] = wallwidth_factor*(bbox[i,2]-bbox[i,1])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        retval = 0\n",
    "        for i in [1:length(myparams);]\n",
    "            if myparams[i]<bbox[i,1]\n",
    "                retval += cosh((bbox[i,1]-myparams[i])/wallwidth[i])-1.0\n",
    "            elseif bbox[i,2] < myparams[i]\n",
    "                retval += cosh((myparams[i]-bbox[i,2])/wallwidth[i])-1.0                \n",
    "            end\n",
    "        end\n",
    "\n",
    "        return 2*retval\n",
    "    end\n",
    "\n",
    "    traj_increment = 100\n",
    "    params = 0  # Make sure to have this here so that params stays defined beyond the try/catch\n",
    "    if ( !(typeof(bbox)<:Dict) ); error(\"Currently only supporting softbox=true, bbox must be a Dict\"); end;\n",
    "    try\n",
    "        params = copy(inverse_wall(bbox, args, seed))\n",
    "    catch y\n",
    "        @printf(\"inverse_wall failed with error %s\\n\", y)\n",
    "        error(\"Were all initial param values within the indicated walls?\")\n",
    "    end\n",
    "    eta = start_eta\n",
    "    trajectory = zeros(2+length(params), traj_increment); cpm_traj = zeros(2, traj_increment)\n",
    "\n",
    "    if verbose\n",
    "        @printf \"%d: eta=%g ps=\" 0 eta \n",
    "        print_vector(vector_wrap(bbox, args, params))\n",
    "        @printf \"\\n\"\n",
    "    end\n",
    "    \n",
    "    if softbox\n",
    "        if !(typeof(bbox)<:Dict); error(\"bhm: If softbox=true, then bbox must eb a Dict\"); end\n",
    "        cost, grad, hess = keyword_vgh((;pars...)->func(;wallwrap(bbox, pars)...), args, params)\n",
    "    elseif hardbox\n",
    "        cost, grad, hess = keyword_vgh((;pars...) -> func(;pars...), args, params)\n",
    "    else\n",
    "        cost, grad, hess = keyword_vgh((;pars...) -> func(;pars...) + wall_cost(args, bbox; wallwidth=wallwidth, pars...),\n",
    "            args, params)        \n",
    "    end\n",
    "        \n",
    "    chessdelta = zeros(size(params))\n",
    "    \n",
    "    i=0  # here so variable i is available outside the loop\n",
    "    for i in [1:maxiter;]\n",
    "        if i > size(trajectory, 2)\n",
    "            trajectory = [trajectory zeros(2+length(params), traj_increment)]\n",
    "            cpm_traj   = [cpm_traj   zeros(2, traj_increment)]\n",
    "        end\n",
    "        trajectory[1:2, i]   = [eta;cost]\n",
    "        trajectory[3:end, i] = vector_wrap(bbox, args, params)\n",
    "        \n",
    "        hessdelta  = - inv(hess)*grad\n",
    "        try\n",
    "            if verbose && verbose_level >= 2\n",
    "                @printf(\"bhm: about to try cpm with grad : \"); print_vector_g(grad); print(\"\\n\")\n",
    "                @printf(\"bhm:   hess :\"); print_vector_g(hess[:]); print(\"\\n\");\n",
    "            end\n",
    "            if verbose && verbose_level >= 2\n",
    "                cpm_out = constrained_parabolic_minimization(hess, grad'', eta, \n",
    "                    maxiter=500, tol=1e-20, do_plot=true, verbose=true)                \n",
    "            else\n",
    "                cpm_out = constrained_parabolic_minimization(hess, grad'', eta, maxiter=500, tol=1e-20)\n",
    "            end\n",
    "            chessdelta = cpm_out[1]; cpm_traj[1,i] = cpm_out[5]; cpm_traj[2,i] = cpm_out[6]\n",
    "            jumptype = \"not failed\"\n",
    "        catch y\n",
    "            jumptype = \"failed\"\n",
    "            if verbose\n",
    "                @printf \"Constrained parabolic minimization failed with error %s\\n\" y\n",
    "                @printf \"\\n\"\n",
    "                @printf \"eta was %g\\n\" eta\n",
    "                @printf \"grad was\\n\"\n",
    "                print_vector(grad)\n",
    "                @printf \"\\n\\nhess was\\n\"\n",
    "                for k in [1:length(grad);]\n",
    "                    print_vector(hess[k,:])\n",
    "                    @printf \"\\n\"\n",
    "                end\n",
    "                @printf \"\\n\"\n",
    "                matwrite(\"error_report.mat\", Dict(\"grad\"=>grad, \"hess\"=>hess, \"eta\"=>eta))\n",
    "            end\n",
    "            break\n",
    "        end\n",
    "\n",
    "        if norm(hessdelta) <= eta\n",
    "            new_params = params + hessdelta\n",
    "            jumptype = \"Newton\"\n",
    "        elseif jumptype != \"failed\" \n",
    "            new_params = params + chessdelta\n",
    "            jumptype  = \"constrained\"\n",
    "        end\n",
    "\n",
    "        if jumptype != \"failed\"\n",
    "            if softbox\n",
    "                new_cost, new_grad, new_hess = \n",
    "                    keyword_vgh((;pars...) -> func(;wallwrap(bbox, pars)...), args, new_params)\n",
    "                if verbose && verbose_level >=2\n",
    "                    @printf(\"bhm: had new_params = : \"); print_vector_g(vector_wrap(bbox, args, params)); print(\"\\n\");\n",
    "                    @printf(\"bhm: and my bbox was : \"); print(bbox); print(\"\\n\")\n",
    "                    @printf(\"bhm: and my wallwrap output was : \"); print(wallwrap(bbox, make_dict(args, new_params))); print(\"\\n\")\n",
    "                    @printf(\"bhm: and this produced new_grad : \"); print_vector_g(new_grad); print(\"\\n\")\n",
    "                    @printf(\"bhm:   new_hess :\"); print_vector_g(new_hess[:]); print(\"\\n\");                                        \n",
    "                end\n",
    "            elseif hardbox\n",
    "                for p in [1:length(new_params);]\n",
    "                    if new_params[p] < bbox[p,1]; new_params[p] = bbox[p,1]; end\n",
    "                    if bbox[p,2] < new_params[p]; new_params[p] = bbox[p,2]; end\n",
    "                 end        \n",
    "                \n",
    "                new_cost, new_grad, new_hess = keyword_vgh((;pars...) -> func(;pars...), args, new_params)\n",
    "            else\n",
    "                new_cost, new_grad, new_hess = keyword_vgh((;pars...) -> func(;pars...) + \n",
    "                        wall_cost(args, bbox; wallwidth=wallwidth, pars...),\n",
    "                    args, new_params)                \n",
    "            end\n",
    "            \n",
    "            if abs(new_cost - cost) < tol || eta < tol\n",
    "                if verbose\n",
    "                    @printf(\"About to break -- tol=%g, new_cost-cost=%g, eta=%g\\n\", tol, new_cost-cost, eta)\n",
    "                end\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if jumptype == \"failed\" || new_cost >= cost  \n",
    "            if verbose\n",
    "                @printf(\"eta going down: new_cost-cost=%g and jumptype='%s'\\n\", new_cost-cost, jumptype)\n",
    "                if verbose_level >= 2\n",
    "                    nwp = vector_wrap(bbox, args, new_params); wp = vector_wrap(bbox, args, params)\n",
    "                    @printf(\"   vvv: proposed new params were : \"); print_vector_g(nwp); print(\"\\n\")\n",
    "                    @printf(\"   vvv: proposed delta params was : \"); print_vector_g(nwp-wp); print(\"\\n\")\n",
    "                    @printf(\"   vvv: grad was : \"); print_vector_g(grad); print(\"\\n\")\n",
    "                    costheta = dot(new_params-params, grad)/(norm(new_params-params)*norm(grad))\n",
    "                    @printf(\"   vvv: costheta of proposed jump was %g\\n\", costheta)\n",
    "                end\n",
    "            end\n",
    "            eta = eta/2\n",
    "            costheta = NaN\n",
    "            if eta < tol\n",
    "                if verbose\n",
    "                    @printf(\"About to break -- tol=%g, new_cost-cost=%g, eta=%g\\n\", tol, new_cost-cost, eta)\n",
    "                end\n",
    "                break\n",
    "            end\n",
    "        else\n",
    "            eta = eta*1.1\n",
    "            costheta = dot(new_params-params, grad)/(norm(new_params-params)*norm(grad))\n",
    "\n",
    "            params = new_params\n",
    "            cost = new_cost\n",
    "            grad = new_grad\n",
    "            hess = new_hess\n",
    "        end\n",
    "\n",
    "        if verbose\n",
    "            if rem(i, verbose_every)==0\n",
    "                @printf \"%d: eta=%g cost=%g jtype=%s costheta=%.3f ps=\" i eta cost jumptype costheta\n",
    "                print_vector_g(vector_wrap(bbox, args, params))\n",
    "                @printf \"\\n\"\n",
    "                if verbose_level >= 3\n",
    "                    @printf \"    At this point, grad is =\"\n",
    "                    print_vector_g(grad)\n",
    "                    @printf \"\\n\"                \n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    trajectory = trajectory[:,1:i]; cpm_traj = cpm_traj[:,1:i]\n",
    "    return vector_wrap(bbox, args, params), trajectory, cost, cpm_traj\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbox_Hessian_keyword_minimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the distribution of VR - VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrials = 500\n",
    "proVs, antiVs = @time(run_ntrials(ntrials; plot_list=[], model_params...))\n",
    "\n",
    "@printf(\"Pro %% correct = %g%%\\n\", 100*length(find(proVs[1,:].>proVs[4,:]))/ntrials)\n",
    "@printf(\"Anti %% correct = %g%% \\n\", 100*length(find(antiVs[1,:].<antiVs[4,:]))/ntrials)\n",
    "\n",
    "figure(1); clf();\n",
    "ax1 = subplot(2,1,1)\n",
    "h = plt[:hist](proVs[1,:]-proVs[4,:],-0.1:0.002:0.1)\n",
    "title(\"PRO Vr - Vl\")\n",
    "remove_xtick_labels(ax1)\n",
    "vlines(0, ylim()[1], ylim()[2])\n",
    "\n",
    "ax2 = subplot(2,1,2)\n",
    "h = plt[:hist](antiVs[1,:]-antiVs[4,:],-0.1:0.002:0.1)\n",
    "title(\"ANTI Vr - Vl\")\n",
    "vlines(0, ylim()[1], ylim()[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
