{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "using PyPlot\n",
    "using ForwardDiff\n",
    "using DiffBase\n",
    "\n",
    "pygui(true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main model dynamics function\n",
    "\n",
    "Note that the documenation indicates some default values for the optional parameters; these values need to be updated to what the code actually says below. The actual defaults are much closer to what Marino's May 2017 model has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_dynamics"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\" \n",
    "function t, U, V, W = run_dynamics(trial_type, params)\n",
    "\n",
    "    Runs the 4-way mutual inhibition model\n",
    "    \n",
    "    Params: vert w; horiz w; pro bias; delay input\n",
    "    \n",
    "\"\"\"\n",
    "function run_dynamics(trial_type, params::Vector ; opto_cue=1, opto_delay=1, opto_choice=1,\n",
    "    light_input=12, noisefr=0.1, threshold=0.18,\n",
    "    tau=4.4, dt=0.05, start_U = [-25, -25, -25, -25],\n",
    "    g_leak = 1, U_rest = 0, theta = 5, beta = 50, do_plot = false, fignum=1,\n",
    "    cue_period = 200, delay_period = 200, choice_period = 50)\n",
    "    \n",
    "    vwi = params[1]; hwi = params[2]; pro_bias = params[3]; delay_input = params[4]\n",
    "    \n",
    "    t = [0 : dt : cue_period + delay_period + choice_period;]\n",
    "\n",
    "    V = zeros(eltype(params), 4, length(t))   # the eltype(params) is for ForwardDiff\n",
    "    U = zeros(eltype(params), 4, length(t))\n",
    "\n",
    "    U[:,1] = start_U\n",
    "\n",
    "    W = [0 -vwi -hwi 0; -vwi 0 0 -hwi;\n",
    "        -hwi 0 0 -vwi; 0 -hwi -vwi 0]\n",
    "\n",
    "\n",
    "    for i in [2:length(t);]  # the funny semicolon appears to be necessary in Julia\n",
    "        \n",
    "        dUdt = W * V[:,i-1] + g_leak*(U_rest - U[:,i-1])/tau\n",
    "        \n",
    "        if t[i] < cue_period + delay_period\n",
    "            if trial_type==\"anti\"\n",
    "                dUdt[[2,4]] += delay_input\n",
    "            elseif trial_type == \"pro\"\n",
    "                dUdt[[1,3]] += delay_input\n",
    "            else\n",
    "                error(\"invalid trial type\")\n",
    "            end\n",
    "            \n",
    "        elseif t[i] < cue_period + delay_period + choice_period\n",
    "            dUdt[[1,2]] += light_input\n",
    "        end\n",
    "    \n",
    "        dUdt[[1,3]] += pro_bias\n",
    "        \n",
    "        \n",
    "\n",
    "        U[:,i] = U[:,i-1] +  dt*dUdt\n",
    "\n",
    "        V[:,i] = 0.5*tanh((U[:,i]-theta)/beta) + 0.5\n",
    "        \n",
    "        if t[i] < cue_period\n",
    "            V[:,i]=V[:,i]*opto_cue\n",
    "        elseif t[i] < cue_period+delay_period\n",
    "            V[:,i]=V[:,i]*opto_delay\n",
    "        elseif t[i] < cue_period+delay_period+choice_period\n",
    "            V[:,i]=V[:,i]*opto_choice\n",
    "        end\n",
    "\n",
    "        V[:,i] = V[:,i] + noisefr*randn(4)*sqrt(dt)\n",
    "\n",
    "\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if do_plot\n",
    "        figure(fignum);\n",
    "        h = plot(t, V');\n",
    "        setp(h[1], color=[0, 0, 1])\n",
    "        setp(h[2], color=[1, 0, 0])\n",
    "        setp(h[3], color=[1, 0.5, 0.5])\n",
    "        setp(h[4], color=[0, 1, 1])\n",
    "         \n",
    "        ax = gca()\n",
    "        yl = [ylim()[1], ylim()[2]]\n",
    "        vlines([cue_period, cue_period+delay_period,\n",
    "                cue_period+delay_period+choice_period],\n",
    "                0.05, 1.05, linewidth=2)\n",
    "        if yl[1]<0.02\n",
    "                 yl[1] = -0.02\n",
    "        end\n",
    "        if yl[2]>0.98\n",
    "                 yl[2] = 1.02\n",
    "        end\n",
    "        ylim(yl)\n",
    "        grid(true)\n",
    "     end\n",
    "                 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    answer  = V[1,end] - V[3,end]\n",
    "\n",
    "\n",
    "    #compute reaction time\n",
    "\n",
    "    reac=NaN;\n",
    "    for i in [8001:length(t)-15;]\n",
    "        val1=mean(V[1,i-15:i+15]);\n",
    "        val3=mean(V[3,i-15:i+15]);\n",
    "        if(abs(val1-val3)>threshold)\n",
    "            reac=t[i];\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return answer, reac, t, U, V\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the dynamics with Marino's parameters just to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5930530293725472\n",
      "402.05\n",
      "******************\n",
      "0.5774225131020866\n",
      "402.0\n",
      "******************\n",
      "0.6226678672508857\n",
      "401.85\n",
      "******************\n",
      "0.5473068688826903\n",
      "402.15\n",
      "******************\n",
      "0.5784606534618995\n",
      "401.85\n",
      "******************\n",
      "-0.3048699289028684\n",
      "428.6\n",
      "******************\n",
      "-0.38437661772862275\n",
      "400.0\n",
      "******************\n",
      "0.701529045962731\n",
      "400.8\n",
      "******************\n",
      "-0.3578939463526034\n",
      "419.95\n",
      "******************\n",
      "-0.3299615763379042\n",
      "427.9\n",
      "******************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "params = [36, 1, 0.854, 1]\n",
    "ntrys = 5\n",
    "opto_delay_use=1\n",
    "opto_choice_use=1\n",
    "\n",
    "                \n",
    "do_plot_use=true;\n",
    "\n",
    "                 \n",
    "for i in [1:ntrys;]\n",
    "    answer, reac, U, V = run_dynamics(\"pro\", params,opto_delay=opto_delay_use,opto_choice=opto_choice_use,do_plot=do_plot_use,fignum=1)\n",
    "    println(answer)\n",
    "    println(reac)\n",
    "    println(\"******************\")\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "for i in [1:ntrys;]\n",
    "answer, reac, U, V = run_dynamics(\"anti\", params,opto_delay=opto_delay_use,opto_choice=opto_choice_use,do_plot=do_plot_use,fignum=2)\n",
    "println(answer)\n",
    "println(reac)\n",
    "println(\"******************\")\n",
    "end\n",
    "\n",
    "                \n",
    "# show()\n",
    "\n",
    "                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we play with testing with differentiating the main dynamics function, and defining a cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.887484490092884\n",
      "[1.40753,-14.4571,-73.8544,78.3756]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "function J(params, targets; ntrials=10, sigma=3.2, random_seed=321)\n",
    "\n",
    "Computes a cost function for certain parameters and fraction correct targets\n",
    "\"\"\"\n",
    "             \n",
    "function J(params, targets; ntrials=10, noisefr=0.1, random_seed=321)\n",
    "    \n",
    "    srand(random_seed)\n",
    "                 \n",
    "    pro_perf  = 0;\n",
    "    anti_perf = 0;\n",
    "    \n",
    "    pro_perf_opto_delay  = 0;\n",
    "    anti_perf_opto_delay = 0;\n",
    "    \n",
    "    pro_perf_opto_choice  = 0;\n",
    "    anti_perf_opto_choice = 0;\n",
    "\n",
    "             \n",
    "    for i in [1:ntrials;]\n",
    "        answer, reac, t, U, V = run_dynamics(\"pro\", params, noisefr=noisefr)\n",
    "        pro_perf += V[1,end] - V[3,end]\n",
    "\n",
    "        answer, reac, t, U, V = run_dynamics(\"anti\", params, noisefr=noisefr)\n",
    "        anti_perf += V[3,end] - V[1,end]\n",
    "        \n",
    "        \n",
    "        answer, reac, t, U, V = run_dynamics(\"pro\", params, noisefr=noisefr, opto_delay=0.95)\n",
    "        pro_perf_opto_delay += V[1,end] - V[3,end]\n",
    "        \n",
    "        answer, reac, t, U, V = run_dynamics(\"anti\", params, noisefr=noisefr, opto_delay=0.95)\n",
    "        anti_perf_opto_delay += V[1,end] - V[3,end]\n",
    "        \n",
    "        \n",
    "        answer, reac, t, U, V = run_dynamics(\"pro\", params, noisefr=noisefr, opto_choice=0.95)\n",
    "        pro_perf_opto_choice += V[1,end] - V[3,end]\n",
    "        \n",
    "        answer, reac, t, U, V = run_dynamics(\"anti\", params, noisefr=noisefr, opto_choice=0.95)\n",
    "        anti_perf_opto_choice += V[1,end] - V[3,end]\n",
    "        \n",
    "        \n",
    "        \n",
    "    end\n",
    "\n",
    "    cost = (pro_perf - ntrials*targets[1])^2 + (anti_perf - ntrials*targets[2])^2 + \n",
    "    (pro_perf_opto_delay - ntrials*targets[3])^2 + (anti_perf_opto_delay - ntrials*targets[4])^2 +\n",
    "    (pro_perf_opto_choice - ntrials*targets[5])^2 + (anti_perf_opto_choice - ntrials*targets[5])^2\n",
    "\n",
    "    return cost/ntrials\n",
    "                 \n",
    "end\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "params = [36, 1, 0.854, 1]\n",
    "\n",
    "targets = [0.8, 0.7, 0.8, 0.5, 0.8, 0.7]   # Fraction correct in Pro and Anti\n",
    "\n",
    "println(J(params, targets))\n",
    "\n",
    "grad = ForwardDiff.gradient(x -> J(x, targets), params)\n",
    "\n",
    "println(grad)\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning to test gradient descent\n",
    "\n",
    "It's kind of working?  Two issues:\n",
    "\n",
    "(a) I think we're trapped in the final attractor values-- maybe time to explore adding reaction time, or not computing unit values so late in the trial? Actually, on further inspection, it is really asking for something like 80% performance without having defined outputs as hit=1, miss=0.  Really need the sigmoid.\n",
    "\n",
    "(b) Right now I only know how to differentiate J when J computes a single scalar.  But sometimes we want to stash some values as we go. Don't yet know how to do that.\n",
    "\n",
    "(c) Would also be nice to save values in a file or something while the gradient descent search is occurring, so as to have a trace of what happened, for later debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "                 \n",
    "                 \n",
    " params = [36, 1, 0.854, 1]\n",
    " \n",
    " \n",
    " targets = [0.8, 0.7, 0.8, 0.5, 0.8, 0.7]   # Fraction correct in Pro and Anti\n",
    "                 \n",
    "\n",
    " \n",
    " ntrials = 100\n",
    " \n",
    "  eta = 0.001;\n",
    " \n",
    "               \n",
    "                 \n",
    " # --------------\n",
    " \n",
    " out = DiffBase.GradientResult(params)\n",
    " ForwardDiff.gradient!(out, x -> J(x, targets, ntrials=ntrials), params)\n",
    " cost = DiffBase.value(out)\n",
    " grad = DiffBase.gradient(out)\n",
    " \n",
    " i=0; while eta > 1e-6\n",
    " \n",
    " i=i+1\n",
    " new_params = params - eta*grad\n",
    " \n",
    " ForwardDiff.gradient!(out, x -> J(x, targets, ntrials=ntrials), new_params)\n",
    " new_cost = DiffBase.value(out)\n",
    " new_grad = DiffBase.gradient(out)\n",
    " \n",
    " if new_cost < cost\n",
    " params = new_params\n",
    " cost   = new_cost\n",
    " grad   = new_grad\n",
    " eta = eta*1.1\n",
    " else\n",
    " eta = eta/2\n",
    " end\n",
    " \n",
    "    if rem(i, 1)==0\n",
    " @printf \"%d: eta=%f, cost=%.5f, params=[%.3f, %.3f, %.3f, %.3f]\\n\" i eta cost params[1] params[2] params[3] params[4]\n",
    " end\n",
    " end\n",
    " \n",
    " \n",
    " \n",
    "                 \n",
    "       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
