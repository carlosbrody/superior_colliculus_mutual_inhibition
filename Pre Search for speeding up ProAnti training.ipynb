{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">TABLE OF CONTENTS</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "**Updates to the table of contents are periodic, but run the cell below to first start or force an update.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this file only explores control trials, no opto yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('make_table_of_contents.js')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "macro javascript_str(s) display(\"text/javascript\", s); end\n",
    "\n",
    "javascript\"\"\"\n",
    "$.getScript('make_table_of_contents.js')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New cost function -- double_search.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_run"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me double_search.jl\n",
    "\n",
    "README_TOP = \"\"\"\n",
    "\n",
    "Code for doing a minimization (no opto) in which we first do a quick search\n",
    "with few trials, not on %correct but instead on specific differences between \n",
    "V[1] and V[4], for example for V[1]-V[4]=0.1 on Pro trials and =-0.1 on Anti \n",
    "trials.\n",
    "\n",
    "We stop that quick pre-search when the binarized hits for Pro and for Anti are\n",
    "both >= 0.7; and it is at those params that we then run the usual minimization.\n",
    "\n",
    "This doesn't make 100% of minimization runs successful, but it does seem to\n",
    "increase the hit rate. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "include(\"pro_anti.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_J() -- a cost function on V[1]-V[4] values, not per cent correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me double_search.jl\n",
    "\n",
    "\"\"\"\n",
    "cost, costf, dP, dA, hBP, hBA, proValls, antiValls = \n",
    "    new_J(nPro, nAnti; pro_target_diff=0.1, anti_target_diff=0.1, \n",
    "    opto_conditions = Array{Any}(0,4), plot_condition = 0,\n",
    "    verbose=false, pre_string=\"\", seedrand=NaN, \n",
    "    rule_and_delay_periods = nothing, target_periods = nothing, post_target_periods = nothing,\n",
    "    plot_list = [], model_params...)\n",
    "\n",
    "Runs a proAnti network, with a cost that simply asks for a certain fixed, signed, difference\n",
    "between the Pro units on Pro trials and another fixed, signed, difference between Anti units.\n",
    "Note that there is nothing about per cent correct here! E.g., 100% of Pro trials have the same target.\n",
    "Like JJ(), this function can, if desired, run across multiple opto conditions and multiple period \n",
    "durations and returns resulting total cost.\n",
    "\n",
    "(The motivation is to use a search on this new_J() to seed starting param values for the full JJ().)\n",
    "\n",
    "If rule_and_delay_periods, target_periods, and post_target_periods are not passed, it tries to get them from \n",
    "their singular (not plural) versions in model_params, e.g., model_params[:rule_and_delay_period]. NOTE that this\n",
    "is not what JJ() does for target_period.\n",
    "\n",
    "# PARAMETERS:\n",
    "\n",
    "- nPro, nAnti    The number of Pro and the number of Anti trials to run\n",
    "\n",
    "- pro_target     The target V[1] - V[4] for Pro trials.\n",
    "\n",
    "- anti_target    The target V[4] - V[1] for Anti trials\n",
    "\n",
    "- opto_conditions    Each row is the [start_time, end_time, pro_target, anti_target] for an opto condition. \n",
    "                The first two columns follow the rules of `parse_opto_times()`: they can be arbitrary Julia \n",
    "                expressions involving the terms trial_start, target_start, target_end, and trial_end.\n",
    "\n",
    "- plot_condition   If non-zero, should be an integer in the range of the rows of opto_conditions, and\n",
    "                indicates which condition to plot.  A zero means don't plot any of them.\n",
    "\n",
    "- seedrand      If sets, calls srand() on the value to initialize the random number generator.\n",
    "\n",
    "- verbose       If true, prints out diagnostic information to the console.\n",
    "\n",
    "- pre_string    Relevant only under verbose=true, a string that gets printed out before the rest of the verbose info.\n",
    "\n",
    "- rule_and_delay_periods    Vector, indicating set of rule_and_delay_period lengths to iterate over, \n",
    "                            while testing set of opto_periods, etc. on each one. \n",
    "                            Deafult is to do a single one, as picked out from model_params[:rule_and_delay_period]\n",
    "\n",
    "- target_periods            Vector, indicating set of target_perdiod lengths to iterate over, \n",
    "                            while testing set of opto_periods, etc. on each one.\n",
    "                            ** DEFAULT IS TO USE 0.1**, not to pick it out from model_params\n",
    "\n",
    "- post_target_periods       Vector, indicating set of post_target_period lengths to iterate over, \n",
    "                            while testing set of opto_periods, etc. on each one. \n",
    "                            Deafult is to do a single one, as picked out from model_params[:post_target_period]\n",
    " \n",
    "- plot_list                 A list of trial numbers to plot in each condition, e.g.  [1:10;]\n",
    "\n",
    "- model_params              Any remaining keyword-value params are passed as is on to run_ntrials \n",
    "\n",
    "\n",
    ", get_value(costf), get_value(dP), get_value(dA), get_value(hBP), get_value(hBA), \n",
    "        get_value(proValls), get_value(antiValls)\n",
    "\n",
    "# RETURNS:\n",
    "\n",
    "- cost   The net cost, composed of squared error cost (promoting signed V[1]-V[4] differences close to the desired ones).\n",
    "\n",
    "- costf  A matrix, with cost for each opto x period_length condition\n",
    "\n",
    "- dP     squared error cost, mean of (V[1]-V[4] - pro_target)^2 on Pro trials\n",
    "    \n",
    "- dA     squared error cost, mean of (V[4]-V[1] - anti_target)^2  on Anti trials\n",
    "    \n",
    "- hBP    Pro binarized hits, as computed by binarizing (equivalent to theta1->0)\n",
    "    \n",
    "- hBA    Anti binarized hits\n",
    "\n",
    "- proValls   record of full V as a function of time for Pro trials\n",
    "\n",
    "- antiValls  record of full V as a function of time for Anti trials\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function new_J(nPro, nAnti; pro_target_diff=0.1, anti_target_diff=0.1, \n",
    "    opto_conditions = Array{Any}(0,4), plot_condition = 0,\n",
    "    verbose=false, pre_string=\"\", seedrand=NaN, \n",
    "    rule_and_delay_periods = nothing, target_periods = nothing, post_target_periods = nothing,\n",
    "    plot_list = [], model_params...)\n",
    "\n",
    "    if FDversion() < 0.6\n",
    "        error(\"Sorry, new_J() runs only on Julia 0.6 or higher\")\n",
    "    end\n",
    "    \n",
    "\n",
    "    # All the variables that we MIGHT choose to differentiate w.r.t. go into this bag -- further down\n",
    "    # we'll use get_eltype(varbag) to check for any of them being ForwardDiff.Dual.\n",
    "    # That is how we'll tell whether new matrices should be regular numbers of ForwardDiff.Dual's.\n",
    "    # *** if you add a new variable you'll want to differentiate w.r.t., it should be added here too ***\n",
    "    varbag = (pro_target_diff, anti_target_diff, opto_conditions, model_params)\n",
    "    # print(\"get_eltype(varbag)=\"); print(get_eltype(varbag)); print(\"\\n\")\n",
    "    \n",
    "    # If the plurals of the periods are not passed in, then use the singular in model_params as the default:\n",
    "    if rule_and_delay_periods==nothing\n",
    "        rule_and_delay_periods = model_params[:rule_and_delay_period]\n",
    "    end\n",
    "    if target_periods==nothing        \n",
    "        target_periods = model_params[:target_period]\n",
    "    end\n",
    "    if post_target_periods==nothing\n",
    "         post_target_periods = model_params[:post_target_period]\n",
    "    end\n",
    "    \n",
    "    if size(opto_conditions,1)==0  # if there's no opto that is being asked for\n",
    "        # Then run with only a single opto_period request, with no opto, and control targets as our targets\n",
    "        opto_conditions = [\"trial_start-1\" \"trial_start-1\" pro_target_diff anti_target_diff]\n",
    "    end\n",
    "    \n",
    "    if size(opto_conditions,2) != 4\n",
    "        try\n",
    "            # Make sure its rows are 4 cols\n",
    "            opto_conditions = reshape(opto_conditions, Int64(round(length(opto_periods)/4)), 4) \n",
    "        catch\n",
    "            error(\"Something is wrong with opto_periods -- it should have 4 columns\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    noptos     = size(opto_conditions,1)  # of opto conditions\n",
    "    nruns_each = length(rule_and_delay_periods)*length(target_periods)*length(post_target_periods)    # runs per opto condition\n",
    "    nruns      = nruns_each*noptos  # total conditions\n",
    "\n",
    "    costf = zeros(get_eltype(varbag), noptos, nruns)\n",
    "    \n",
    "    dP  = zeros(noptos, nruns_each);   # Pro  diffs\n",
    "    dA  = zeros(noptos, nruns_each);   # Anti diffs\n",
    "    hBP = zeros(noptos, nruns_each);   # Pro binarized hits\n",
    "    hBA = zeros(noptos, nruns_each);   # Anti binarized hits\n",
    "\n",
    "    proValls         = [];\n",
    "    antiValls        = [];\n",
    "    opto_fraction    = [];\n",
    "    pro_input        = [];\n",
    "    anti_input       = [];\n",
    "    \n",
    "    for nopto=1:noptos # iterate over each opto inactivation period\n",
    "        # @printf(\"size(hBP) is %d, %d\\n\", size(hBP,1), size(hBP,2))\n",
    "\n",
    "        # reset random number generator for each opto period, so it cant over fit noise samples\n",
    "        if ~isnan(seedrand); srand(seedrand); end\n",
    "\n",
    "        n = 0  # n is a counter over all period duration conditions\n",
    "        totHitsP = totHitsA = totDiffsP = totDiffsA = 0\n",
    "        for i in rule_and_delay_periods\n",
    "            for j in target_periods\n",
    "                for k = post_target_periods\n",
    "                    n += 1\n",
    "\n",
    "                    # include this opto inactivation in the parameters to pass on\n",
    "                    my_params = make_dict([\"rule_and_delay_period\",\"target_period\",\"post_target_period\"], [i,j,k])\n",
    "                    my_params = make_dict([\"opto_times\"], [reshape(opto_conditions[nopto,1:2], 1, 2)], my_params)\n",
    "                    my_params = merge(Dict(model_params), my_params)  # my_params takes precedence\n",
    "\n",
    "                    my_plot_list = []\n",
    "                    if plot_condition == nopto; my_plot_list = plot_list; else myplot_list=[]; end\n",
    "\n",
    "                    # print(\"model params is \" ); print(model_params); print(\"\\n\")\n",
    "                    proVs, antiVs, proVall, antiVall, opto_fraction,pro_input,anti_input =\n",
    "                        run_ntrials(nPro, nAnti; plot_list=my_plot_list, my_params...)\n",
    "\n",
    "                    if length(proValls)==0\n",
    "                        proValls = zeros(4, size(proVall,2), size(proVall,3), noptos)\n",
    "                    end\n",
    "                    if length(antiValls)==0\n",
    "                        antiValls = zeros(4, size(antiVall,2), size(antiVall,3), noptos)\n",
    "                    end\n",
    "                    proValls[:,:,:,nopto]  = get_value(proVall)  # make sure they're not stored as ForwardDiff Duals\n",
    "                    antiValls[:,:,:,nopto] = get_value(antiVall)\n",
    "                    \n",
    "                    diffsP = proVs[1,:]  - proVs[4,:]\n",
    "                    diffsA = antiVs[4,:] - antiVs[1,:]\n",
    "                    \n",
    "                    # set up storage  -- we do get_value() to make sure to from ForwardDiff.Dual into Float64 if necessary\n",
    "                    dP[nopto, n] = sqrt(mean((get_value(diffsP) - opto_conditions[nopto,3]).^2));\n",
    "                    dA[nopto, n] = sqrt(mean((get_value(diffsA) - opto_conditions[nopto,4]).^2));\n",
    "                    hBP[nopto, n] = get_value(sum(proVs[1,:] .>= proVs[4,:,])/nPro);\n",
    "                    hBA[nopto, n] = get_value(sum(antiVs[4,:] .>  antiVs[1,:,])/nAnti);                    \n",
    "                    \n",
    "                    if nPro>0 && nAnti>0\n",
    "                        # cost can accept ForwardDiff.Dual, so no get_value() for them\n",
    "                        costf[nopto, n] = (nPro *mean((diffsP - opto_conditions[nopto,3]).^2) +\n",
    "                                         nAnti*mean((diffsA - opto_conditions[nopto,4]).^2))/(nPro+nAnti)\n",
    "                    elseif nPro>0\n",
    "                        costf[nopto, n] = mean((diffsP - opto_conditions[nopto,3]).^2)\n",
    "                    else\n",
    "                        costf[nopto, n] = mean((diffsA - opto_conditions[nopto,4]).^2)\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        if verbose\n",
    "            pcost = mean(costf[nopto,:])   # partial costs\n",
    "            \n",
    "            # Notice the get_value() calls below, to transform ForwardDiff Duals into Float64s\n",
    "            @printf(\"%s\", pre_string)\n",
    "            @printf(\"Opto condition # %d\\n\", nopto)\n",
    "            @printf(\"     - %d - cost=%g\\n\", nopto, get_value(pcost))\n",
    "            if nPro>0 && nAnti>0\n",
    "                @printf(\"     - %d - hBP=%g, dP=%g, hBA=%g, dA=%g\\n\", nopto, \n",
    "                    mean(hBP[nopto,:]), mean(dP[nopto,:]), mean(hBA[nopto,:]), mean(dA[nopto,:]))\n",
    "            elseif nPro>0\n",
    "                @printf(\"     - %d - hBP=%g, dP=%g\\n\", nopto, mean(hBP[nopto,:]), mean(dP[nopto,:]))\n",
    "            else\n",
    "                @printf(\"     - %d - hBA=%g, dA=%g\\n\", nopto, mean(hBA[nopto,:]), mean(dA[nopto,:]))\n",
    "            end        \n",
    "        end\n",
    "    end\n",
    "        \n",
    "    cost = mean(costf)\n",
    "\n",
    "    if verbose\n",
    "        @printf(\"%s\", pre_string)\n",
    "        @printf(\"OVERALL\\n\")\n",
    "        @printf(\"     -- cost=%g\\n\", get_value(cost))\n",
    "    end\n",
    "    \n",
    "\n",
    "    # The scalar cost should be differentiable, the others should be regular Float64s\n",
    "    return cost, get_value(costf), get_value(dP), get_value(dA), get_value(hBP), get_value(hBA), \n",
    "        get_value(proValls), get_value(antiValls)\n",
    "end                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## quick_search() -- run a quick set of minimizations with new_J() to find seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me double_search.jl\n",
    "\n",
    "\"\"\"\n",
    "    pars, [pro_targ_doff, anti_targ_diff] = quick_search(ntrials, seed, args, bbox; \n",
    "        BP_target=0.7, pro_diffs_targets=[0.1, 0.2, 0.3, 0.4], anti_diffs_targets=nothing,\n",
    "        model_params=nothing, verbose=true, maxiter=500)\n",
    "\n",
    "runs a series of minimizations with new_J() and the passed model params, iterating over the\n",
    "list of target V[1]-V[4] differences in pro_diffs_targets and anti_diffs_targets. As soon as it\n",
    "finds parameters that give binarized %correct of at least BP_target (for both Pro and Anti),\n",
    "returns those values.  If it can't find good param values, returns the original seed.\n",
    "\n",
    "# PARAMETERS\n",
    "\n",
    "- ntrials    The number of Pro and number of Anti trials to use with new_J()\n",
    "\n",
    "- seed       A vector with starting paramter values\n",
    "\n",
    "- args       A vector of strings, indicating the name of the keyword-value params\n",
    "             that correspond to the entries in seed\n",
    "\n",
    "- bbox       A Dict() indicating a bounding box, as used by bbox_Hessian_keyword_minimization()\n",
    "\n",
    "\n",
    "# OBLIGATORY KEYWORD-VALUE PARAM:\n",
    "\n",
    "- model_params   The paramaters for the ProAnti model that will be passed on to new_J(). Obligatory param.\n",
    "\n",
    "\n",
    "# OPTIONAL PARAMS:\n",
    "\n",
    "- BP-target    The binarized fraction correct target, for both Pro and Anti trials. When this \n",
    "             is reached, we return.\n",
    "\n",
    "- pro_diffs_targets   A vector, representing a list of target V[1]-V[4] end-of-Pro-trial values to \n",
    "            train for.  Training attempts proceed in sequence, from the first to the last. If success is found\n",
    "            with an early one, later ones are not tried.\n",
    "\n",
    "- anti_diffs_targets   Like pro_diffs_targets, but indicates the target V[4]-V[1] end-of-Anti-trials\n",
    "            values to train for.  The default value, \"nothing\", means use the same targets as for Pro.  \n",
    "            (Note that +0.1 for Pro means V[1]>V[4], while +0.1 for Anti means V[4]>V[1])\n",
    "\n",
    "- verbose   If true, prints diagnostic info out to screen during minimizations\n",
    "\n",
    "- maxiter   Maximum number of iterations to run during each minimization attempt\n",
    "\n",
    "\n",
    "# RETURNS:\n",
    "\n",
    "- pars      If a good set of parameter values is found, returns those; otherwise returns seed\n",
    "\n",
    "- qu_out    A 1x2 vector with the pro_diffs_target value and the anti_diffs_target value that\n",
    "            produced success. If success was not found, returns zeros(1,2)\n",
    "\n",
    "\"\"\"\n",
    "function quick_search(ntrials, seed, args, bbox; \n",
    "    BP_target=0.7, pro_diffs_targets=[0.1, 0.2, 0.3, 0.4], anti_diffs_targets=nothing,\n",
    "    model_params=nothing, verbose=true, maxiter=500)\n",
    "   \n",
    "    if model_params==nothing; error(\"You need to specify model_params\"); end\n",
    "    if anti_diffs_targets == nothing; anti_diffs_targets = pro_diffs_targets; end\n",
    "    if length(anti_diffs_targets)!=length(pro_diffs_targets)\n",
    "        error(\"pro_diffs_targets and anti_diffs_targets must be same length (or anti_diffs_targets=nothing)\")\n",
    "    end\n",
    "\n",
    "    for i=1:length(pro_diffs_targets)\n",
    "\n",
    "        function stopping_func(;cost=0, func_out=[], ignored_extra_params...)\n",
    "            costf, dP, dA, hBP, hBA = func_out\n",
    "            return hBP[1]>=BP_target && hBA[1] >= BP_target\n",
    "        end\n",
    "\n",
    "        func2 =  (;params...) -> new_J(ntrials, ntrials; \n",
    "            pro_target_diff=pro_diffs_targets[i], anti_target_diffs=anti_diffs_targets[i],\n",
    "            pre_string=\"new_J(): \", \n",
    "            verbose=false, merge(model_params, Dict(params))...)\n",
    "\n",
    "        pars2, traj2, cost2, cpm_traj2, ftraj2 = bbox_Hessian_keyword_minimization(seed, \n",
    "            args, bbox, func2, \n",
    "            stopping_function = stopping_func, \n",
    "        start_eta = 0.1, tol=1e-12, verbose=verbose, verbose_every=1, maxiter=maxiter)\n",
    "        \n",
    "        if stopping_func(cost=0, func_out=ftraj2[3,end])\n",
    "            return pars2, [pro_diffs_targets[i], anti_diffs_targets[i]]\n",
    "        end\n",
    "    end    \n",
    "\n",
    "    return copy(seed), [0, 0]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me double_search.jl\n",
    "\n",
    "\n",
    "mypars = Dict(\n",
    ":init_add               =>          0,\n",
    ":const_add              =>          0,\n",
    ":noise                  =>          Any[],\n",
    ":input                  =>          0,\n",
    ":start_anti             =>          [-0.5, -0.5, -0.5, -0.5],\n",
    ":start_pro              =>          [-0.5, -0.5, -0.5, -0.5],\n",
    ":rule_and_delay_period  =>          1.2,\n",
    ":rule_and_delay_periods =>          [1.2],\n",
    ":target_period          =>          0.3,\n",
    ":target_periods         =>          [0.3],\n",
    ":post_target_period     =>          0.3,\n",
    ":post_target_periods    =>          [0.3],\n",
    ":anti_rule_strength     =>          0.054,\n",
    ":U_rest                 =>          0,\n",
    ":theta                  =>          0.05,\n",
    ":beta                   =>          0.5,\n",
    ":g_leak                 =>          1,\n",
    ":nsteps                 =>          301,\n",
    ":dt                     =>          0.024,\n",
    ":tau                    =>          0.09,\n",
    ":right_light_excitation =>          0.49924152955481954,\n",
    ":opto_strength          =>          0.85,\n",
    ":opto_periods           =>          String[\n",
    "                                    \"trial_start\" \"trial_start\"; \n",
    "                                    \"trial_start\" \"trial_end\"; \n",
    "                                    \"trial_start\" \"target_start/2\"; \n",
    "                                    \"target_start/2\" \"target_start\"; \n",
    "                                    \"target_start\" \"target_end\"],\n",
    ":opto_targets          =>           [\n",
    "                                    0.9 0.7; \n",
    "                                    0.9 0.5; \n",
    "                                    0.9 0.7; \n",
    "                                    0.9 0.5; \n",
    "                                    0.9 0.7],\n",
    ":theta2 => 0.15,\n",
    ":theta1 => 0.05,\n",
    ":sigma => 0.01,\n",
    ":cbeta => 0.04,\n",
    ":sW => 0.6416875048295452,\n",
    ":hW => 0.054701836208134846,\n",
    ":dW => 0.1267124266934907,\n",
    ":vW => -1.588850577499782,\n",
    ":constant_excitation => -0.37242520737694207,\n",
    ":const_pro_bias => 0.04366897857834884,\n",
    ":target_period_excitation => 0.15315254453690974,\n",
    ":right_light_pro_extra => 0,\n",
    ":pro_rule_strength => 0.05,\n",
    ":nPro => 200,\n",
    ":nAnti => 200,\n",
    ")\n",
    "\n",
    "\n",
    "extra_pars = Dict(\n",
    ":plot_list        =>   [], \n",
    ":plot_conditions  =>   true,\n",
    ":verbose          =>   true,\n",
    ":opto_periods     =>   String[\"trial_start\" \"trial_start-0.1\"],\n",
    ":opto_targets     =>   [0.9,  0.7],\n",
    ":opto_times       =>   [\"trial_start\", \"trial_start-0.1\"],       # This one is for run_ntrials\n",
    ":cbeta            =>   0.001,\n",
    ":search_range     =>   1.2,\n",
    ")\n",
    "\n",
    "\n",
    "search_conditions = Dict(   # :param    default_start   search_box  bound_box\n",
    ":vW     =>                   [mypars[:vW],                       [-0.5, 0.5],  [-3,   3]], \n",
    ":hW     =>                   [mypars[:hW],                       [-0.5, 0.5],  [-3,   3]],\n",
    ":dW     =>                   [mypars[:dW],                       [-0.5, 0.5],  [-3,   3]],\n",
    ":sW     =>                   [mypars[:sW],                       [0,    0.5],  [0,    3]],\n",
    ":sigma  =>                   [0.11,                              [0.1,  0.2],  [0.1, 0.4]],\n",
    ":constant_excitation      => [mypars[:constant_excitation],      [-1,     1],  [-2,   2]], \n",
    ":target_period_excitation => [mypars[:target_period_excitation], [0.001,0.5],  [0     4]],\n",
    ":right_light_excitation   => [mypars[:right_light_excitation],   [0.05, 0.5],  [0.05, 4]],\n",
    ":const_pro_bias           => [mypars[:const_pro_bias],           [-0.5, 0.5],  [-2,   2]],\n",
    "# :opto_strength            => [mypars[:opto_strength],            [0.7, 0.99],  [0,    1]],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for double_search.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@include_me double_search.jl\n",
    "ftraj2 = []; cost2 = [];\n",
    "extra_pars[:seedrand] = Int64(round(1000*time()))   # 1510782006169 causes lin.alg error but then looks like it'll succeed\n",
    "srand(extra_pars[:seedrand])\n",
    "\n",
    "search_range = extra_pars[:search_range]; \n",
    "\n",
    "README = \"\"\"\n",
    "\n",
    "Farm C11: Just like C10, but now the full original search box.\n",
    "(which is still small compared to the full parameter range we'd \n",
    "*like* to search.)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if !isdir(\"../NewFarms\"); mkdir(\"../NewFarms\"); end\n",
    "fbasename = \"../NewFarms/farm_C11_\"\n",
    "# If we wanted a unique identifier per processor run the following line would help:\n",
    "# if ~isnull(tryparse(Int64, ARGS[1])); fbasename = fbasename * ARGS[1] * \"_\"; end\n",
    "\n",
    "@printf(\"\\n\\n\\nStarting with random seed %d\\n\\n\\n\", extra_pars[:seedrand])\n",
    "\n",
    "while true\n",
    "    \n",
    "    @printf(\"\\n\\n--- new run ---\\n\\n\")\n",
    "    args = []; seed = []; bbox = Dict()\n",
    "    for k in keys(search_conditions)\n",
    "        search_box = search_conditions[k][2]\n",
    "        args = [args; String(k)]\n",
    "        # --- search within the indicated search range:\n",
    "        # myseed = search_conditions[k][1] + search_range*(rand()-0.5)*diff(search_box); myseed = myseed[1]\n",
    "        # if myseed > search_box[2]; myseed = search_box[2]; end\n",
    "        # if myseed < search_box[1]; myseed = search_box[1]; end\n",
    "        # seed = [seed ;  myseed]\n",
    "        # --- No search, just start at the indicated position:\n",
    "        # seed = [seed ; search_conditions[k][1]]\n",
    "        # --- search within the full indicated search box\n",
    "        seed = [seed ; rand()*diff(search_box) + search_box[1]]\n",
    "        bbox = merge(bbox, Dict(k => Array{Float64}(search_conditions[k][3])))\n",
    "    end\n",
    "    args = Array{String}(args)\n",
    "    seed = Array{Float64}(seed)\n",
    "\n",
    "\n",
    "    maxiter1 = 1000;   # for func1, the regular search\n",
    "    maxiter2 = 500;    # for the quick_search\n",
    "    testruns = 10000;  # Number of trials for evaluating the results of the model. 10000 is a good number \n",
    "\n",
    "    # For func2:\n",
    "    extra_pars[:opto_conditions] = []    \n",
    "    extra_pars[:plot_condition] = 0            \n",
    "    extra_pars[:plot_list] = []\n",
    "\n",
    "    # Make sure to keep the noise frozen over the search, meaning JJ() needs the seedrand parameter\n",
    "    func1 =  (;params...) -> JJ(mypars[:nPro], mypars[:nAnti]; verbose=false, \n",
    "        merge(merge(mypars, extra_pars), Dict(params))...)[1]\n",
    "    \n",
    "    try\n",
    "        ntries = 2  # old ans unnecessary; should just delete from here and from save\n",
    "\n",
    "        # Initial quick search to find good seed param values\n",
    "        start_pars, qu_out = quick_search(40, seed, args, bbox; model_params=merge(mypars, extra_pars),\n",
    "            maxiter=maxiter2)\n",
    "\n",
    "        # Then full minimization\n",
    "        pars3, traj3, cost3, cpm_traj3, ftraj3 = bbox_Hessian_keyword_minimization(start_pars, \n",
    "            args, bbox, func1, \n",
    "            start_eta = 0.01, tol=1e-12, \n",
    "            verbose=true, verbose_every=1, maxiter=maxiter1)\n",
    "            \n",
    "        # evaluate the result with many trials, for accuracy\n",
    "        cost, cost1s, cost2s, hP, hA, dP, dA, hBP, hBA = JJ(testruns, testruns; verbose=false, \n",
    "            make_dict(args, pars3, merge(merge(mypars, extra_pars)))...)\n",
    "        \n",
    "        # Write out the results\n",
    "        myfilename = next_file(fbasename, 4)\n",
    "        myfilename = myfilename*\".jld\"\n",
    "\n",
    "        @printf(\"\\n\\n ****** writing to file %s *******\\n\\n\", myfilename)\n",
    "        \n",
    "        # write file\n",
    "        save(myfilename, Dict(\"README\"=>README, \"nPro\"=>mypars[:nPro], \"nAnti\"=>mypars[:nAnti], \"ntries\"=>ntries, \n",
    "            \"start_pars\"=>start_pars, \"qu_out\"=>qu_out,\n",
    "            \"mypars\"=>mypars, \"extra_pars\"=>extra_pars, \"args\"=>args, \"seed\"=>seed, \"bbox\"=>bbox, \n",
    "                        \"pars3\"=>pars3, \"traj3\"=>traj3, \"cost3\"=>cost3, \"cpm_traj3\"=>cpm_traj3, \"ftraj3\"=>ftraj3,\n",
    "            \"cost\"=>cost, \"cost1s\"=>cost1s, \"cost2s\"=>cost2s,\n",
    "            \"hP\"=>hP, \"hA\"=>hA, \"dP\"=>dP, \"dA\"=>dA, \"hBP\"=>hBP, \"hBA\"=>hBA))\n",
    "\n",
    "    catch y\n",
    "        # Interrupts should not get caught:\n",
    "        if isa(y, InterruptException); throw(InterruptException()); end\n",
    "\n",
    "        # Other errors get caught and a warning is issued but then we run again\n",
    "        @printf(\"\\n\\nWhoopsety, unkown error!\\n\\n\");\n",
    "        @printf(\"Error was :\\n\"); print(y); @printf(\"\\n\\nTrying new random seed.\\n\\n\")\n",
    "    end\n",
    "\n",
    "    # Change random seed before next iteration so we don't get stuck in one loop\n",
    "    extra_pars[:seedrand] = extra_pars[:seedrand]+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing runs from double_search.jl : analyze_double_search.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #@include_me analyze_double_search.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 runs found\n",
      "  did run 10\n",
      "  did run 20\n",
      "  did run 30\n",
      "  did run 40\n",
      "  did run 50\n",
      "  did run 60\n",
      "  did run 70\n",
      "  did run 80\n",
      "  did run 90\n",
      "  did run 100\n",
      "  did run 110\n",
      "  did run 120\n",
      "  did run 130\n",
      "  did run 140\n",
      "  did run 150\n",
      "  did run 160\n",
      "  did run 170\n",
      "  did run 180\n",
      "  did run 190\n",
      "  did run 200\n",
      "  did run 210\n",
      "  did run 220\n",
      "  did run 230\n",
      "  did run 240\n",
      "  did run 250\n",
      "  did run 260\n",
      "  did run 270\n",
      "  did run 280\n",
      "  did run 290\n",
      "  did run 300\n",
      "  did run 310\n",
      "  did run 320\n",
      "  did run 330\n",
      "  did run 340\n",
      "  did run 350\n",
      "  did run 360\n",
      "  did run 370\n",
      "  did run 380\n",
      "  did run 390\n",
      "  did run 400\n"
     ]
    }
   ],
   "source": [
    "#@include_me analyze_double_search.jl\n",
    "\n",
    "using JLD\n",
    "\n",
    "standard  = \"C15\"\n",
    "pre_search = \"C14\"\n",
    "\n",
    "nruns = 0;\n",
    "for f in filter(x -> startswith(x, \"farm_\" * standard * \"_\"), readdir(\"../NewFarms\")); nruns += 1; end\n",
    "@printf(\"%d runs found\\n\", nruns)\n",
    "\n",
    "outs = zeros(nruns,3)\n",
    "for i=1:nruns;\n",
    "    myname = @sprintf(\"%d\", i)\n",
    "    while length(myname)<4; myname = \"0\" * myname; end\n",
    "    outs[i,1] = load(\"../NewFarms/farm_\" * standard * \"_\" * myname * \".jld\", \"traj3\")[2,end]\n",
    "    traj3, qu_out = load(\"../NewFarms/farm_\" * pre_search * \"_\" * myname * \".jld\", \"traj3\", \"qu_out\")\n",
    "    outs[i,2] = traj3[2,end]\n",
    "    outs[i,3] = qu_out[1]\n",
    "    if rem(i,10)==0; @printf(\"  did run %d\\n\", i); end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject Text(-0.000925,0.07,'Success rate after pre-search success is 34.78%\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@include_me analyze_double_search.jl\n",
    "\n",
    "using StatsBase\n",
    "using PyPlot\n",
    "pygui(true)\n",
    "\n",
    "x = -0.001:0.000001:maximum(outs[:,1:2])\n",
    "\n",
    "h1 = fit(Histogram, outs[:,1], x, closed=:right)\n",
    "h2 = fit(Histogram, outs[:,2], x, closed=:right)\n",
    "\n",
    "figure(2); clf();\n",
    "subplot(2,1,1)\n",
    "plot(x, [0 ; cumsum(h1.weights)]/sum(h1.weights), \"b-\")\n",
    "plot(x, [0 ; cumsum(h2.weights)]/sum(h2.weights), \"r-\")\n",
    "\n",
    "legend([\"standard minimization\", \"with pre-search\"])\n",
    "title(@sprintf(\"%d runs for each method\", sum(h1.weights)))\n",
    "\n",
    "subplot(2,1,2)\n",
    "plot(x, [0 ; cumsum(h1.weights)]/sum(h1.weights), \"b-\")\n",
    "plot(x, [0 ; cumsum(h2.weights)]/sum(h2.weights), \"r-\")\n",
    "xlim([-0.001, -0.0007])\n",
    "vlines(-0.00095, ylim()[1], ylim()[2], color=\"g\", linestyle=\"--\")\n",
    "\n",
    "xlabel(\"Training cost (left of green dashed is a good run)\")\n",
    "ylabel(\"fraction of runs\")\n",
    "\n",
    "\n",
    "pre_fail = outs[outs[:,3].==0,2]\n",
    "pre_succ = outs[.!(outs[:,3].==0),2]\n",
    "\n",
    "ylim(-0.002, 0.095)\n",
    "text(-0.000925, 0.06, \n",
    "    @sprintf(\"Success rate after pre-search fail is %.2f%%\\n\", 100*length(find(pre_fail.<-0.0009))/length(pre_fail)))\n",
    "text(-0.000925, 0.07, \n",
    "    @sprintf(\"Success rate after pre-search success is %.2f%%\\n\", 100*length(find(pre_succ.<-0.0009))/length(pre_succ)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44-element Array{Float64,1}:\n",
       "  0.0729852  \n",
       "  0.0190134  \n",
       "  0.053404   \n",
       "  0.0689119  \n",
       "  0.0905253  \n",
       "  0.0694576  \n",
       "  0.0690334  \n",
       "  0.0769976  \n",
       " -0.000988805\n",
       "  0.017663   \n",
       " -0.000999909\n",
       " -0.000997303\n",
       "  0.0489064  \n",
       "  ⋮          \n",
       "  0.0420751  \n",
       "  0.04059    \n",
       "  0.0196222  \n",
       "  0.0198052  \n",
       "  0.0185829  \n",
       "  0.0705669  \n",
       "  0.10925    \n",
       "  0.0420244  \n",
       " -0.000999037\n",
       "  0.0902017  \n",
       "  0.0169432  \n",
       "  0.0514954  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35-element Array{Int64,1}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       " 10\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       "  ⋮\n",
       " 32\n",
       " 33\n",
       " 34\n",
       " 35\n",
       " 36\n",
       " 37\n",
       " 38\n",
       " 39\n",
       " 40\n",
       " 42\n",
       " 43\n",
       " 44"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find(outs[outs[:,3].==0,2] .>= -0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
